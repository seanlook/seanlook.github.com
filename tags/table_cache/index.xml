<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>table_cache on Sean Note</title>
    <link>http://xgknight.com/tags/table_cache/</link>
    <description>Recent content in table_cache on Sean Note</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Oct 2017 16:32:49 +0000</lastBuildDate><atom:link href="http://xgknight.com/tags/table_cache/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>table_open_cache 与 table_definition_cache 对MySQL(内存)的影响</title>
      <link>http://xgknight.com/posts/2017/10/table_open_cache-%E4%B8%8E-table_definition_cache-%E5%AF%B9mysql%E5%86%85%E5%AD%98%E7%9A%84%E5%BD%B1%E5%93%8D/</link>
      <pubDate>Fri, 13 Oct 2017 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/10/table_open_cache-%E4%B8%8E-table_definition_cache-%E5%AF%B9mysql%E5%86%85%E5%AD%98%E7%9A%84%E5%BD%B1%E5%93%8D/</guid>
      <description>1. 现象，内存使用大 首先说一下最近遇到的一个现象，因为分库的缘故，单实例里面的表的数量增加了20倍，总数将近达到10000个。在开发环境明显感觉到执行简单查询都很慢，在processlist里面看到状态 opening table 达到好几秒但数据库并没有什么负载。本能的想到应该要加大 table_open_cache，可是加大后发现MySQL刚启动 RES 就占用了2.5G内存，之前才500-600M的样子。
只是将 table_open_cache 从默认的2000，增加到10000（先不论这个值合不合理），就独占了2G的内存，这对于生产环境内存浪费是不可接受的。还好，关于这个问题的讨论有不少，感兴趣的话可以阅读 #bug 68287, #bug 68514, 12015-percona-5-6-14-56-very-high-memory-usage。
Oracle官方工程师并不认为这是个bug，导致初始化分配这么多内存的原因是，开启了 Performance_Schema 。P_S测量数据库的性能指标，需要提前一次性分配内存，而不是随着数据库运行逐渐申请内存。
下表是不同参数组合下内存占用的测试结果： （注：可以通过这个来查看PFS里面哪些占内存比较多，mysql -hxxxx -Pxxx -uxx -pxx -e &amp;quot;show engine performance_schema status&amp;quot;|grep memory|sort -nr -k3 |head ）
对于 table_open_cache 设置的非常大的情况下，即使还有许多cache多余，但P_S都需要分配这个数量的内存。解决这个内存大的问题有3个方向：
table_open_cache, table_definition_cache, max_connections 设置合理 关闭 performance_schema 保持 PFS 开启，关闭测量 max_table_instances和max_table_handles performance_schema_max_table_instances: 最大测量多少个表对象
对应 (pfs_table_share).memory，我的环境里固定 277600000 bytes performance_schema_max_table_handles: 最大打开表的总数
对应(pfs_table).memory，随着 table_open_cache 的增大而增大 关闭的方法是在my.cnf里面设置以上变量为 0 。默认是 -1 ，表示 autosize，即根据 table_open_cache/table_def_cache/max_connections 的值自动设置，相关代码 pfs_autosize.cc：
PFS_sizing_data *estimate_hints(PFS_global_param *param) { if ((param-&amp;gt;m_hints.</description>
    </item>
    
    <item>
      <title>MySQL实例阻塞分析一例(线程statistics状态)</title>
      <link>http://xgknight.com/posts/2017/09/mysql%E5%AE%9E%E4%BE%8B%E9%98%BB%E5%A1%9E%E5%88%86%E6%9E%90%E4%B8%80%E4%BE%8B%E7%BA%BF%E7%A8%8Bstatistics%E7%8A%B6%E6%80%81/</link>
      <pubDate>Sat, 23 Sep 2017 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/09/mysql%E5%AE%9E%E4%BE%8B%E9%98%BB%E5%A1%9E%E5%88%86%E6%9E%90%E4%B8%80%E4%BE%8B%E7%BA%BF%E7%A8%8Bstatistics%E7%8A%B6%E6%80%81/</guid>
      <description>1. 现象 某日下午下班后低峰期，现网MySQL一个库突然报出大量慢sql，状态是 statistics，但是过后拿这些sql去执行的时候，实际很快。处于 statistics 状态的线程有个特征：查询的都是视图，但看监控那个时间段并没有明显的update/detele/insert。通过我们的快照程序，去分析当时的 innodb status，发现如下信息：
SEMAPHORES ---------- OS WAIT ARRAY INFO: reservation count 17208994 --Thread 139964610234112 has waited at srv0srv.cc line 2132 for 14.00 seconds the semaphore: X-lock (wait_ex) on RW-latch at 0x1635a00 created in file dict0dict.cc line 900 a writer (thread id 139964610234112) has reserved it in mode wait exclusive number of readers 1, waiters flag 0, lock_word: ffffffffffffffff Last time read locked in file row0purge.cc line 720 Last time write locked in file /home/admin/146_20161018140650857_13830810_code/rpm_workspace/storage/innobase/srv/srv0srv.</description>
    </item>
    
    <item>
      <title>一个简单的数据订阅程序(for DBA)</title>
      <link>http://xgknight.com/posts/2017/09/%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%95%B0%E6%8D%AE%E8%AE%A2%E9%98%85%E7%A8%8B%E5%BA%8Ffor-dba/</link>
      <pubDate>Tue, 05 Sep 2017 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/09/%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%95%B0%E6%8D%AE%E8%AE%A2%E9%98%85%E7%A8%8B%E5%BA%8Ffor-dba/</guid>
      <description>本程序基于大众点评github项目 binlog2sql 二次开发而来，可以实现对源库的binlog实时接收，并组装成增量sql。
原项目默认是把sql输出到控制台，二次开发后的版本把sql放入redis队列，根据需要由另一个程序消费到目标库，模拟了一个“从库”。 在测试时--stop-never在qa环境没有作用，添加了在 BinLogStreamReader 实例里面加入 blocking=True 来保证源源不断的接受binlog而不中断。
另外也加入了更改目标库名的功能，比如原库叫d_my1，生成的sql目标库名是 d_my2 。
项目地址：https://github.com/seanlook/binlog2sql
应用场景 目前想到以下应用场景：
实时同步部分表到另外一个数据库实例 比如在数据库迁库时，将当天表的数据同步到新库，模拟阿里云dms数据传输的功能，相当于在测试环境演练，减少失误。 另外还可以从新库反向同步增量数据到老库，解决测试环境多项目测试引起数据库冲突的问题。
正式切库时的回滚措施 比如数据库迁移项目，切换期间数据写向新库，但如果切换失败需要回滚到老库，就需要把这段时间新增的数据同步回老库（启动消费程序），这就不需要程序段再考虑复杂的回滚设计。
数据库闪回 关于数据库误操作的闪回方案，见 文章MySQL根据离线binlog快速闪回 。binlog2sql的 -B 选项可以将sql反向组装，生产回滚sql。如果需要完善的闪回功能，要进一步开发，提高易用性。
binlog搜索功能 目前组内一版的binlog搜索功能，是离线任务处理的方式，好处是不会占用太大空间，缺点是处理时间较长。通过实时binlog解析过滤的方式，入ES可以快速搜索。需要进一步开发完善。
使用方法 安装好python2.7虚拟环境，安装必要模块：pymysql, mysql-replication, redis, rq
pip install -r requirements.txt 注意：pymysqlreplication 库在处理 &amp;lsquo;0000-00-00 00:00:00&amp;rsquo; 时有些不尽人意，可能会导致生产的sql在目标库执行失败，还有对datetime(6)类型有个bug，也对它进行了修复，地址：https://github.com/seanlook/python-mysql-replication 。
准备一个redis用于存放sql队列，在环境变量里面设置redis地址
export REDIS_URL=&amp;#39;redis://localhost:6379&amp;#39; 在主库执行 show master status 得到binlog开始的文件名和postion，然后开始订阅：
binlog2sql原版使用时： $ ~/.pyenv/versions/2.7.10/envs/py2_binlog/bin/python binlog2sql.py -h192.168.1.185 -P3306 -uecuser -pecuser \ -d d_ec_contact --tables t_crm_contact_at \ --start-file=&amp;#39;mysql-bin.000001&amp;#39; --start-datetime=&amp;#39;2017-08-30 12:30:00&amp;#39; --start-position=6529058 \ --stop-never &amp;gt; contact0.</description>
    </item>
    
  </channel>
</rss>
