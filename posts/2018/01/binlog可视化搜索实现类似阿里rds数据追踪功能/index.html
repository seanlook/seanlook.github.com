<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Binlog可视化搜索：实现类似阿里RDS数据追踪功能 | Sean Note</title>
<meta name="keywords" content="mysql, binlog">
<meta name="description" content="MySQL Binlog 里面记录了每行数据的变更，开发有时候需要根据这些变更的时间、中间值去查问题，是bug导致的，还是用户操作引发的。然而原始binlog内容不利于检索，有段时间使用阿里RDS企业版DMS数据追踪的功能，也能完成这个工作，甚至生成回滚sql，后由于收费以及容量不够的缘故，放弃不用。
本文所介绍的就是基于外面开源的各类组件，整合起来，达到类似数据追踪的功能 —— binlog 可视化。 功能类似：10分钟搭建MySQL Binlog分析&#43;可视化方案
1. 主要技术 项目地址： https://github.com/seanlook/maxwell-graylog
docker
使用容器来实现资源的申请和释放，毕竟这类检索binlog内容的需求不多。 本文基于阿里云的容器服务。
maxwell
从mysql server获取binlog和字段信息，组装成json流。建议先阅读 http://xgknight.com/2018/01/13/maxwell-binlog/
官网：http://maxwells-daemon.io/
graylog
代替ELK技术栈的日志收集、处理、展示平台。社区版够用，需要自行安装，也可以把 graylog 换成 ELK stack。
官网：https://www.graylog.org/
nxlog
nxlog 是用 C 语言写的一个开源日志收集处理软件，它是一个模块化、多线程、高性能的日志管理解决方案，支持多平台。
参考：http://blog.csdn.net/weixin_29477879/article/details/52183746
rabbitmq
一款开源消息队列中间件，采用Erlang语言开发，RabbitMQ是AMQP(Advanced Message Queueing Protocol)的标准实现。建议先阅读 http://xgknight.com/2018/01/06/rabbitmq-introduce/ 。
你也可以把消息队列换成kafka。
2. 使用说明 2.1 举例 查看 some3 库 2018-01-22 13:00:00 ~ 2018-01-22 13:00:00 之间，表 t_ecsome_detail 的binlog变化，graylog根据AMQP协议从rabbitmq取binlog json流
提前创建一个 Swarm容器集群，名字叫 maxwell。
在【编排模板】里选择 maxwell-graylog-rabbitmq，【创建应用】下一步修改编排模板： （只修改 environment 里面的变量值）
mysql-binlogsvr: image: registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3 volumes: - maxwellgraylog_db_data:/var/lib/mysql environment: DBINSTANCE_ID: rm-bp19t9it7c2998633 START_TIME: &#39;2018-01-22 13:00:00&#39; END_TIME: &#39;2018-01-22 14:00:00&#39; ACCESS_ID: LTAIXKHm0v6ob5P4 ACCESS_SECRET: F7g***************Nll19no MYSQL_ROOT_PASSWORD: strongpassword maxwell-svr: image: registry-vpc.">
<meta name="author" content="admin">
<link rel="canonical" href="http://xgknight.com/posts/2018/01/binlog%E5%8F%AF%E8%A7%86%E5%8C%96%E6%90%9C%E7%B4%A2%E5%AE%9E%E7%8E%B0%E7%B1%BB%E4%BC%BC%E9%98%BF%E9%87%8Crds%E6%95%B0%E6%8D%AE%E8%BF%BD%E8%B8%AA%E5%8A%9F%E8%83%BD/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.bccfefac377bc340f06c260aed1bddf49a4354816d7c570d6aac75a997986c95.css" integrity="sha256-vM/vrDd7w0DwbCYK7Rvd9JpDVIFtfFcNaqx1qZeYbJU=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="http://xgknight.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://xgknight.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://xgknight.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://xgknight.com/apple-touch-icon.png">
<link rel="mask-icon" href="http://xgknight.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Binlog可视化搜索：实现类似阿里RDS数据追踪功能" />
<meta property="og:description" content="MySQL Binlog 里面记录了每行数据的变更，开发有时候需要根据这些变更的时间、中间值去查问题，是bug导致的，还是用户操作引发的。然而原始binlog内容不利于检索，有段时间使用阿里RDS企业版DMS数据追踪的功能，也能完成这个工作，甚至生成回滚sql，后由于收费以及容量不够的缘故，放弃不用。
本文所介绍的就是基于外面开源的各类组件，整合起来，达到类似数据追踪的功能 —— binlog 可视化。 功能类似：10分钟搭建MySQL Binlog分析&#43;可视化方案
1. 主要技术 项目地址： https://github.com/seanlook/maxwell-graylog
docker
使用容器来实现资源的申请和释放，毕竟这类检索binlog内容的需求不多。 本文基于阿里云的容器服务。
maxwell
从mysql server获取binlog和字段信息，组装成json流。建议先阅读 http://xgknight.com/2018/01/13/maxwell-binlog/
官网：http://maxwells-daemon.io/
graylog
代替ELK技术栈的日志收集、处理、展示平台。社区版够用，需要自行安装，也可以把 graylog 换成 ELK stack。
官网：https://www.graylog.org/
nxlog
nxlog 是用 C 语言写的一个开源日志收集处理软件，它是一个模块化、多线程、高性能的日志管理解决方案，支持多平台。
参考：http://blog.csdn.net/weixin_29477879/article/details/52183746
rabbitmq
一款开源消息队列中间件，采用Erlang语言开发，RabbitMQ是AMQP(Advanced Message Queueing Protocol)的标准实现。建议先阅读 http://xgknight.com/2018/01/06/rabbitmq-introduce/ 。
你也可以把消息队列换成kafka。
2. 使用说明 2.1 举例 查看 some3 库 2018-01-22 13:00:00 ~ 2018-01-22 13:00:00 之间，表 t_ecsome_detail 的binlog变化，graylog根据AMQP协议从rabbitmq取binlog json流
提前创建一个 Swarm容器集群，名字叫 maxwell。
在【编排模板】里选择 maxwell-graylog-rabbitmq，【创建应用】下一步修改编排模板： （只修改 environment 里面的变量值）
mysql-binlogsvr: image: registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3 volumes: - maxwellgraylog_db_data:/var/lib/mysql environment: DBINSTANCE_ID: rm-bp19t9it7c2998633 START_TIME: &#39;2018-01-22 13:00:00&#39; END_TIME: &#39;2018-01-22 14:00:00&#39; ACCESS_ID: LTAIXKHm0v6ob5P4 ACCESS_SECRET: F7g***************Nll19no MYSQL_ROOT_PASSWORD: strongpassword maxwell-svr: image: registry-vpc." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://xgknight.com/posts/2018/01/binlog%E5%8F%AF%E8%A7%86%E5%8C%96%E6%90%9C%E7%B4%A2%E5%AE%9E%E7%8E%B0%E7%B1%BB%E4%BC%BC%E9%98%BF%E9%87%8Crds%E6%95%B0%E6%8D%AE%E8%BF%BD%E8%B8%AA%E5%8A%9F%E8%83%BD/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-01-25T15:32:49+00:00" />
<meta property="article:modified_time" content="2018-01-25T15:32:49+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Binlog可视化搜索：实现类似阿里RDS数据追踪功能"/>
<meta name="twitter:description" content="MySQL Binlog 里面记录了每行数据的变更，开发有时候需要根据这些变更的时间、中间值去查问题，是bug导致的，还是用户操作引发的。然而原始binlog内容不利于检索，有段时间使用阿里RDS企业版DMS数据追踪的功能，也能完成这个工作，甚至生成回滚sql，后由于收费以及容量不够的缘故，放弃不用。
本文所介绍的就是基于外面开源的各类组件，整合起来，达到类似数据追踪的功能 —— binlog 可视化。 功能类似：10分钟搭建MySQL Binlog分析&#43;可视化方案
1. 主要技术 项目地址： https://github.com/seanlook/maxwell-graylog
docker
使用容器来实现资源的申请和释放，毕竟这类检索binlog内容的需求不多。 本文基于阿里云的容器服务。
maxwell
从mysql server获取binlog和字段信息，组装成json流。建议先阅读 http://xgknight.com/2018/01/13/maxwell-binlog/
官网：http://maxwells-daemon.io/
graylog
代替ELK技术栈的日志收集、处理、展示平台。社区版够用，需要自行安装，也可以把 graylog 换成 ELK stack。
官网：https://www.graylog.org/
nxlog
nxlog 是用 C 语言写的一个开源日志收集处理软件，它是一个模块化、多线程、高性能的日志管理解决方案，支持多平台。
参考：http://blog.csdn.net/weixin_29477879/article/details/52183746
rabbitmq
一款开源消息队列中间件，采用Erlang语言开发，RabbitMQ是AMQP(Advanced Message Queueing Protocol)的标准实现。建议先阅读 http://xgknight.com/2018/01/06/rabbitmq-introduce/ 。
你也可以把消息队列换成kafka。
2. 使用说明 2.1 举例 查看 some3 库 2018-01-22 13:00:00 ~ 2018-01-22 13:00:00 之间，表 t_ecsome_detail 的binlog变化，graylog根据AMQP协议从rabbitmq取binlog json流
提前创建一个 Swarm容器集群，名字叫 maxwell。
在【编排模板】里选择 maxwell-graylog-rabbitmq，【创建应用】下一步修改编排模板： （只修改 environment 里面的变量值）
mysql-binlogsvr: image: registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3 volumes: - maxwellgraylog_db_data:/var/lib/mysql environment: DBINSTANCE_ID: rm-bp19t9it7c2998633 START_TIME: &#39;2018-01-22 13:00:00&#39; END_TIME: &#39;2018-01-22 14:00:00&#39; ACCESS_ID: LTAIXKHm0v6ob5P4 ACCESS_SECRET: F7g***************Nll19no MYSQL_ROOT_PASSWORD: strongpassword maxwell-svr: image: registry-vpc."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://xgknight.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Binlog可视化搜索：实现类似阿里RDS数据追踪功能",
      "item": "http://xgknight.com/posts/2018/01/binlog%E5%8F%AF%E8%A7%86%E5%8C%96%E6%90%9C%E7%B4%A2%E5%AE%9E%E7%8E%B0%E7%B1%BB%E4%BC%BC%E9%98%BF%E9%87%8Crds%E6%95%B0%E6%8D%AE%E8%BF%BD%E8%B8%AA%E5%8A%9F%E8%83%BD/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Binlog可视化搜索：实现类似阿里RDS数据追踪功能",
  "name": "Binlog可视化搜索：实现类似阿里RDS数据追踪功能",
  "description": "MySQL Binlog 里面记录了每行数据的变更，开发有时候需要根据这些变更的时间、中间值去查问题，是bug导致的，还是用户操作引发的。然而原始binlog内容不利于检索，有段时间使用阿里RDS企业版DMS数据追踪的功能，也能完成这个工作，甚至生成回滚sql，后由于收费以及容量不够的缘故，放弃不用。\n本文所介绍的就是基于外面开源的各类组件，整合起来，达到类似数据追踪的功能 —— binlog 可视化。 功能类似：10分钟搭建MySQL Binlog分析+可视化方案\n1. 主要技术 项目地址： https://github.com/seanlook/maxwell-graylog\ndocker\n使用容器来实现资源的申请和释放，毕竟这类检索binlog内容的需求不多。 本文基于阿里云的容器服务。\nmaxwell\n从mysql server获取binlog和字段信息，组装成json流。建议先阅读 http://xgknight.com/2018/01/13/maxwell-binlog/\n官网：http://maxwells-daemon.io/\ngraylog\n代替ELK技术栈的日志收集、处理、展示平台。社区版够用，需要自行安装，也可以把 graylog 换成 ELK stack。\n官网：https://www.graylog.org/\nnxlog\nnxlog 是用 C 语言写的一个开源日志收集处理软件，它是一个模块化、多线程、高性能的日志管理解决方案，支持多平台。\n参考：http://blog.csdn.net/weixin_29477879/article/details/52183746\nrabbitmq\n一款开源消息队列中间件，采用Erlang语言开发，RabbitMQ是AMQP(Advanced Message Queueing Protocol)的标准实现。建议先阅读 http://xgknight.com/2018/01/06/rabbitmq-introduce/ 。\n你也可以把消息队列换成kafka。\n2. 使用说明 2.1 举例 查看 some3 库 2018-01-22 13:00:00 ~ 2018-01-22 13:00:00 之间，表 t_ecsome_detail 的binlog变化，graylog根据AMQP协议从rabbitmq取binlog json流\n提前创建一个 Swarm容器集群，名字叫 maxwell。\n在【编排模板】里选择 maxwell-graylog-rabbitmq，【创建应用】下一步修改编排模板： （只修改 environment 里面的变量值）\nmysql-binlogsvr: image: registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3 volumes: - maxwellgraylog_db_data:/var/lib/mysql environment: DBINSTANCE_ID: rm-bp19t9it7c2998633 START_TIME: \u0026#39;2018-01-22 13:00:00\u0026#39; END_TIME: \u0026#39;2018-01-22 14:00:00\u0026#39; ACCESS_ID: LTAIXKHm0v6ob5P4 ACCESS_SECRET: F7g***************Nll19no MYSQL_ROOT_PASSWORD: strongpassword maxwell-svr: image: registry-vpc.",
  "keywords": [
    "mysql", "binlog"
  ],
  "articleBody": "MySQL Binlog 里面记录了每行数据的变更，开发有时候需要根据这些变更的时间、中间值去查问题，是bug导致的，还是用户操作引发的。然而原始binlog内容不利于检索，有段时间使用阿里RDS企业版DMS数据追踪的功能，也能完成这个工作，甚至生成回滚sql，后由于收费以及容量不够的缘故，放弃不用。\n本文所介绍的就是基于外面开源的各类组件，整合起来，达到类似数据追踪的功能 —— binlog 可视化。 功能类似：10分钟搭建MySQL Binlog分析+可视化方案\n1. 主要技术 项目地址： https://github.com/seanlook/maxwell-graylog\ndocker\n使用容器来实现资源的申请和释放，毕竟这类检索binlog内容的需求不多。 本文基于阿里云的容器服务。\nmaxwell\n从mysql server获取binlog和字段信息，组装成json流。建议先阅读 http://xgknight.com/2018/01/13/maxwell-binlog/\n官网：http://maxwells-daemon.io/\ngraylog\n代替ELK技术栈的日志收集、处理、展示平台。社区版够用，需要自行安装，也可以把 graylog 换成 ELK stack。\n官网：https://www.graylog.org/\nnxlog\nnxlog 是用 C 语言写的一个开源日志收集处理软件，它是一个模块化、多线程、高性能的日志管理解决方案，支持多平台。\n参考：http://blog.csdn.net/weixin_29477879/article/details/52183746\nrabbitmq\n一款开源消息队列中间件，采用Erlang语言开发，RabbitMQ是AMQP(Advanced Message Queueing Protocol)的标准实现。建议先阅读 http://xgknight.com/2018/01/06/rabbitmq-introduce/ 。\n你也可以把消息队列换成kafka。\n2. 使用说明 2.1 举例 查看 some3 库 2018-01-22 13:00:00 ~ 2018-01-22 13:00:00 之间，表 t_ecsome_detail 的binlog变化，graylog根据AMQP协议从rabbitmq取binlog json流\n提前创建一个 Swarm容器集群，名字叫 maxwell。\n在【编排模板】里选择 maxwell-graylog-rabbitmq，【创建应用】下一步修改编排模板： （只修改 environment 里面的变量值）\nmysql-binlogsvr: image: registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3 volumes: - maxwellgraylog_db_data:/var/lib/mysql environment: DBINSTANCE_ID: rm-bp19t9it7c2998633 START_TIME: '2018-01-22 13:00:00' END_TIME: '2018-01-22 14:00:00' ACCESS_ID: LTAIXKHm0v6ob5P4 ACCESS_SECRET: F7g***************Nll19no MYSQL_ROOT_PASSWORD: strongpassword maxwell-svr: image: registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_graylog:1.1.3 depends_on: - mysql-binlogsvr environment: producer: rabbitmq MYSQL_HOST: MYSQL_USER: MYSQL_PASSWORD: MYSQL_HOST_GIT: db_some_shard3 include_dbs: include_tables: t_ecsome_detail include_column_values: init_position: rabbitmq_host: 10.81.xx.xxx rabbitmq_virtual_host: /maxwell rabbitmq_user: admin rabbitmq_pass: admin kafka_server: kafka_producer_partition_by: database MAXWELL_OPTS: volumes: - maxwellgraylog_db_data:/var/lib/mysql links: - mysql-binlogsvr:mysql_binlogsvr 2.2 变量/参数说明： DBINSTANCE_ID\n需要分析哪个实例的binlog。必须提供 ACCESS_ID, ACCESS_SECRET\n从OSS下载该实例binlog的key，这个key的用户需要RDS的读权限。必须提供 START_TIME, END_TIME\n需要分析 binlog 大致位于哪个时间段。请尽可能的精确，如果时间范围过大，可能耗时非常久。3个binlog入完graylog大约6分钟。不能保持示例默认的值\n如果你想从 MYSQL_HOST 直接在线拉取binlog，则不要设置设置 START_TIME 和 END_TIME，程序会一致从当前位置持续读取。 MYSQL_ROOT_PASSWORD\nmysql binlogsvr 的root的密码。默认为 strongpassword producer\n指定maxwell产生的binlog json流输出到哪里，完整的支持file, rabbitmq, kafka MYSQL_HOST, MYSQL_USER, MYSQL_PASSWORD\n它在两种情况下使用： 前面的START_TIME、END_TIME留空，这里的 MYSQL_HOST 代表的是maxwell直接连接的地址，持续获取binlog。maxwell的 schema_database 也在这个库上(monitor，用户需要有读写这个db的权限) 前面的START_TIME、END_TIME有值，并且没有设置 MYSQL_HOST_GIT，那么 MYSQL_HOST 代表的是从这个地址拉取表结构，相当于maxwell的 schema_host 地址（当然获取binlog还是从 mysql_binlogsvr ） MYSQL_HOST_GIT, MYSQL_HOST_GIT_COMMIT\n从git仓库拉取表结构信息，MYSQL_HOST_GIT指定仓库里面实例目录名，MYSQL_HOST_GIT_COMMIT可以满足指定某个 提交 时候的表机构版本。在 START_TIME, END_TIME 有设置的情况下才有效。\n仓库见：http://xgknight.com/2016/11/28/mysql-schema-gather-structure/ rabbitmq_host, rabbitmq_virtual_host, rabbitmq_user, rabbitmq_pass, rabbitmq_exchange_type\n在 producer=rabbitmq 才有效。这些rabbitmq_xxx选项，与maxwell配置文件里面的完全相同 过滤选项\ninclude_dbs, include_tables, include_column_values\n与maxwell配置文件里面的完全相同。这里没有列出 exclude_xxx 相关过滤项，如果要指定，请使用 MAXWELL_OPTS\nexclude_columns，去除哪些列是值不予展示，可用于脱敏。\n支持的值参考maxwell的配置文件里面正则说明。 kafka_server\n在 rabbitmq=kafka 时有效。对应 maxwell 的 kafka.bootstrap.servers 选项\n其它选项如果要指定，可以使用MAXWELL_OPTS MAXWELL_OPTS\n因为现有 environment 变量没有覆盖所有的maxwell选项，所有其它选项可以直接像 maxwell 命令行参数一样，指定在 MAXWELL_OPTS 里面。 创建完后，可以看到两个容器：\n其中 maxwell-svr 在等待 mysql_binlogsvr 就绪:\nmaxwell-graylog-rabbitmq-some3_maxwell-svr_1 | 2018-01-26T11:58:08.424411112Z waiting for mysql_binlogsvr prepared maxwell-graylog-rabbitmq-some3_maxwell-svr_1 | 2018-01-26T11:58:28.427993770Z waiting for mysql_binlogsvr prepared maxwell-graylog-rabbitmq-some3_maxwell-svr_1 | 2018-01-26T11:58:48.431136523Z binlog download is done, wait more seconds for mysql_binlogsvr ready mysql-binlogsvr 在初始化 mysql server 的数据，下载binlog。完成的标志是在 /var/lib/mysql/initialized.lock里面写入 1 或 2，来通知 maxwell-svr。（1和2的意义见下面的Dockerfile说明） 在 maxwell-svr 日志里面看到 INFO BinlogConnectorLifecycleListener - Binlog connected. 字样，表示已经在binlog往外推。\n此时在 graylog 里面就可以看到输出内容了: http://graylog.workec.com:3003/search?q=gl2_source_input%3A5a655c3ba002a0526615062a\u0026relative=0\n处理速度大概在 10000msg/s，在graylog里面没有看到新数据进来，就代表分析完成。 现在比较麻烦的地方在于，处理完结束后，销毁容器容易，但前面创建的持久存储卷，阿里云的容器服务并不会删除本地的卷，它所提供的存储推荐是 OSS,NAS,云盘 这些存储服务，然后要为它单独创建子账号，单独对某个盘、bucket授权，十分麻烦。\n本地卷并不能自动的删除，如果下次启动这个binlog分析服务，因为挂在的是同样的 db_data，里面已经有脏数据，所以需要手动删除 主机上的 rm -rf /var/lib/docker/volumes/maxwellgraylog_db_data/_data/*\n2.3 其它编排模板 上面的示例，是基于 maxwell-graylog-rabbitmq 的编排模板，已经自定义了一下compose模板：\nmaxwell-graylog-rabbitmq\n依赖于外部 rabbitmq server，需要明确指定 rabbitmq_host 等信息。\n第一次使用，通过rabbitmq-init-for-maxwell.sh去初始化 maxwell-graylog 所需要的exchange,queue等。\nmaxwell-graylog-rabbitmq-nodeps\n会比上面的多起一个容器： rabbitmq-server，但是它的数据要通过容器集群的LB，才能被外面的graylog服务消费。 它的 rabbitmq_host被指定为maxwell-rabbitmq-server (container link)\nmaxwell-graylog-file\n不适用消息队列，直接写入文件，通过 nxlog 将数据推到 graylog，所以会多出一个 nxlog 容器 多出三个 environment variabeles:\ngraylogserver\nnxlog将“日志”上报的 graylog server 地址 graylog_maxwell_gelf_port\ngraylog 节点为接收这个消息监听的端口 (NXlog Outputs) graylog_maxwell_source_collector\ngraylog 为这个消息定义好的collecter名字 （collecter是graylog的入口，在它之上定义流转、拆解、存储等流程） graylog的配置方法和搜索使用，见后文。\nmaxwell-graylog-kafka\n使用 kafka 作为消息队列。需要指定现有的 kafka_server 。\n这个编排模板，没有提供很详细的实现，请结合 MAXWELL_OPTS 使用。\n提示：\n在使用时，如果容器启动失败，观察日志后，一般可以放心的直接重启容器，已做良好的修复处理。 选择哪个模板和设置什么变量值，主要考虑两个因素：从哪里获取binlog，maxwell将binlog生产到哪里 输出到file，nxlog读取的交给graylog处理的压力会非常大，可能会导致graylog响应慢。输出到rabbitmq，可以控制流入graylog的速度(Allow throttling this input?) 2.4 docker-compose.yml 阿里云的编排模板，与标准的 docker compose 并不完全一样。在 docker-compose 目录中，提供了6种编排方案，可使用自建的docker平台来做。 4个容器和变量的组合，应对不同的场景：\ndocker-compose.file.yml\n启动 mysql-binlogsvr, maxwell-svr, nxlog-svr 三个容器，binlog数据写入file。\ndocker-compose.file-schema.yml\n启动 mysql-binlogsvr, maxwell-svr, nxlog-svr 三个容器，binlog数据写入file。\n表结构从 schema_host 获取，而不是git仓库。monitor用户需要 REPLICATION SLAVE, REPLICATION CLIENT 权限。\ndocker-compose.rabbitmq.yml\n启动 mysql-binlogsvr, maxwell-svr 两个容器，binlog数据写入现有rabbitmq。\ndocker-compose.rabbitmq-nodeps.yml\n启动 mysql-binlogsvr, maxwell-svr, rabbitmq-server 三个容器，binlog数据写入rabbitmq容器。\n不依赖外部rabbitmq。\ndocker-compose.rabbitmq-nobinlog-svr.yml\n启动 mysql-binlogsvr, maxwell-svr, rabbitmq-server 三个容器，binlog数据写入rabbitmq容器。\nmysql-binlogsvr启动后会停止，这里直接从 MYSQL_HOST 在线持续拉取binlog，用户需要能够读取表结构的权限。\ndocker-compose.kafka.yml\n启动 mysql-binlogsvr, maxwell-svr 两个容器，binlog数据写入现有kafka。\n也可以逐个启动容器，不适用 docker-compose.yml。各个容器详情见后文。\n3. graylog配置和使用 生成的binlog json流要在graylog里面可视化展示，还需要对graylog设置。下面分别以 file 和 rabbitmq 的输出为例。\n3.1 Input: file 上面已经通过 maxwell容器 将数据写入了 output_file=/var/lib/mysql/maxwell_binlog_stream.json.log，又通过 nxlog容器 tail监控这个日志文件。\n创建一个 GELF TCP Input [System / Inputs] -\u003e [Inputs]\n勾选 Global 表示所有的 graylog 集群节点，都可以接收这个日志，Port： 12201 便是监听的端口。前文编排模板里面要求提供的参数 graylogserver 和 graylog_maxwell_gelf_port，就是从这来的。\n那么 Collecter graylog_maxwell_source_collector 呢，可以任意设置一个字符串。在标准的 graylog 配置流程里面，collecter 就是一个 nxlog 进程，一般一台机器就一个 nxlog，所以collecter对应的其实是收集日志的机器。\nnxlog 是一个单独的组件，与graylog没多大关系，而为了将两者整合在一起，需要 graylog-sidecar 来下发 nxlog 的配置，告诉它日志目录在哪、怎么读取日志。\n所以我们的docker容器只需要nxlog进程，不需要graylog-sidecar来交代配置，也就不需要在graylog Web界面配置NXLog Outputs/Inputs，而是直接通过变量传递来完成 nxlog.conf 模板的配置。\n下面的过程实际是不需要的，只是为了理解如何生成 nxlog.conf。\nCreate configuration 给这个 configuration 设置 tags 例如maxwell_binlog。\ngraylog-sidecar 会把 tag 打给某个机器(collecter)，告诉nxlog或其他收集组件，当前机器有哪几种日志需要收集\n编写 NXLog Outputs 相当于 nxlog.conf 中 部分，Host、Port 即第1步里面的graylog接收binlog json流而监听的地址和端口。 Type选择 [NXLog]GELF TCP output。\n编写 NXLog Inputs 相当于 nxlog.conf 中 部分，这里指定日志输入来源于文件,Type选择[NXLog]file input\nForward to 设置刚才创建的 Output File，要收集的日志路径为/var/lib/mysql/maxwell_binlog_stream.json.log Pool Interval，即检查日志文件的间隔时间。剩下的保持默认\n使用 JSON extractor 解析message 经过上面几步，启动maxwell和nxlog服务/容器之后，在graylog的 WebUI 上找到第1步建的Input，就可以看到有日志进来了。\n选择任意一个message，[Create extractor for field message] -\u003e [JSON]，将json数据解压出来，存储，便可以快速根据字段名来搜索binlog内容。\n3.2 Input: rabbitmq 使用rabbitmq更简单，不需要nxlog，直接在第1步里，把新建GELF TCP改成Raw/Plaintext AMQP。\n需要填写的就是AMQP协议里broker, port, user, exchange, queue, routing_key。 就可以在binlog里面，可视化看到binlog内容了。\n3.3 在graylog里面搜索binlog日志 搜索语法：http://docs.graylog.org/en/2.4/pages/queries.html\n例如，查看 t_ecsome_detail 表中 f_some_id=1242036566 在给定时间内的变化过程：\ngl2_source_input:5a38cc9bd56c001305aaefc0 AND data_f_some_id: 1242036566 OR old_f_some_id: 1242036566 例如使用Quick values功能，快速得到全国各地区对t_ecsome_detail表的操作量：\ngl2_source_input:5a38cc9bd56c001305aaefc0 AND NOT data_f_company_region: 0 我们有做db分库，查看各个分库下的请求量数据是不是平均的，database: quick value：\n4. 容器镜像说明：Dockerfile 本节是关于细节实现的部分，与上面的介绍会略有重复。\n4.1 Dockerfile.binlogsvr 承载 binlog 的mysql server服务。\n它首先根据提供的数据库实例信息、日期时间信息，去OSS拉取已经上传的binlog到本地，修改 mysql-bin.index文件，提供binlog来源。\n因为容器停止或者销毁后，内部的数据也随之丢失，所以需要一个主机上的目录来挂在到容器中，做数据的持久化，我们把这个数据卷命名为 db_data 。\nbinlogsvr-entrypoint.sh\n容器入口。因为 mysql server 启动第一次都要进行初始化，假如容器启动失败，再次启动时不需要再次初始化。\n脚本内通过 lockfile=/var/lib/mysql/initialized.lock 区分三种工作模式：\nlockfile 存在：mysql server 已经初始化 lockfile 内容为0：mysql server 作为binlogsvr lockfile 内容为2: binlog已经下载完成。避免重启容器导致重复下载binlog lockfile 内容为1：该容器无用，因为判断 START_TIME 和 END_TIME 为空。实际上表示后续maxwell 拉取，是直接从原 MYSQL_HOST 读取，不需要该binlogsvr\nlockfile 里面的值会被 maxwell 容器读取，以便决定工作模式 download_binlog.py\n从阿里OSS下载binlog，需要提供 DBINSTANCE_ID 和 时间界限。\nrequirements.txt：python环境依赖\nmysql_3306.cnf\nbinlogsvr的启动配置文件\n4.2 Dockerfile.maxwell maxwell服务容器，主版本1.12.0，加上修改了点内容：https://github.com/seanlook/maxwell\nmaxwell-entrypoint.sh\n容器入口。会等待 mysql_binlogsvr 初始化完成，maxwell的结构、postion等信息存放在binlogsvr的 monitor 库。\nwork_mode=1: 直接从 MYSQL_HOST 拉取binlog，不需要binlogsvr，可以实现持续读取现网的binlog work_mode=0: 从 mysql_binlogsvr 拉取binlog\n该模式下因为 binlogsvr 里并没有maxwell需要的表结构，支持两种方法： 如果设置了 MYSQL_HOST_GIT，表示从我们的git仓库里面拉取表结构 否则从 MYSQL_HOST 拉取表结构，对应maxwell变量 schema_host 。即这个时候的 MYSQL_HOST 不是指定binlog来源，而是表结构来源。 如果都没设置，异常退出 maxwell启动时需要指定 init_position，即从binlog_svr哪个binlog位置开始拉取：\n如果从直接从原数据库实例拉取，则指定为最新的binlog起始点； 如果为 binlogsvr 拉取，则指定为下载的binlog最小的那个binlog起始点； 在容器启动的时候，也可以直接指定 init_postion ，优先生效。\nlockfile=/var/lib/mysql/initialized_maxwell.lock 表示已经通过 init_postion 启动，如果重启maxwell容器，应该从上次停止的地方继续。 容器启动时，可以指定 producer 为 file, rabbitmq, kafka，根据对应的生产者，应该设置子选项。见后文。\nmaxwell-retrive-tablemeta.sh\n从git拉取所需要的表结构，并用 myloader 工具导入到 binlogsvr 。\n因为考虑到需求通常要过滤表，所以这里也这会在 binlogsvr 创建需要的表结构。\n如果指定了 MYSQL_HOST_GIT_COMMIT，可以拉取git上历史表结构。\nid_rsa：文件是拉起表结构用的 ssh key。\nmaxwell-src-1.12.0.tar.gz:\n已下载的maxwell包，会通过maven编译。\n4.3 Dockerfile.nxlog 在 producer=file 时，maxwell产生的binlog stream 是文件，要把文件放到 graylog 用到 nxlog 。\n它也会挂在 db_data，读取 output_file=/var/lib/mysql/maxwell_binlog_stream.json.log 内容，发送到 graylog server 。\ngraylogserver: graylog server 地址\ngraylog_maxwell_gelf_port: 在graylog提前配置好的接收maxwell数据的端口\ngraylog_maxwell_source_collector: 对应graylog的 collector id.\n配置graylog 方法见后文。\nnxlog-entrypoint.sh\n容器入口。主要是对 /etc/nxlog/nxlog.conf 进行变量替换。\n提示：也会读取 /var/lib/mysql/maxwell_instance_id 里面由 mysql_binlogsvr 传递过来的 instance_id 作为 message 的一部分\nnxlog.conf\nnxlog的配置文件模板，用于替换成上面的变量。\n4.4 Dockerfile.rabbitmq 在 producer=rabbitmq 时，maxwell需要 rabbitmq server 作为队列。\n这里提供两种使用方法：\n如果已经有现成的 rabbitmq ，则自己创建 vhost, exchange, user，需要提供的内容见 rabbitmq-init-formaxwell.sh\n如果没有rabbitmq，则通过这个 Dockerfile 创建 rabbitmq server container\nrabbitmq-entrypoint.sh\n容器入口。只是为了调用 rabbitmq-init-formaxwell.sh，在rabbitmq起来后，创建 --vhost=/maxwell --username=admin --password=admin,exchange=maxwell.binlog queue=maxwell_binlog binding_key=# 给maxwell和graylog使用。\n在后台通过 wait-for-it.sh 来同步等待 rabbitmq ok.\n4.5 build image docker build -f Dockerfile.binlogsvr . -t registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3 docker build -f Dockerfile.maxwell . -t registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_graylog:1.1.3 docker build -f Dockerfile.nxlog . -t registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_nxlog:0.4.3 docker build -f Dockerfile.rabbitmq . -t registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_rabbitmq:0.4.3 docker push registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3 docker push registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_graylog:1.1.3 docker push registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_nxlog:0.4.3 docker push registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_rabbitmq:0.4.3 参考\n原文连接地址：http://xgknight.com/2018/01/25/maxwell-graylog/\n",
  "wordCount" : "794",
  "inLanguage": "en",
  "datePublished": "2018-01-25T15:32:49Z",
  "dateModified": "2018-01-25T15:32:49Z",
  "author":{
    "@type": "Person",
    "name": "admin"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://xgknight.com/posts/2018/01/binlog%E5%8F%AF%E8%A7%86%E5%8C%96%E6%90%9C%E7%B4%A2%E5%AE%9E%E7%8E%B0%E7%B1%BB%E4%BC%BC%E9%98%BF%E9%87%8Crds%E6%95%B0%E6%8D%AE%E8%BF%BD%E8%B8%AA%E5%8A%9F%E8%83%BD/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Sean Note",
    "logo": {
      "@type": "ImageObject",
      "url": "http://xgknight.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://xgknight.com/" accesskey="h" title="Sean Note (Alt + H)">Sean Note</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://xgknight.com/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
            <li>
                <a href="http://xgknight.com/about/" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Binlog可视化搜索：实现类似阿里RDS数据追踪功能
    </h1>
    <div class="post-meta"><span title='2018-01-25 15:32:49 +0000 UTC'>January 25, 2018</span>&nbsp;·&nbsp;admin

</div>
  </header> 
  <div class="post-content"><p>MySQL Binlog 里面记录了每行数据的变更，开发有时候需要根据这些变更的时间、中间值去查问题，是bug导致的，还是用户操作引发的。然而原始binlog内容不利于检索，有段时间使用阿里RDS企业版DMS数据追踪的功能，也能完成这个工作，甚至生成回滚sql，后由于收费以及容量不够的缘故，放弃不用。</p>
<p>本文所介绍的就是基于外面开源的各类组件，整合起来，达到类似数据追踪的功能 —— binlog 可视化。
功能类似：<a href="https://yq.aliyun.com/articles/338423">10分钟搭建MySQL Binlog分析+可视化方案</a></p>
<h2 id="1-主要技术">1. 主要技术<a hidden class="anchor" aria-hidden="true" href="#1-主要技术">#</a></h2>
<p>项目地址： <a href="https://github.com/seanlook/maxwell-graylog">https://github.com/seanlook/maxwell-graylog</a></p>
<ul>
<li>
<p>docker<br>
使用容器来实现资源的申请和释放，毕竟这类检索binlog内容的需求不多。
本文基于阿里云的容器服务。</p>
</li>
<li>
<p>maxwell<br>
从mysql server获取binlog和字段信息，组装成json流。建议先阅读 <a href="http://xgknight.com/2018/01/13/maxwell-binlog/">http://xgknight.com/2018/01/13/maxwell-binlog/</a><br>
官网：http://maxwells-daemon.io/</p>
</li>
<li>
<p>graylog<br>
代替ELK技术栈的日志收集、处理、展示平台。社区版够用，需要自行安装，也可以把 graylog 换成 ELK stack。<br>
官网：https://www.graylog.org/</p>
</li>
<li>
<p>nxlog<br>
nxlog 是用 C 语言写的一个开源日志收集处理软件，它是一个模块化、多线程、高性能的日志管理解决方案，支持多平台。<br>
参考：http://blog.csdn.net/weixin_29477879/article/details/52183746</p>
</li>
<li>
<p>rabbitmq<br>
一款开源消息队列中间件，采用Erlang语言开发，RabbitMQ是AMQP(Advanced Message Queueing Protocol)的标准实现。建议先阅读 <a href="http://xgknight.com/2018/01/06/rabbitmq-introduce/">http://xgknight.com/2018/01/06/rabbitmq-introduce/</a> 。<br>
你也可以把消息队列换成kafka。</p>
</li>
</ul>
<p><img loading="lazy" src="http://github.com/seanlook/sean-notes-comment/raw/main/static/maxwell-graylog.png" alt="maxwell-graylog.png"  />
</p>
<h2 id="2-使用说明">2. 使用说明<a hidden class="anchor" aria-hidden="true" href="#2-使用说明">#</a></h2>
<h3 id="21-举例">2.1 举例<a hidden class="anchor" aria-hidden="true" href="#21-举例">#</a></h3>
<blockquote>
<p>查看 some3 库 2018-01-22 13:00:00 ~ 2018-01-22 13:00:00 之间，表 t_ecsome_detail 的binlog变化，graylog根据AMQP协议从rabbitmq取binlog json流</p>
</blockquote>
<p>提前创建一个 Swarm容器集群，名字叫 maxwell。<br>
<img loading="lazy" src="http://github.com/seanlook/sean-notes-comment/raw/main/static/compose-template.png" alt="compose-template.png"  />
</p>
<p>在【编排模板】里选择 <em>maxwell-graylog-rabbitmq</em>，【创建应用】下一步修改编排模板：
（只修改 environment 里面的变量值）</p>
<pre tabindex="0"><code>mysql-binlogsvr:
  image: registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3
  volumes:
    - maxwellgraylog_db_data:/var/lib/mysql
  environment:
    DBINSTANCE_ID: rm-bp19t9it7c2998633
    START_TIME: &#39;2018-01-22 13:00:00&#39;
    END_TIME: &#39;2018-01-22 14:00:00&#39;
    ACCESS_ID: LTAIXKHm0v6ob5P4
    ACCESS_SECRET: F7g***************Nll19no
    MYSQL_ROOT_PASSWORD: strongpassword

maxwell-svr:
  image: registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_graylog:1.1.3
  depends_on:
    - mysql-binlogsvr
  environment:
    producer: rabbitmq
    MYSQL_HOST:
    MYSQL_USER:
    MYSQL_PASSWORD:
    MYSQL_HOST_GIT: db_some_shard3
    include_dbs:
    include_tables: t_ecsome_detail
    include_column_values:
    init_position:
    rabbitmq_host: 10.81.xx.xxx
    rabbitmq_virtual_host: /maxwell
    rabbitmq_user: admin
    rabbitmq_pass: admin
    kafka_server:
    kafka_producer_partition_by: database
    MAXWELL_OPTS:
  volumes:
    - maxwellgraylog_db_data:/var/lib/mysql
  links:
    - mysql-binlogsvr:mysql_binlogsvr
</code></pre><h3 id="22-变量参数说明">2.2 变量/参数说明：<a hidden class="anchor" aria-hidden="true" href="#22-变量参数说明">#</a></h3>
<ul>
<li><code>DBINSTANCE_ID</code><br>
需要分析哪个实例的binlog。必须提供</li>
<li><code>ACCESS_ID</code>, <code>ACCESS_SECRET</code><br>
从OSS下载该实例binlog的key，这个key的用户需要RDS的读权限。必须提供</li>
<li><code>START_TIME</code>, <code>END_TIME</code><br>
需要分析 binlog 大致位于哪个时间段。请尽可能的精确，如果时间范围过大，可能耗时非常久。3个binlog入完graylog大约6分钟。不能保持示例默认的值<br>
如果你想从 <code>MYSQL_HOST</code> 直接在线拉取binlog，则不要设置设置 START_TIME 和 END_TIME，程序会一致从当前位置持续读取。</li>
<li><code>MYSQL_ROOT_PASSWORD</code><br>
mysql binlogsvr 的root的密码。默认为 strongpassword</li>
</ul>
<!-- raw HTML omitted -->
<ul>
<li><code>producer</code><br>
指定maxwell产生的binlog json流输出到哪里，完整的支持<code>file</code>, <code>rabbitmq</code>, <code>kafka</code></li>
<li><code>MYSQL_HOST</code>, <code>MYSQL_USER</code>, <code>MYSQL_PASSWORD</code><br>
它在两种情况下使用：
<ol>
<li>前面的<code>START_TIME</code>、<code>END_TIME</code>留空，这里的 MYSQL_HOST 代表的是maxwell直接连接的地址，持续获取binlog。maxwell的 schema_database 也在这个库上(monitor，用户需要有读写这个db的权限)</li>
<li>前面的<code>START_TIME</code>、<code>END_TIME</code>有值，并且没有设置 <code>MYSQL_HOST_GIT</code>，那么 MYSQL_HOST 代表的是从这个地址拉取表结构，相当于maxwell的 schema_host 地址（当然获取binlog还是从 mysql_binlogsvr ）</li>
</ol>
</li>
<li><code>MYSQL_HOST_GIT</code>, <code>MYSQL_HOST_GIT_COMMIT</code><br>
从git仓库拉取表结构信息，<code>MYSQL_HOST_GIT</code>指定仓库里面实例目录名，<code>MYSQL_HOST_GIT_COMMIT</code>可以满足指定某个 提交 时候的表机构版本。在 START_TIME, END_TIME 有设置的情况下才有效。<br>
仓库见：http://xgknight.com/2016/11/28/mysql-schema-gather-structure/</li>
<li><code>rabbitmq_host</code>, <code>rabbitmq_virtual_host</code>, <code>rabbitmq_user</code>, <code>rabbitmq_pass</code>, <code>rabbitmq_exchange_type</code><br>
在 producer=rabbitmq 才有效。这些rabbitmq_xxx选项，与maxwell配置文件里面的完全相同</li>
<li>过滤选项<br>
<code>include_dbs</code>, <code>include_tables</code>, <code>include_column_values</code><br>
与maxwell配置文件里面的完全相同。这里没有列出 exclude_xxx 相关过滤项，如果要指定，请使用 <code>MAXWELL_OPTS</code><br>
<code>exclude_columns</code>，去除哪些列是值不予展示，可用于脱敏。<br>
支持的值参考maxwell的配置文件里面正则说明。</li>
<li><code>kafka_server</code><br>
在 rabbitmq=kafka 时有效。对应 maxwell 的 <code>kafka.bootstrap.servers</code> 选项<br>
其它选项如果要指定，可以使用<code>MAXWELL_OPTS</code></li>
<li><code>MAXWELL_OPTS</code><br>
因为现有 environment 变量没有覆盖所有的maxwell选项，所有其它选项可以直接像 maxwell 命令行参数一样，指定在 <code>MAXWELL_OPTS</code> 里面。</li>
</ul>
<p>创建完后，可以看到两个容器：<br>
<img loading="lazy" src="http://github.com/seanlook/sean-notes-comment/raw/main/static/maxwell-binlog-container.png" alt="maxwell-binlog-container.png"  />
</p>
<p>其中 <code>maxwell-svr</code> 在等待 mysql_binlogsvr 就绪:</p>
<pre tabindex="0"><code>maxwell-graylog-rabbitmq-some3_maxwell-svr_1 | 2018-01-26T11:58:08.424411112Z waiting for mysql_binlogsvr prepared
maxwell-graylog-rabbitmq-some3_maxwell-svr_1 | 2018-01-26T11:58:28.427993770Z waiting for mysql_binlogsvr prepared
maxwell-graylog-rabbitmq-some3_maxwell-svr_1 | 2018-01-26T11:58:48.431136523Z binlog download is done, wait more seconds for mysql_binlogsvr ready
</code></pre><p><code>mysql-binlogsvr</code> 在初始化 mysql server 的数据，下载binlog。完成的标志是在 <code>/var/lib/mysql/initialized.lock</code>里面写入 1 或 2，来通知 maxwell-svr。（1和2的意义见下面的Dockerfile说明）
在 <code>maxwell-svr</code> 日志里面看到 <code>INFO  BinlogConnectorLifecycleListener - Binlog connected.</code> 字样，表示已经在binlog往外推。</p>
<p>此时在 graylog 里面就可以看到输出内容了: <a href="http://graylog.workec.com:3003/search?q=gl2_source_input%3A5a655c3ba002a0526615062a&amp;relative=0">http://graylog.workec.com:3003/search?q=gl2_source_input%3A5a655c3ba002a0526615062a&amp;relative=0</a></p>
<p>处理速度大概在 10000msg/s，在graylog里面没有看到新数据进来，就代表分析完成。
现在比较麻烦的地方在于，处理完结束后，销毁容器容易，但前面创建的持久存储卷，阿里云的容器服务并不会删除本地的卷，它所提供的存储推荐是 OSS,NAS,云盘 这些存储服务，然后要为它单独创建子账号，单独对某个盘、bucket授权，十分麻烦。</p>
<p>本地卷并不能自动的删除，如果下次启动这个binlog分析服务，因为挂在的是同样的 db_data，里面已经有脏数据，所以需要<strong>手动删除</strong> 主机上的 <code>rm -rf /var/lib/docker/volumes/maxwellgraylog_db_data/_data/*</code></p>
<h3 id="23-其它编排模板">2.3 其它编排模板<a hidden class="anchor" aria-hidden="true" href="#23-其它编排模板">#</a></h3>
<p>上面的示例，是基于 <code>maxwell-graylog-rabbitmq</code> 的编排模板，已经自定义了一下compose模板：</p>
<ul>
<li>
<p><code>maxwell-graylog-rabbitmq</code><br>
依赖于外部 rabbitmq server，需要明确指定 <code>rabbitmq_host</code> 等信息。<br>
第一次使用，通过<code>rabbitmq-init-for-maxwell.sh</code>去初始化 maxwell-graylog 所需要的exchange,queue等。</p>
</li>
<li>
<p><code>maxwell-graylog-rabbitmq-nodeps</code><br>
会比上面的多起一个容器： rabbitmq-server，但是它的数据要通过容器集群的LB，才能被外面的graylog服务消费。
它的 <code>rabbitmq_host</code>被指定为<code>maxwell-rabbitmq-server</code> (container link)</p>
</li>
<li>
<p><code>maxwell-graylog-file</code><br>
不适用消息队列，直接写入文件，通过 nxlog 将数据推到 graylog，所以会多出一个 nxlog 容器
多出三个 environment variabeles:</p>
<ul>
<li><code>graylogserver</code><br>
nxlog将“日志”上报的 graylog server 地址</li>
<li><code>graylog_maxwell_gelf_port</code><br>
graylog 节点为接收这个消息监听的端口 (NXlog Outputs)</li>
<li><code>graylog_maxwell_source_collector</code><br>
graylog 为这个消息定义好的collecter名字 （collecter是graylog的入口，在它之上定义流转、拆解、存储等流程）</li>
</ul>
<p>graylog的配置方法和搜索使用，见后文。</p>
</li>
<li>
<p><code>maxwell-graylog-kafka</code><br>
使用 kafka 作为消息队列。需要指定现有的 kafka_server 。<br>
这个编排模板，没有提供很详细的实现，请结合 <code>MAXWELL_OPTS</code> 使用。</p>
</li>
</ul>
<p><strong>提示：</strong></p>
<ol>
<li>在使用时，如果容器启动失败，观察日志后，一般可以放心的直接重启容器，已做良好的修复处理。</li>
<li>选择哪个模板和设置什么变量值，主要考虑两个因素：从哪里获取binlog，maxwell将binlog生产到哪里</li>
<li>输出到file，nxlog读取的交给graylog处理的压力会非常大，可能会导致graylog响应慢。输出到rabbitmq，可以控制流入graylog的速度(Allow throttling this input?)</li>
</ol>
<h3 id="24-docker-composeyml">2.4 docker-compose.yml<a hidden class="anchor" aria-hidden="true" href="#24-docker-composeyml">#</a></h3>
<p>阿里云的编排模板，与标准的 docker compose 并不完全一样。在 docker-compose 目录中，提供了6种编排方案，可使用自建的docker平台来做。
4个容器和变量的组合，应对不同的场景：</p>
<ul>
<li>
<p><strong>docker-compose.file.yml</strong><br>
启动 mysql-binlogsvr, maxwell-svr, nxlog-svr 三个容器，binlog数据写入file。</p>
</li>
<li>
<p><strong>docker-compose.file-schema.yml</strong><br>
启动 mysql-binlogsvr, maxwell-svr, nxlog-svr 三个容器，binlog数据写入file。<br>
表结构从 schema_host 获取，而不是git仓库。monitor用户需要 REPLICATION SLAVE, REPLICATION CLIENT 权限。</p>
</li>
<li>
<p><strong>docker-compose.rabbitmq.yml</strong><br>
启动 mysql-binlogsvr, maxwell-svr 两个容器，binlog数据写入现有rabbitmq。</p>
</li>
<li>
<p><strong>docker-compose.rabbitmq-nodeps.yml</strong><br>
启动 mysql-binlogsvr, maxwell-svr, rabbitmq-server 三个容器，binlog数据写入rabbitmq容器。<br>
不依赖外部rabbitmq。</p>
</li>
<li>
<p><strong>docker-compose.rabbitmq-nobinlog-svr.yml</strong><br>
启动 mysql-binlogsvr, maxwell-svr, rabbitmq-server 三个容器，binlog数据写入rabbitmq容器。<br>
mysql-binlogsvr启动后会停止，这里直接从 MYSQL_HOST 在线持续拉取binlog，用户需要能够读取表结构的权限。</p>
</li>
<li>
<p><strong>docker-compose.kafka.yml</strong><br>
启动 mysql-binlogsvr, maxwell-svr 两个容器，binlog数据写入现有kafka。</p>
</li>
</ul>
<p>也可以逐个启动容器，不适用 docker-compose.yml。各个容器详情见后文。</p>
<h2 id="3-graylog配置和使用">3. graylog配置和使用<a hidden class="anchor" aria-hidden="true" href="#3-graylog配置和使用">#</a></h2>
<p>生成的binlog json流要在graylog里面可视化展示，还需要对graylog设置。下面分别以 file 和 rabbitmq 的输出为例。</p>
<h3 id="31-input-file">3.1 Input: file<a hidden class="anchor" aria-hidden="true" href="#31-input-file">#</a></h3>
<p>上面已经通过 maxwell容器 将数据写入了 <code>output_file</code>=<code>/var/lib/mysql/maxwell_binlog_stream.json.log</code>，又通过 nxlog容器 tail监控这个日志文件。</p>
<ol>
<li><strong>创建一个 GELF TCP Input</strong>
[System / Inputs] -&gt; [Inputs]<br>
<img loading="lazy" src="http://github.com/seanlook/sean-notes-comment/raw/main/static/graylog-fileinput.png" alt="graylog-fileinput.png"  />
</li>
</ol>
<p><img loading="lazy" src="http://github.com/seanlook/sean-notes-comment/raw/main/static/graylog-fileinput-create.png" alt="graylog-fileinput-create.png"  />
</p>
<p>勾选 Global 表示所有的 graylog 集群节点，都可以接收这个日志，Port： <code>12201</code> 便是监听的端口。前文编排模板里面要求提供的参数 <code>graylogserver</code> 和 <code>graylog_maxwell_gelf_port</code>，就是从这来的。</p>
<p>那么 Collecter <code>graylog_maxwell_source_collector</code> 呢，可以任意设置一个字符串。在标准的 graylog 配置流程里面，collecter 就是一个 nxlog 进程，一般一台机器就一个 nxlog，所以collecter对应的其实是收集日志的机器。</p>
<p>nxlog 是一个单独的组件，与graylog没多大关系，而为了将两者整合在一起，需要 graylog-sidecar 来下发 nxlog 的配置，告诉它日志目录在哪、怎么读取日志。</p>
<p>所以我们的docker容器只需要nxlog进程，不需要graylog-sidecar来交代配置，也就不需要在graylog Web界面配置NXLog Outputs/Inputs，而是直接通过变量传递来完成 nxlog.conf 模板的配置。</p>
<p>下面的过程实际是不需要的，只是为了理解如何生成 nxlog.conf。</p>
<ol start="2">
<li>Create configuration
给这个 configuration 设置 <code>tags</code> 例如<code>maxwell_binlog</code>。<br>
<img loading="lazy" src="http://github.com/seanlook/sean-notes-comment/raw/main/static/graylog-nxlog-config.png" alt="graylog-nxlog-config.png"  />
</li>
</ol>
<p>graylog-sidecar 会把 tag 打给某个机器(collecter)，告诉nxlog或其他收集组件，当前机器有哪几种日志需要收集</p>
<ol start="3">
<li>
<p>编写 NXLog Outputs
相当于 nxlog.conf 中 <code>&lt;Output&gt;</code>部分，Host、Port 即第1步里面的graylog接收binlog json流而监听的地址和端口。
Type选择 <code>[NXLog]GELF TCP output</code>。<br>
<img loading="lazy" src="http://github.com/seanlook/sean-notes-comment/raw/main/static/graylog-nxlog-output.png" alt="graylog-nxlog-output.png"  />
</p>
</li>
<li>
<p>编写 NXLog Inputs
相当于 nxlog.conf 中 <code>&lt;Input&gt;</code>部分，这里指定日志输入来源于<strong>文件</strong>,<code>Type</code>选择<code>[NXLog]file input</code><br>
<img loading="lazy" src="http://github.com/seanlook/sean-notes-comment/raw/main/static/graylog-nxlog-input.png" alt="graylog-nxlog-input.png"  />
</p>
</li>
</ol>
<p><code>Forward to</code> 设置刚才创建的 Output
<code>File</code>，要收集的日志路径为<code>/var/lib/mysql/maxwell_binlog_stream.json.log</code>
<code>Pool Interval</code>，即检查日志文件的间隔时间。剩下的保持默认</p>
<ol start="5">
<li><strong>使用 JSON extractor 解析message</strong>
经过上面几步，启动maxwell和nxlog服务/容器之后，在graylog的 WebUI 上找到第1步建的Input，就可以看到有日志进来了。<br>
<img loading="lazy" src="http://github.com/seanlook/sean-notes-comment/raw/main/static/maxwell-graylog-message.png" alt="maxwell-graylog-message.png"  />
</li>
</ol>
<p>选择任意一个message，[Create extractor for field message] -&gt; [JSON]，将json数据解压出来，存储，便可以快速根据字段名来搜索binlog内容。</p>
<h3 id="32-input-rabbitmq">3.2 Input: rabbitmq<a hidden class="anchor" aria-hidden="true" href="#32-input-rabbitmq">#</a></h3>
<p>使用rabbitmq更简单，不需要nxlog，直接在第1步里，把新建<code>GELF TCP</code>改成<code>Raw/Plaintext AMQP</code>。<br>
<img loading="lazy" src="http://github.com/seanlook/sean-notes-comment/raw/main/static/maxwell-graylog-rabbitmq.png" alt="maxwell-graylog-rabbitmq.png"  />
</p>
<p>需要填写的就是AMQP协议里broker, port, user, exchange, queue, routing_key。
就可以在binlog里面，可视化看到binlog内容了。</p>
<h3 id="33-在graylog里面搜索binlog日志">3.3 在graylog里面搜索binlog日志<a hidden class="anchor" aria-hidden="true" href="#33-在graylog里面搜索binlog日志">#</a></h3>
<p>搜索语法：http://docs.graylog.org/en/2.4/pages/queries.html</p>
<p>例如，查看 t_ecsome_detail 表中 f_some_id=1242036566 在给定时间内的变化过程：</p>
<pre tabindex="0"><code>gl2_source_input:5a38cc9bd56c001305aaefc0 AND data_f_some_id: 1242036566 OR old_f_some_id: 1242036566
</code></pre><p>例如使用Quick values功能，快速得到全国各地区对t_ecsome_detail表的操作量：</p>
<pre tabindex="0"><code>gl2_source_input:5a38cc9bd56c001305aaefc0 AND NOT data_f_company_region: 0
</code></pre><p>我们有做db分库，查看各个分库下的请求量数据是不是平均的，database: quick value：<br>
<img loading="lazy" src="http://github.com/seanlook/sean-notes-comment/raw/main/static/maxwell-graylog-quickvalue.png" alt="maxwell-graylog-quickvalue.png"  />
</p>
<h2 id="4-容器镜像说明dockerfile">4. 容器镜像说明：Dockerfile<a hidden class="anchor" aria-hidden="true" href="#4-容器镜像说明dockerfile">#</a></h2>
<p>本节是关于细节实现的部分，与上面的介绍会略有重复。</p>
<h3 id="41-dockerfilebinlogsvr">4.1 Dockerfile.binlogsvr<a hidden class="anchor" aria-hidden="true" href="#41-dockerfilebinlogsvr">#</a></h3>
<p>承载 binlog 的mysql server服务。<br>
它首先根据提供的数据库实例信息、日期时间信息，去OSS拉取已经上传的binlog到本地，修改 <code>mysql-bin.index</code>文件，提供binlog来源。<br>
因为容器停止或者销毁后，内部的数据也随之丢失，所以需要一个主机上的目录来挂在到容器中，做数据的持久化，我们把这个数据卷命名为 db_data 。</p>
<ul>
<li>
<p><code>binlogsvr-entrypoint.sh</code><br>
容器入口。因为 mysql server 启动第一次都要进行初始化，假如容器启动失败，再次启动时不需要再次初始化。<br>
脚本内通过 <code>lockfile=/var/lib/mysql/initialized.lock</code> 区分三种工作模式：</p>
<ul>
<li>lockfile 存在：mysql server 已经初始化</li>
<li>lockfile 内容为0：mysql server 作为binlogsvr</li>
<li>lockfile 内容为2: binlog已经下载完成。避免重启容器导致重复下载binlog</li>
<li>lockfile 内容为1：该容器无用，因为判断 START_TIME 和 END_TIME 为空。实际上表示后续maxwell  拉取，是直接从原 MYSQL_HOST 读取，不需要该binlogsvr<br>
lockfile 里面的值会被 maxwell 容器读取，以便决定工作模式</li>
</ul>
</li>
<li>
<p><code>download_binlog.py</code><br>
从阿里OSS下载binlog，需要提供 DBINSTANCE_ID 和 时间界限。<br>
requirements.txt：python环境依赖</p>
</li>
<li>
<p><code>mysql_3306.cnf</code><br>
binlogsvr的启动配置文件</p>
</li>
</ul>
<h3 id="42-dockerfilemaxwell">4.2 Dockerfile.maxwell<a hidden class="anchor" aria-hidden="true" href="#42-dockerfilemaxwell">#</a></h3>
<p>maxwell服务容器，主版本1.12.0，加上修改了点内容：https://github.com/seanlook/maxwell</p>
<ul>
<li>
<p><code>maxwell-entrypoint.sh</code><br>
容器入口。会等待 mysql_binlogsvr 初始化完成，maxwell的结构、postion等信息存放在binlogsvr的 monitor 库。</p>
<ul>
<li><code>work_mode=1</code>: 直接从 <code>MYSQL_HOST</code> 拉取binlog，不需要binlogsvr，可以实现持续读取现网的binlog</li>
<li><code>work_mode=0</code>: 从 mysql_binlogsvr 拉取binlog<br>
该模式下因为 binlogsvr 里并没有maxwell需要的表结构，支持两种方法：
<ul>
<li>如果设置了 <code>MYSQL_HOST_GIT</code>，表示从我们的git仓库里面拉取表结构</li>
<li>否则从 <code>MYSQL_HOST</code> 拉取表结构，对应maxwell变量 <code>schema_host</code> 。即这个时候的 MYSQL_HOST 不是指定binlog来源，而是表结构来源。</li>
<li>如果都没设置，异常退出</li>
</ul>
</li>
</ul>
<p>maxwell启动时需要指定 init_position，即从binlog_svr哪个binlog位置开始拉取：</p>
<ul>
<li>如果从直接从原数据库实例拉取，则指定为最新的binlog起始点；</li>
<li>如果为 binlogsvr 拉取，则指定为下载的binlog最小的那个binlog起始点；</li>
<li>在容器启动的时候，也可以直接指定 init_postion ，优先生效。<br>
<code>lockfile=/var/lib/mysql/initialized_maxwell.lock</code> 表示已经通过 init_postion 启动，如果重启maxwell容器，应该从上次停止的地方继续。</li>
</ul>
<p>容器启动时，可以指定 producer 为 file, rabbitmq, kafka，根据对应的生产者，应该设置子选项。见后文。</p>
</li>
<li>
<p><code>maxwell-retrive-tablemeta.sh</code><br>
从git拉取所需要的表结构，并用 myloader 工具导入到 binlogsvr 。<br>
因为考虑到需求通常要过滤表，所以这里也这会在 binlogsvr 创建需要的表结构。<br>
如果指定了 <code>MYSQL_HOST_GIT_COMMIT</code>，可以拉取git上历史表结构。<br>
<code>id_rsa</code>：文件是拉起表结构用的 ssh key。</p>
</li>
<li>
<p><code>maxwell-src-1.12.0.tar.gz</code>:<br>
已下载的maxwell包，会通过maven编译。</p>
</li>
</ul>
<h3 id="43-dockerfilenxlog">4.3 Dockerfile.nxlog<a hidden class="anchor" aria-hidden="true" href="#43-dockerfilenxlog">#</a></h3>
<p>在 <code>producer=file</code> 时，maxwell产生的binlog stream 是文件，要把文件放到 graylog 用到 nxlog 。<br>
它也会挂在 db_data，读取 <code>output_file=/var/lib/mysql/maxwell_binlog_stream.json.log</code> 内容，发送到 graylog server 。</p>
<ul>
<li>
<p><code>graylogserver</code>: graylog server 地址</p>
</li>
<li>
<p><code>graylog_maxwell_gelf_port</code>: 在graylog提前配置好的接收maxwell数据的端口</p>
</li>
<li>
<p><code>graylog_maxwell_source_collector</code>: 对应graylog的 collector id.<br>
配置graylog 方法见后文。</p>
</li>
<li>
<p><code>nxlog-entrypoint.sh</code><br>
容器入口。主要是对 /etc/nxlog/nxlog.conf 进行变量替换。<br>
提示：也会读取 <code>/var/lib/mysql/maxwell_instance_id</code> 里面由 mysql_binlogsvr 传递过来的 instance_id 作为 message 的一部分</p>
</li>
<li>
<p><code>nxlog.conf</code><br>
nxlog的配置文件模板，用于替换成上面的变量。</p>
</li>
</ul>
<h3 id="44-dockerfilerabbitmq">4.4 Dockerfile.rabbitmq<a hidden class="anchor" aria-hidden="true" href="#44-dockerfilerabbitmq">#</a></h3>
<p>在 <code>producer=rabbitmq</code> 时，maxwell需要 rabbitmq server 作为队列。<br>
这里提供两种使用方法：</p>
<ul>
<li>
<p>如果已经有现成的 rabbitmq ，则自己创建 vhost, exchange, user，需要提供的内容见 <code>rabbitmq-init-formaxwell.sh</code></p>
</li>
<li>
<p>如果没有rabbitmq，则通过这个 Dockerfile 创建 rabbitmq server container</p>
</li>
<li>
<p><code>rabbitmq-entrypoint.sh</code><br>
容器入口。只是为了调用 <code>rabbitmq-init-formaxwell.sh</code>，在rabbitmq起来后，创建 <code>--vhost=/maxwell --username=admin --password=admin</code>,<code>exchange=maxwell.binlog queue=maxwell_binlog binding_key=#</code> 给maxwell和graylog使用。<br>
在后台通过 <a href="https://github.com/vishnubob/wait-for-it"><code>wait-for-it.sh</code></a> 来同步等待 rabbitmq ok.</p>
</li>
</ul>
<h3 id="45-build-image">4.5 build image<a hidden class="anchor" aria-hidden="true" href="#45-build-image">#</a></h3>
<pre tabindex="0"><code>docker build -f Dockerfile.binlogsvr . -t registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3
docker build -f Dockerfile.maxwell . -t registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_graylog:1.1.3
docker build -f Dockerfile.nxlog . -t registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_nxlog:0.4.3
docker build -f Dockerfile.rabbitmq . -t registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_rabbitmq:0.4.3

docker push registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3
docker push registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_graylog:1.1.3
docker push registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_nxlog:0.4.3
docker push registry-vpc.cn-hangzhou.aliyuncs.com/workec/maxwell_rabbitmq:0.4.3
</code></pre><p><strong>参考</strong></p>
<hr>
<p>原文连接地址：http://xgknight.com/2018/01/25/maxwell-graylog/</p>
<hr>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://xgknight.com/tags/mysql/">mysql</a></li>
      <li><a href="http://xgknight.com/tags/binlog/">binlog</a></li>
    </ul>
  </footer><script src="https://utteranc.es/client.js"
        repo="seanlook/sean-notes-comment"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="http://xgknight.com/">Sean Note</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
