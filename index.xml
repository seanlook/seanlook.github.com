<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Sean Note</title>
    <link>http://xgknight.com/</link>
    <description>Recent content on Sean Note</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 22 Mar 2018 21:32:49 +0000</lastBuildDate><atom:link href="http://xgknight.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MySQL复制与数据一致性 分享</title>
      <link>http://xgknight.com/posts/2018/03/mysql%E5%A4%8D%E5%88%B6%E4%B8%8E%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7-%E5%88%86%E4%BA%AB/</link>
      <pubDate>Thu, 22 Mar 2018 21:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2018/03/mysql%E5%A4%8D%E5%88%B6%E4%B8%8E%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7-%E5%88%86%E4%BA%AB/</guid>
      <description>这是针对公司内部的一个分享，主题是去年10月份就想好的，中间因为一些项目，也包括自己的拖延症，ppt一直没准备好。
在临近快要辞职的时候，还是想兑现一下承诺，加班加点完成了。
分享的内容包括：
binlog介绍 我们有不少项目依赖于binlog同步数据，所以对binlog的格式以及内部结构进行了简单介绍
innodb事务的提交过程 主要是两阶段提交的一些概念和原理，与下面的组提交原理一起，方便后面对崩溃恢复机制的理解
组提交 着重介绍组提交的概念，以及它的实现。为下面的并行复制做铺垫
介绍MySQL复制流程 种类包括异步复制、半同步复制、增强半同步复制和并行复制，顺便结束了复制延迟常见的原因
基于上面的原理，介绍主库、从库分别在异常宕机的情况下，如何保证数据一致的
高可用类型 这部分由于时间的关系，没有准备，并且本身也是一个很大课题，所以干脆就去掉了
演示稿中穿插了一些思考题，感兴趣的朋友不妨思考思考。
{% pdf http://github.com/seanlook/sean-notes-comment/raw/main/static/mysql-replication-and-consistency.pdf 1000 800 %}
原文连接地址：http://xgknight.com/2018/03/22/mysql-ppt-replication-and-consistency/</description>
    </item>
    
    <item>
      <title>MySQL分页优化</title>
      <link>http://xgknight.com/posts/2018/03/mysql%E5%88%86%E9%A1%B5%E4%BC%98%E5%8C%96/</link>
      <pubDate>Wed, 21 Mar 2018 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2018/03/mysql%E5%88%86%E9%A1%B5%E4%BC%98%E5%8C%96/</guid>
      <description>关于数据库分页查询的话题，网上谈论的很多，但开发人员在使用上还是习惯以往的思路。
比如我们有个电话记录表：
CREATE TABLE `t_tel_record` ( `f_id` bigint(20) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;流水号&amp;#39;, `f_qiye_id` bigint(20) NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;企业&amp;#39;, `f_callno` varchar(20) DEFAULT NULL COMMENT &amp;#39;主叫号码&amp;#39;, `f_calltono` varchar(30) DEFAULT NULL COMMENT &amp;#39;被叫号码&amp;#39;, `f_Starttime` datetime NOT NULL COMMENT &amp;#39;开始时间&amp;#39;, `f_Endtime` datetime DEFAULT NULL COMMENT &amp;#39;结束时间&amp;#39;, `f_Calltime` mediumint(8) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;通话时间&amp;#39;, `f_user_id` bigint(20) NOT NULL COMMENT &amp;#39;员工用户&amp;#39;, `f_path` varchar(200) DEFAULT NULL COMMENT &amp;#39;语音文件路径&amp;#39;, `f_crm_id` bigint(20) NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;客户库id&amp;#39;, `f_call_type` tinyint(4) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;0:未知，1:为呼入类型，2:呼出类型&amp;#39;, PRIMARY KEY (`f_id`), KEY `idx_endtime_userid` (`f_Endtime`,`f_user_id`,`f_qiye_id`), KEY `idx_crmid` (`f_crm_id`), KEY `idx_qiye_user_calltime` (`f_qiye_id`,`f_Starttime`), KEY `idx_calltono` (`f_calltono`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 查询第1页的数据： SELECT * FROM t_tel_record WHERE f_qiye_id=xxx ORDER BY f_Starttime DESC LIMIT 0,100 当数据量很大，需要查询第10000页的数据： SELECT * FROM t_tel_record WHERE f_qiye_id=xxx ORDER BY f_Starttime DESC LIMIT 999900,100 -- 或者 OFFSET 999900 LIMIT 100 MySQL的 limit m,n 工作原理就是先读取符合where条件的前面m+n条记录，然后抛弃前m条，返回后面n条，所以m越大，偏移量越大，性能就越差。这也是大部分ORM框架生成的分页sql。</description>
    </item>
    
    <item>
      <title>MySQL主从复制idempotent模式以及同步错误处理预案</title>
      <link>http://xgknight.com/posts/2018/03/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6idempotent%E6%A8%A1%E5%BC%8F%E4%BB%A5%E5%8F%8A%E5%90%8C%E6%AD%A5%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86%E9%A2%84%E6%A1%88/</link>
      <pubDate>Sun, 11 Mar 2018 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2018/03/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6idempotent%E6%A8%A1%E5%BC%8F%E4%BB%A5%E5%8F%8A%E5%90%8C%E6%AD%A5%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86%E9%A2%84%E6%A1%88/</guid>
      <description>1. slave_exec_mode 参数作用 slave_exec_mode 可以在主从复制中遇到 duplicate-key 和 no-key-found 错误时，自动覆盖或者略过binlog里面这个row_event，避免报错停止复制。
这个参数原本是解决像 NDB Cluster 多节点写入冲突的情况，也可以在普通主从、双主、环形复制等情况下解决冲突，保持幂等性。幂等性怎么定义，感兴趣的可以阅读The differences between IDEMPOTENT and AUTO-REPAIR mode）。
set global slave_exec_mode=IDEMPOTENT （可以动态修改）使从库运行在 幂等模式，对1062，1032等不同的错误类型，有不同的处理：
write_row event 遇到主键冲突或唯一索引冲突，这一行被覆写(delete + insert)。 delete时候不是full value match，仅需要主键或唯一索引找到记录则删除 delete_row event 遇到记录不存在，忽略这一行 update_row event 修改唯一索引导致的冲突，忽略这一行 注意：
idempotent 模式都是对有疑问的行进行replace或ignore，不影响其它row。 idempotent 模式要求表上必须要有主键 binlog必须是 FULL RBR 模式 2. slave-skip-errors 这个参数不能在线修改，只能加到配置文件里面或者启动的时候带上--slave-skip-errors=1032,1062。除非你真的理解它skip掉了什么，否则不建议使用。
讲一个我所遇到的坑。在我们的一个分库项目中，需要把一个database里面的数据拆成32份，于是做了个主从，把从库里面不需要的那份删除，但复制过来肯定会报 HA_ERR_KEY_NOT_FOUND 错误，于是这也是所期望的，就设置了--slave-skip-errors=1032。
但接下来就出现 1062:HA_ERR_FOUND_DUPP_KEY 错误！从库只会删数据，不会写入和更新，怎么会出现重复数据？读者不妨试想一下为什么。
这里做个说明：
① insert into t values (1, &amp;#39;a&amp;#39;), (2, &amp;#39;b&amp;#39;), (3, &amp;#39;c&amp;#39;); ② begin; ③ delete from t where id=1; ④ delete from t where id in (1, 2, 3); ⑤ insert into t where (3, &amp;#39;c&amp;#39;), (4, &amp;#39;d&amp;#39;), (5, &amp;#39;e&amp;#39;); ⑥ update t set .</description>
    </item>
    
    <item>
      <title>Binlog可视化搜索：实现类似阿里RDS数据追踪功能</title>
      <link>http://xgknight.com/posts/2018/01/binlog%E5%8F%AF%E8%A7%86%E5%8C%96%E6%90%9C%E7%B4%A2%E5%AE%9E%E7%8E%B0%E7%B1%BB%E4%BC%BC%E9%98%BF%E9%87%8Crds%E6%95%B0%E6%8D%AE%E8%BF%BD%E8%B8%AA%E5%8A%9F%E8%83%BD/</link>
      <pubDate>Thu, 25 Jan 2018 15:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2018/01/binlog%E5%8F%AF%E8%A7%86%E5%8C%96%E6%90%9C%E7%B4%A2%E5%AE%9E%E7%8E%B0%E7%B1%BB%E4%BC%BC%E9%98%BF%E9%87%8Crds%E6%95%B0%E6%8D%AE%E8%BF%BD%E8%B8%AA%E5%8A%9F%E8%83%BD/</guid>
      <description>MySQL Binlog 里面记录了每行数据的变更，开发有时候需要根据这些变更的时间、中间值去查问题，是bug导致的，还是用户操作引发的。然而原始binlog内容不利于检索，有段时间使用阿里RDS企业版DMS数据追踪的功能，也能完成这个工作，甚至生成回滚sql，后由于收费以及容量不够的缘故，放弃不用。
本文所介绍的就是基于外面开源的各类组件，整合起来，达到类似数据追踪的功能 —— binlog 可视化。 功能类似：10分钟搭建MySQL Binlog分析+可视化方案
1. 主要技术 项目地址： https://github.com/seanlook/maxwell-graylog
docker
使用容器来实现资源的申请和释放，毕竟这类检索binlog内容的需求不多。 本文基于阿里云的容器服务。
maxwell
从mysql server获取binlog和字段信息，组装成json流。建议先阅读 http://xgknight.com/2018/01/13/maxwell-binlog/
官网：http://maxwells-daemon.io/
graylog
代替ELK技术栈的日志收集、处理、展示平台。社区版够用，需要自行安装，也可以把 graylog 换成 ELK stack。
官网：https://www.graylog.org/
nxlog
nxlog 是用 C 语言写的一个开源日志收集处理软件，它是一个模块化、多线程、高性能的日志管理解决方案，支持多平台。
参考：http://blog.csdn.net/weixin_29477879/article/details/52183746
rabbitmq
一款开源消息队列中间件，采用Erlang语言开发，RabbitMQ是AMQP(Advanced Message Queueing Protocol)的标准实现。建议先阅读 http://xgknight.com/2018/01/06/rabbitmq-introduce/ 。
你也可以把消息队列换成kafka。
2. 使用说明 2.1 举例 查看 some3 库 2018-01-22 13:00:00 ~ 2018-01-22 13:00:00 之间，表 t_ecsome_detail 的binlog变化，graylog根据AMQP协议从rabbitmq取binlog json流
提前创建一个 Swarm容器集群，名字叫 maxwell。
在【编排模板】里选择 maxwell-graylog-rabbitmq，【创建应用】下一步修改编排模板： （只修改 environment 里面的变量值）
mysql-binlogsvr: image: registry-vpc.cn-hangzhou.aliyuncs.com/workec/mysql_binlogsvr:1.1.3 volumes: - maxwellgraylog_db_data:/var/lib/mysql environment: DBINSTANCE_ID: rm-bp19t9it7c2998633 START_TIME: &amp;#39;2018-01-22 13:00:00&amp;#39; END_TIME: &amp;#39;2018-01-22 14:00:00&amp;#39; ACCESS_ID: LTAIXKHm0v6ob5P4 ACCESS_SECRET: F7g***************Nll19no MYSQL_ROOT_PASSWORD: strongpassword maxwell-svr: image: registry-vpc.</description>
    </item>
    
    <item>
      <title>基于MySQL binlog增量数据同步方案(maxwell&#43;rabbimt&#43;pydbsync)</title>
      <link>http://xgknight.com/posts/2018/01/%E5%9F%BA%E4%BA%8Emysql-binlog%E5%A2%9E%E9%87%8F%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88maxwell-rabbimt-pydbsync/</link>
      <pubDate>Sun, 14 Jan 2018 15:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2018/01/%E5%9F%BA%E4%BA%8Emysql-binlog%E5%A2%9E%E9%87%8F%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%96%B9%E6%A1%88maxwell-rabbimt-pydbsync/</guid>
      <description>应用场景：同 http://xgknight.com/2017/09/05/mysql-binlog-subscribe-simple-for-dba/ ，但更灵活：
实时同步部分表到另外一个数据库实例 比如在数据库迁库时，将当天表的数据同步到新库，模拟阿里云dms数据传输的功能，相当于在测试环境演练，减少失误。 另外还可以从新库反向同步增量数据到老库，解决测试环境多项目测试引起数据库冲突的问题。
正式切库时的回滚措施 比如数据库迁移项目，切换期间数据写向新库，但如果切换失败需要回滚到老库，就需要把这段时间新增的数据同步回老库（启动消费程序），这就不需要程序段再考虑复杂的回滚设计。
数据库闪回 关于数据库误操作的闪回方案，见 文章MySQL根据离线binlog快速闪回 。binlog2sql的 -B 选项可以将sql反向组装，生产回滚sql。如果需要完善的闪回功能，要进一步开发，提高易用性。
binlog搜索功能 目前组内一版的binlog搜索功能，是离线任务处理的方式，好处是不会占用太大空间，缺点是处理时间较长。通过实时binlog解析过滤的方式，入ES可以快速搜索。需要进一步开发完善。 结合graylog可以实现阿里云RDS类似的数据追踪功能。见 http://xgknight.com/2018/01/25/maxwell-graylog/
rabbitmq介绍：http://xgknight.com/2018/01/06/rabbitmq-introduce/
maxwell介绍：http://xgknight.com/2018/01/13/maxwell-binlog/
数据已经生成，要完成 MySQL binlog 增量数据同步，还差一个消费者程序，将rabbitmq里面的消息取出来，在目标库重放：
** https://github.com/seanlook/pydbsync ** 目前这个增量程序重放动作是：
binlog里面 insert 和 update 行，都变成 replace into binlog里面 delele ，变成 delete ignore xxx limit 1 alter/create，原封不动 所以如果表上没有主键或者唯一索引，是非常难搞定的，原本的update变成 replace into 多插入一条数据。当然如果把 update 事件改成 update tables set f1=v1,f2=v2 where f1=v1,f2=vv2 limit 1 也没毛病。
使用python3，安装rabbitmq 的python客户端即可：pip install pika
config.py
增量程序的配置文件
db_info: 指定要写入的目标db rabbitmq_conn_info: 增量数据的来源，rabbitmq连接信息 rabbitmq_queue_bind: 指定怎么划分队列</description>
    </item>
    
    <item>
      <title>自建Binlog订阅服务 —— Maxwell</title>
      <link>http://xgknight.com/posts/2018/01/%E8%87%AA%E5%BB%BAbinlog%E8%AE%A2%E9%98%85%E6%9C%8D%E5%8A%A1-maxwell/</link>
      <pubDate>Sat, 13 Jan 2018 15:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2018/01/%E8%87%AA%E5%BB%BAbinlog%E8%AE%A2%E9%98%85%E6%9C%8D%E5%8A%A1-maxwell/</guid>
      <description>1. 介绍 Maxwell 是java语言编写的能够读取、解析MySQL binlog，将行更新以json格式发送到 Kafka、RabbitMQ、AWS Kinesis、Google Cloud Pub/Sub、文件，有了增量的数据流，可以想象的应用场景实在太多了，如ETL、维护缓存、收集表级别的dml指标、增量到搜索引擎、数据分区迁移、切库binlog回滚方案，等等。
它还提供其它功能：
支持SELECT * FROM table 的方式做全量数据初始化 支持主库发生failover后，自动恢复binlog位置（GTID） 灵活的对数据进行分区，解决数据倾斜的问题。kafka支持 database, table, column等级别的数据分区 它的实现方式是伪装成MySQL Server的从库，接收binlog events，然后根据schemas信息拼装，支持ddl,xid,rows等各种event. maxwell由 zendesk 开源：https://github.com/zendesk/maxwell ，而且维护者相当活跃。
网上已有人对 Alibaba Cannal, Zendesk Maxwell, Yelp mysql_streamer进行对比，见文后参考 实时抓取MySQL的更新数据到Hadoop。
类似功能的还有：http://debezium.io/docs/connectors/mysql/
安装 使用 maxwell 非常简单，只需要jdk环境
yum install -y java-1.8.0-openjdk-1.8.0.121-1.b13.el6.x86_64 curl -sLo - https://github.com/zendesk/maxwell/releases/download/v1.12.0/maxwell-1.12.0.tar.gz \ | tar zxvf - cd maxwell-1.12.0 # 默认寻找当前目录下的 config.properties 配置文件 要求 mysql server binlog格式是 ROW， row_image 是 FULL。感受一下输出结果
mysql&amp;gt; update test.e set m = 5.</description>
    </item>
    
    <item>
      <title>RabbitMQ 入门</title>
      <link>http://xgknight.com/posts/2018/01/rabbitmq-%E5%85%A5%E9%97%A8/</link>
      <pubDate>Sat, 06 Jan 2018 15:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2018/01/rabbitmq-%E5%85%A5%E9%97%A8/</guid>
      <description>rabbitmq可以用一本书取讲，这里只是介绍一些使用过程中，常用到的基本的知识点。 官方文档覆盖的内容，非常全面：http://www.rabbitmq.com/documentation.html 。
1. 介绍 RabbitMQ，即消息队列系统，它是一款开源消息队列中间件，采用Erlang语言开发，RabbitMQ是AMQP(Advanced Message Queueing Protocol)的标准实现。
AMQP是一个公开发布的异步消息的规范，是提供统一消息服务的应用层标准高级消息队列协议，为面向消息的中间件设计.消息中间件主要用于组件之间的解耦，消息的发送者无需知道消息使用者的存在，反之亦然。
https://www.rabbitmq.com/tutorials/amqp-concepts.html
相对于JMS(Java Message Service)规范来说，JMS使用的是特定语言的APIs，而消息格式可自由定义，而AMQP对消息的格式和传输是有要求的，但实现不会受操作系统、开发语言以及平台等的限制。
JMS和AMQP还有一个较大的区别：JMS有队列(Queues)和主题(Topics)两种消息传递模型，发送到 JMS队列 的消息最多只能被一个Client消费，发送到 JMS主题 的消息可能会被多个Clients消费；AMQP只有队列(Queues)，队列的消息只能被单个接受者消费，发送者并不直接把消息发送到队列中，而是发送到Exchange中，该Exchage会与一个或多个队列绑定，能够实现与JMS队列和主题同样的功能。
另外还有一种 MQTT协议，意为消息队列遥测传输，是IBM开发的一个即时通讯协议。由于其维护一个长连接以轻量级低消耗著称，所以常用于移动端消息推送服务开发。MQTT是基于TCP的应用层协议封装，实现了异步Pub/Sub，在物联网（IoT）应用广泛。
RabbitMQ可通过库、插件的形式，支持JMS和MQTT协议。参考：http://geek.csdn.net/news/detail/71894
1.1 主要概念 Broker
接收和分发消息的应用，RabbitMQ Server就是Message Broker
Exchange
message到达broker的第一站，根据分发规则，匹配查询表中的routing key，分发消息到queue中去。常用的类型有：direct, topic, fanout。
如果没有队列绑定到exchange上，那么该exchange上的消息都会被丢弃，因为它不存储消息又不知道该怎么处理消息。
Queue
消息队列载体，每个消息都会被投入到一个或多个队列
Binding
在exchange和queue之间建立关系就叫Binding，消费者声明队列的时候一般会指定routing_key，也可以叫binding_key。Binding信息被保存到exchange中的查询表中，用于message的分发依据。
Routing Key
这里区分一下binding和routing: binding是一个将exchange和queue关联起来的动作，routing_key可以理解成队列的一个属性，表示这个队列接受符合该routing_key的消息，routing_key需要在发送消息的时候指定。
Vhost
于多租户和安全因素设计的，把AMQP的基本组件划分到一个虚拟的分组中，类似于网络中的namespace概念。当多个不同的用户使用同一个RabbitMQ server提供的服务时，可以划分出多个vhost，每个用户在自己的vhost创建exchange／queue等
Producer
消息生产者，就是投递消息的程序。只负责把消息发送exchange，附带一些消息属性。
Consumer
消息消费者，就是接受消息的程序。
Channel
如果每一次访问RabbitMQ都建立一个Connection，在消息量大的时候建立TCP Connection的开销将是巨大的，效率也较低。
Channel是在connection内部建立的逻辑连接，如果应用程序支持多线程，通常每个thread创建单独的channel进行通讯，AMQP method包含了channel id帮助客户端和message broker识别channel，所以channel之间是完全隔离的。Channel作为轻量级的Connection极大减少了操作系统建立TCP connection的开销。
1.2 对比 rabbitmq activemq rocketmq kafka zeromq redis
celery 待续
2. 安装配置 CentOS 6.</description>
    </item>
    
    <item>
      <title>MySQL数据库表结构同步之SchemaSync</title>
      <link>http://xgknight.com/posts/2017/11/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E7%BB%93%E6%9E%84%E5%90%8C%E6%AD%A5%E4%B9%8Bschemasync/</link>
      <pubDate>Thu, 02 Nov 2017 15:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/11/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E7%BB%93%E6%9E%84%E5%90%8C%E6%AD%A5%E4%B9%8Bschemasync/</guid>
      <description>SchemaSync是个能够在mysql数据库之间，比较并生成表结构差异的工具，项目地址 https://github.com/mmatuson/SchemaSync 。
SchemaSync介绍与使用 因为工作中经常需要在各个环境之间同步表结构，特别是生产与测试环境之间，长时间的运行后，总会有不一致的。测试环境的表结构一般是测试验证功能之后没有问题，然后通过工单的形式由DBA在生产环境修改。但生产库的结构，如修改索引，紧急修改字段长度，久而久之就会与测试环境有差异，需要同步到测试环境。
又或者有多套测试环境之间要保持结构同步，又比如同一类db（分库）的情况下，比较schema之间的对象差异。
SchemaSync不仅限于表结构，它可以处理的对象还有：视图、事件、存储过程、函数、触发器、外键，与 mysql-utilities 相当。但 SchemaSync 更适合于实践：
默认不会同步 AUTO_INCREMENT 和 COMMENT`，有选项可以控制 对不存在的对象会生成对应的CREATE，对多余的对象会生成DROP 对生成 alter&amp;hellip;column 的sql，是有列顺序的 安装简单，相比mysqldiff，要安装mysql-connector-python和一整套mysql-utilities工具 当然前两点在我自己的 mysqldiff 版本里，已经加入了支持，见 MySQL数据库表结构同步之mysqldiff
SchemaSync安装：
（使用virtualenv） $ pip install mysql-python pymysql schemaobject schemasync SchemaObject也是同一个作者的，专门用于操作数据库对象的库，于是schemasync只需要获取对象，比较差异，然后调用schemaobect生成sql。（SchemaObject依赖pymysql，SchemaSync依赖MySQLdb，其实可以用同一个）
SchemaSync用法：
$ schemasync --help Usage: schemasync [options] &amp;lt;source&amp;gt; &amp;lt;target&amp;gt; source/target format: mysql://user:pass@host:port/database A MySQL Schema Synchronization Utility Options: -h, --help show this help message and exit -V, --version show version and exit. -r, --revision increment the migration script version number if a file with the same name already exists.</description>
    </item>
    
    <item>
      <title>MySQL order by limit 走错索引(range-&gt;indexscan)</title>
      <link>http://xgknight.com/posts/2017/10/mysql-order-by-limit-%E8%B5%B0%E9%94%99%E7%B4%A2%E5%BC%95range-indexscan/</link>
      <pubDate>Thu, 26 Oct 2017 15:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/10/mysql-order-by-limit-%E8%B5%B0%E9%94%99%E7%B4%A2%E5%BC%95range-indexscan/</guid>
      <description>生产库遇到过好几例本文要讨论的案例，而且比较棘手。简而言之，有类似这样的查询 SELECT * FROM t1 where t1.f2&amp;gt;1 and t2.f2&amp;lt;100 order by t1.id，id是主键，条件里面有个range查询，就会造成优化器是选择主键，还是选择filesort问题，有些特殊情况就会选错索引，比如为了回避内存排序，选择了主键扫描，导致原本走范围过滤再sort 500ms勉强可以结束的查询，5分钟不出结果。
下面具体来这个案例。
1. 背景 阿里云RDS，5.6.16-log。 表 d_ec_someextend.t_tbl_test_time_08:
CREATE TABLE `t_tbl_test_time_08` ( `f_some_id` int(11) unsigned DEFAULT &amp;#39;0&amp;#39;, `f_qiye_id` int(11) DEFAULT &amp;#39;0&amp;#39;, `f_type` tinyint(3) DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;有效联系类型 1: QQ联系，2:拨打电话，3:发送邮件，4:发送短信，5:添加跟进记录，6:拜访客户，7:EC联系，8:更新客户阶段&amp;#39;, `f_contact_time` timestamp NULL DEFAULT &amp;#39;1970-01-01 16:00:01&amp;#39;, UNIQUE KEY `some_qiye_type` (`f_some_id`,`f_qiye_id`,`f_type`), KEY `f_contact_time` (`f_contact_time`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 表索引信息：
mysql&amp;gt; show table status like &amp;#34;t_tbl_test_time_08&amp;#34;; +-----------------------+--------+---------+------------+----------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+-------------+------------+--------------------+----------+----------------+---------+--------------+ | Name | Engine | Version | Row_format | Rows | Avg_row_length | Data_length | Max_data_length | Index_length | Data_free | Auto_increment | Create_time | Update_time | Check_time | Collation | Checksum | Create_options | Comment | Block_format | +-----------------------+--------+---------+------------+----------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+-------------+------------+--------------------+----------+----------------+---------+--------------+ | t_tbl_test_time_08 | InnoDB | 10 | Compact | 19264318 | 45 | 882900992 | 0 | 2176843776 | 752877568 | NULL | 2017-10-25 20:27:08 | NULL | NULL | utf8mb4_general_ci | NULL | | | Original | +-----------------------+--------+---------+------------+----------+----------------+-------------+-----------------+--------------+-----------+----------------+---------------------+-------------+------------+--------------------+----------+----------------+---------+--------------+ 1 row in set mysql&amp;gt; show index from t_tbl_test_time_08; +--------------------+------------+-----------------+--------------+----------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | +--------------------+------------+-----------------+--------------+----------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ | t_tbl_test_time_08 | 0 | some_qiye_type | 1 | f_some_id | A | 19264318 | NULL | NULL | YES | BTREE | | | | t_tbl_test_time_08 | 0 | some_qiye_type | 2 | f_qiye_id | A | 19264318 | NULL | NULL | YES | BTREE | | | | t_tbl_test_time_08 | 0 | some_qiye_type | 3 | f_type | A | 19264318 | NULL | NULL | YES | BTREE | | | | t_tbl_test_time_08 | 1 | f_contact_time | 1 | f_contact_time | A | 9632159 | NULL | NULL | YES | BTREE | | | +--------------------+------------+-----------------+--------------+----------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ 4 rows in set 问题查询：</description>
    </item>
    
    <item>
      <title>“大”事务引起的锁等待分析案例</title>
      <link>http://xgknight.com/posts/2017/10/%E5%A4%A7%E4%BA%8B%E5%8A%A1%E5%BC%95%E8%B5%B7%E7%9A%84%E9%94%81%E7%AD%89%E5%BE%85%E5%88%86%E6%9E%90%E6%A1%88%E4%BE%8B/</link>
      <pubDate>Tue, 17 Oct 2017 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/10/%E5%A4%A7%E4%BA%8B%E5%8A%A1%E5%BC%95%E8%B5%B7%E7%9A%84%E9%94%81%E7%AD%89%E5%BE%85%E5%88%86%E6%9E%90%E6%A1%88%E4%BE%8B/</guid>
      <description>1. 现象 生产环境数据库在某一刻突然发现大量活跃连接，而且大部分状态是 updating 。问题出现在周六上午，持续了大概三四分钟，得益于我们自己的快照程序，拿到了当时现场的的processlist, 锁等待关系，innodb status 信息：(经过脱敏处理)
innodb_status.txt片段： var_mydb_snapshot.html （也可以通过 pt-stalk 收集）
首先在 Lock Waits Info 一节，看到每行的trx_id(事务)的role分为 Blocker(引起阻塞的线程) 与 Blockee（被阻塞者）；最后一列 blocking_trx_id 在role是Blockee时才有值，代表谁阻塞了当前事务。 根据上面的关系，可以得出以下结论：
事务 19705811640 运行了231s，阻塞了19706118937、19706124453、19706124752，而这些事务都在做同一个UPDATE语句 被锁定的记录是 mydb.mytable1表的主键索引值为 5317885 行 事务 19706124752 既被阻塞，也阻塞了别人19706125253 不难发现 19705811640 应该最先运行的事务，且对其它事务产生了链式阻塞，它的thread_id是 9898630，来源IP 但是当你兴冲冲的找到引起阻塞的事务 19705811640 在做什么事情时，发现它没有任何sql的信息，lock info以及processlist里面都是None。那么有哪些情况会导致在会话是活跃的，但sql的内容为空：
执行show processlist的时候，刚好在事务里面两个sql的中间 sql已经执行完成，但长时间没有提交 2. 初步分析 其实这个现象已经遇到过很多次了，第1个原因常发生在 大量单条记录更新 的情况，一个sql在一个事务里循环执行10000次，即使每条都很快，但大部分时间都在网络传输上，（可以改成批量的形式）。在本案例基本上能确定的是第2个原因：事务开启之后，sql也执行了，但中间又做别的事情去了。那么怎样才能知道这个事务是什么内容呢？两个方向去找：
从来源ip上的应用程序的日志里分析 binlog里面分析 应用程序日志里可以看 10:21:00 ~ 10:26:00 之间，mydb.mytable1 表上主键id=5317885 在做什么事情。因为我们上了听云，在听云APM里面也可以清楚的看到这个时间点的哪个方法慢： 响应时间230多秒，从“相关SQL”里面看到操作的记录内容，确定就是它了(根据innodb status快照时间 - ACTIVE 230.874 sec，倒推得到的时间与这里刚好吻合)。从接口名称也清楚的知道是在进行禁用用户的操作，猜想： 禁用用户的逻辑上有先挪到回收站，再删资料、删权限、删关系，清理缓存等等一系列操作，放在事务里保证他们的原子性，似乎是合理的。但为什么执行了将近4分钟还没有提交呢，分析相关的sql效率都很高。
有三种情况：
这个事务执行到一半，它需要操作的数据被别人锁住，等待了这么久 类似事务要操作5000条数据，但是一条一条的操作，然后一起提交（已出现过类似的例子） 事务务执行完成很快，但调用其它接口迟迟没有返回，导致事务没提交。 不会是1和2，因为从一开始的分析看到事务 19705811640 都是在阻塞别人，而不是受害者。那么结合上图中有个有两个操作redis的接口执行时间占比96%，可以下定论了：</description>
    </item>
    
    <item>
      <title>table_open_cache 与 table_definition_cache 对MySQL(内存)的影响</title>
      <link>http://xgknight.com/posts/2017/10/table_open_cache-%E4%B8%8E-table_definition_cache-%E5%AF%B9mysql%E5%86%85%E5%AD%98%E7%9A%84%E5%BD%B1%E5%93%8D/</link>
      <pubDate>Fri, 13 Oct 2017 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/10/table_open_cache-%E4%B8%8E-table_definition_cache-%E5%AF%B9mysql%E5%86%85%E5%AD%98%E7%9A%84%E5%BD%B1%E5%93%8D/</guid>
      <description>1. 现象，内存使用大 首先说一下最近遇到的一个现象，因为分库的缘故，单实例里面的表的数量增加了20倍，总数将近达到10000个。在开发环境明显感觉到执行简单查询都很慢，在processlist里面看到状态 opening table 达到好几秒但数据库并没有什么负载。本能的想到应该要加大 table_open_cache，可是加大后发现MySQL刚启动 RES 就占用了2.5G内存，之前才500-600M的样子。
只是将 table_open_cache 从默认的2000，增加到10000（先不论这个值合不合理），就独占了2G的内存，这对于生产环境内存浪费是不可接受的。还好，关于这个问题的讨论有不少，感兴趣的话可以阅读 #bug 68287, #bug 68514, 12015-percona-5-6-14-56-very-high-memory-usage。
Oracle官方工程师并不认为这是个bug，导致初始化分配这么多内存的原因是，开启了 Performance_Schema 。P_S测量数据库的性能指标，需要提前一次性分配内存，而不是随着数据库运行逐渐申请内存。
下表是不同参数组合下内存占用的测试结果： （注：可以通过这个来查看PFS里面哪些占内存比较多，mysql -hxxxx -Pxxx -uxx -pxx -e &amp;quot;show engine performance_schema status&amp;quot;|grep memory|sort -nr -k3 |head ）
对于 table_open_cache 设置的非常大的情况下，即使还有许多cache多余，但P_S都需要分配这个数量的内存。解决这个内存大的问题有3个方向：
table_open_cache, table_definition_cache, max_connections 设置合理 关闭 performance_schema 保持 PFS 开启，关闭测量 max_table_instances和max_table_handles performance_schema_max_table_instances: 最大测量多少个表对象
对应 (pfs_table_share).memory，我的环境里固定 277600000 bytes performance_schema_max_table_handles: 最大打开表的总数
对应(pfs_table).memory，随着 table_open_cache 的增大而增大 关闭的方法是在my.cnf里面设置以上变量为 0 。默认是 -1 ，表示 autosize，即根据 table_open_cache/table_def_cache/max_connections 的值自动设置，相关代码 pfs_autosize.cc：
PFS_sizing_data *estimate_hints(PFS_global_param *param) { if ((param-&amp;gt;m_hints.</description>
    </item>
    
    <item>
      <title>MySQL实例阻塞分析一例(线程statistics状态)</title>
      <link>http://xgknight.com/posts/2017/09/mysql%E5%AE%9E%E4%BE%8B%E9%98%BB%E5%A1%9E%E5%88%86%E6%9E%90%E4%B8%80%E4%BE%8B%E7%BA%BF%E7%A8%8Bstatistics%E7%8A%B6%E6%80%81/</link>
      <pubDate>Sat, 23 Sep 2017 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/09/mysql%E5%AE%9E%E4%BE%8B%E9%98%BB%E5%A1%9E%E5%88%86%E6%9E%90%E4%B8%80%E4%BE%8B%E7%BA%BF%E7%A8%8Bstatistics%E7%8A%B6%E6%80%81/</guid>
      <description>1. 现象 某日下午下班后低峰期，现网MySQL一个库突然报出大量慢sql，状态是 statistics，但是过后拿这些sql去执行的时候，实际很快。处于 statistics 状态的线程有个特征：查询的都是视图，但看监控那个时间段并没有明显的update/detele/insert。通过我们的快照程序，去分析当时的 innodb status，发现如下信息：
SEMAPHORES ---------- OS WAIT ARRAY INFO: reservation count 17208994 --Thread 139964610234112 has waited at srv0srv.cc line 2132 for 14.00 seconds the semaphore: X-lock (wait_ex) on RW-latch at 0x1635a00 created in file dict0dict.cc line 900 a writer (thread id 139964610234112) has reserved it in mode wait exclusive number of readers 1, waiters flag 0, lock_word: ffffffffffffffff Last time read locked in file row0purge.cc line 720 Last time write locked in file /home/admin/146_20161018140650857_13830810_code/rpm_workspace/storage/innobase/srv/srv0srv.</description>
    </item>
    
    <item>
      <title>一个简单的数据订阅程序(for DBA)</title>
      <link>http://xgknight.com/posts/2017/09/%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%95%B0%E6%8D%AE%E8%AE%A2%E9%98%85%E7%A8%8B%E5%BA%8Ffor-dba/</link>
      <pubDate>Tue, 05 Sep 2017 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/09/%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E6%95%B0%E6%8D%AE%E8%AE%A2%E9%98%85%E7%A8%8B%E5%BA%8Ffor-dba/</guid>
      <description>本程序基于大众点评github项目 binlog2sql 二次开发而来，可以实现对源库的binlog实时接收，并组装成增量sql。
原项目默认是把sql输出到控制台，二次开发后的版本把sql放入redis队列，根据需要由另一个程序消费到目标库，模拟了一个“从库”。 在测试时--stop-never在qa环境没有作用，添加了在 BinLogStreamReader 实例里面加入 blocking=True 来保证源源不断的接受binlog而不中断。
另外也加入了更改目标库名的功能，比如原库叫d_my1，生成的sql目标库名是 d_my2 。
项目地址：https://github.com/seanlook/binlog2sql
应用场景 目前想到以下应用场景：
实时同步部分表到另外一个数据库实例 比如在数据库迁库时，将当天表的数据同步到新库，模拟阿里云dms数据传输的功能，相当于在测试环境演练，减少失误。 另外还可以从新库反向同步增量数据到老库，解决测试环境多项目测试引起数据库冲突的问题。
正式切库时的回滚措施 比如数据库迁移项目，切换期间数据写向新库，但如果切换失败需要回滚到老库，就需要把这段时间新增的数据同步回老库（启动消费程序），这就不需要程序段再考虑复杂的回滚设计。
数据库闪回 关于数据库误操作的闪回方案，见 文章MySQL根据离线binlog快速闪回 。binlog2sql的 -B 选项可以将sql反向组装，生产回滚sql。如果需要完善的闪回功能，要进一步开发，提高易用性。
binlog搜索功能 目前组内一版的binlog搜索功能，是离线任务处理的方式，好处是不会占用太大空间，缺点是处理时间较长。通过实时binlog解析过滤的方式，入ES可以快速搜索。需要进一步开发完善。
使用方法 安装好python2.7虚拟环境，安装必要模块：pymysql, mysql-replication, redis, rq
pip install -r requirements.txt 注意：pymysqlreplication 库在处理 &amp;lsquo;0000-00-00 00:00:00&amp;rsquo; 时有些不尽人意，可能会导致生产的sql在目标库执行失败，还有对datetime(6)类型有个bug，也对它进行了修复，地址：https://github.com/seanlook/python-mysql-replication 。
准备一个redis用于存放sql队列，在环境变量里面设置redis地址
export REDIS_URL=&amp;#39;redis://localhost:6379&amp;#39; 在主库执行 show master status 得到binlog开始的文件名和postion，然后开始订阅：
binlog2sql原版使用时： $ ~/.pyenv/versions/2.7.10/envs/py2_binlog/bin/python binlog2sql.py -h192.168.1.185 -P3306 -uecuser -pecuser \ -d d_ec_contact --tables t_crm_contact_at \ --start-file=&amp;#39;mysql-bin.000001&amp;#39; --start-datetime=&amp;#39;2017-08-30 12:30:00&amp;#39; --start-position=6529058 \ --stop-never &amp;gt; contact0.</description>
    </item>
    
    <item>
      <title>网易云跟帖迁移评论到disqus</title>
      <link>http://xgknight.com/posts/2017/08/%E7%BD%91%E6%98%93%E4%BA%91%E8%B7%9F%E5%B8%96%E8%BF%81%E7%A7%BB%E8%AF%84%E8%AE%BA%E5%88%B0disqus/</link>
      <pubDate>Tue, 29 Aug 2017 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/08/%E7%BD%91%E6%98%93%E4%BA%91%E8%B7%9F%E5%B8%96%E8%BF%81%E7%A7%BB%E8%AF%84%E8%AE%BA%E5%88%B0disqus/</guid>
      <description>早前折腾博客的时候，在众多评论系统中选择了多说，用了2年结果多说倒闭了，也算是影响了网络上众多的站点。
于是在16年的时候把评论换成了网易云跟帖，以为有网易这个靠山，体验虽然差点但是不会轻易关闭。云跟帖还提供了从多说直接导入的工具，随意旧的评论直接弄过来了。
可谁想不到一年，网易云跟帖也关闭了。
现在不怎么去折腾博客这玩意了，往里面写写东西才是王道，所以就决定直接把评论系统换成国外的 disqus，总不至于国内种种原因关闭了，代价就是要懂得科学上网，考虑博客的受众都是IT同仁，也就只好这样了。
然而被坑了，网上有许多文章和工具可以从多说迁移到disqus，但是几乎没看到从网易云跟帖迁移到disqus，三者导出的评论格式不一样。云跟帖导出的是 json，disqus导入是扩展的Wordpress格式。
在拖了3个月后，找到了从网易云跟帖备份出来的旧评论文件，简单用python转换了一下，现在可以用了。
WXR格式：https://help.disqus.com/customer/portal/articles/472150-custom-xml-import-format
转换代码gist地址：https://gist.coding.net/u/seanlook/c395cda7c5f4421b85efcd898a8fdf21 (comments_convert.py)
云跟帖导出文件命名为 gentie163.py，懒得用python处理，直接修改这个文件的内容为 python 字典定义：
sed -i &amp;#39;s/&amp;#34;url&amp;#34;:&amp;#34;xgknight.com/&amp;#34;url&amp;#34;:&amp;#34;http:\/\/xgknight.com/g&amp;#39; gentie163.py sed -i &amp;#39;s/false/False/g&amp;#39; gentie163.py sed -i &amp;#39;s/:null/:&amp;#34;&amp;#34;/g&amp;#39; gentie163.py sed -i &amp;#39;s/^/comments = /&amp;#39; gentie163.py 字典直接转xml比较容易：http://python3-cookbook.readthedocs.io/zh_CN/latest/c06/p05_turning_dictionary_into_xml.html#
转换后的文件为 data_output.xml:
# python3 comments_convert.py 在这个页面导入：https://seanlook.disqus.com/admin/discussions/import/platform/generic/
可在页面 https://import.disqus.com/ 看到import进度，包括失败信息。（不要重复导入）
说明：
disqus每篇文章有个thread_idendifier，这里处理直接根据文章的时间戳转换来用，不影响 dsq:remote是设置单点登录，没去深究，直接丢弃这个属性了 头像信息丢失(因为sso) 本文链接地址：http://xgknight.com/2017/08/29/blog_migrate_gentie163_disqus/</description>
    </item>
    
    <item>
      <title>MySQL数据库表结构同步之mysqldiff</title>
      <link>http://xgknight.com/posts/2017/08/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E7%BB%93%E6%9E%84%E5%90%8C%E6%AD%A5%E4%B9%8Bmysqldiff/</link>
      <pubDate>Sat, 05 Aug 2017 15:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/08/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E7%BB%93%E6%9E%84%E5%90%8C%E6%AD%A5%E4%B9%8Bmysqldiff/</guid>
      <description>mysqldiff mysql官方有个 mysql-utilities 工具集，其中 mysqldiff 可用于比较两个db之间的表结构。 mysqldiff的语法格式是：
$ mysqldiff --server1=user:pass@host:port:socket --server2=user:pass@host:port:socket db1.object1:db2.object1 db3:db4 这个语法有两个用法：
db1:db2：如果只指定数据库，那么就将两个数据库中互相缺少的对象显示出来，不比较对象里面的差异。这里的对象包括表、存储过程、函数、触发器等。 如果db1与db2名字相同，可以只指定 db1 db1.object1:db2.object1：如果指定了具体表对象，那么就会详细对比两个表的差异，包括表名、字段名、备注、索引、大小写等所有的表相关的对象。
如果两边db和对象名都相同，可以只指定 db1.object1 接下来看一些主要的参数：
--server1：配置server1的连接。 --server2：配置server2的连接。 --character-set：配置连接时用的字符集，如果不显示配置默认使用character_set_client。 --width：配置显示的宽度。 --skip-table-options：保持表的选项不变，即对比的差异里面不包括表名、AUTO_INCREMENT、ENGINE、CHARSET等差异。 -d DIFFTYPE,--difftype=DIFFTYPE：差异的信息显示的方式，有 [unified|context|differ|sql]，默认是unified。如果使用sql，那么就直接生成差异的SQL，这样非常方便。 --changes-for=：修改对象。例如 &amp;ndash;changes-for=server2，那么对比以sever1为主，生成的差异的修改也是针对server2的对象的修改。 --show-reverse：在生成的差异修改里面，同时会包含server2和server1的修改。 --force：完成所有的比较，不会在遇到一个差异之后退出 -vv：便于调试，输出许多信息 -q：quiet模式，关闭多余的信息输出 问题修复与增强 但是试用下来，发现有以下几大问题
对象在一方不存在时，比对结果是 object does not exist，而我们通常需要的是，生产 CREATE/DROP XXX 语句 要比对一个db下面所有的对象（table, view, event, proc, func, trigger），要手动挨个 db1.t1, db2.v2&amp;hellip;，而 db1:db2只是检查对象是否存在，不会自动比较db1与db2下的所有对象 比较时，auto_increment应该忽略，但是 mysqldiff 只提供 --skip-table-options ，忽略全部表选项，包括 auto_increment, engine, charset等等。 严重bug T1: idx1(f1,f2), T2: idx1(f1)，这种索引会生成 ADD INDEX idx(f2) T1: idx2(f1,f2), idx3(f3,f4), T2: idx4(f5)，这种组合索引，有可能生成的会乱序 这两个bug与mysqldiff的设计有关系，个人觉得它把比较和生产差异sql完全分开，复杂化了。它得到差异结果之后，生成sql又从db捞各种元数据来组装，其实从差异diff里面就可以获得组装需要的数据，也不容易出现隐藏的bug。参考实现 https://github.</description>
    </item>
    
    <item>
      <title>ProxySQL PPT分享</title>
      <link>http://xgknight.com/posts/2017/07/proxysql-ppt%E5%88%86%E4%BA%AB/</link>
      <pubDate>Wed, 19 Jul 2017 21:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/07/proxysql-ppt%E5%88%86%E4%BA%AB/</guid>
      <description>前些天在公司内部进行了一次 ProxySQL主题的介绍 《ProxySQL数据库中间件使用实践》，因为proxysql是我调研并引入公司的，有必要跟本组开发同学，进行一个正式的介绍和使用说明，以及我们当前的应用情况。
分享比较偷懒，直接拿来proxysql作者renecannao在 Percona Live Europe 2016 上的PPT，是一个非常全面又具有点睛作用的演示稿了。
{% pdf http://github.com/seanlook/sean-notes-comment/raw/main/static/ProxySQL-Tutorials-PerconaLive.pdf 1000 800 %}
PPT来源：https://www.percona.com/live/17/sessions/proxysql-tutorial
另外一个觉得也还不错：https://www.slideshare.net/MyDBOPS/proxysql-for-mysql
&amp;ndash; 我只是ppt的搬运工
原文连接地址：http://xgknight.com/2017/07/19/proxysql-tutorials-ec/</description>
    </item>
    
    <item>
      <title>ProxySQL之改进patch：记录查询sql完整样例与合并digest多个?</title>
      <link>http://xgknight.com/posts/2017/04/proxysql%E4%B9%8B%E6%94%B9%E8%BF%9Bpatch%E8%AE%B0%E5%BD%95%E6%9F%A5%E8%AF%A2sql%E5%AE%8C%E6%95%B4%E6%A0%B7%E4%BE%8B%E4%B8%8E%E5%90%88%E5%B9%B6digest%E5%A4%9A%E4%B8%AA/</link>
      <pubDate>Thu, 27 Apr 2017 15:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/04/proxysql%E4%B9%8B%E6%94%B9%E8%BF%9Bpatch%E8%AE%B0%E5%BD%95%E6%9F%A5%E8%AF%A2sql%E5%AE%8C%E6%95%B4%E6%A0%B7%E4%BE%8B%E4%B8%8E%E5%90%88%E5%B9%B6digest%E5%A4%9A%E4%B8%AA/</guid>
      <description>近期一直在思考sql上线审核该怎么做，刚好接触到 ProxySQL 这个中间件，内置了一个计算sql指纹的功能，但是没有记录原始的sql语句。当前正有个紧急的拆库项目也希望知道库上所有的查询。于是把ProxySQL的代码下了回来研究了几天，改了把，加入了两个功能：
在 stats_mysql_query_digest 表上增加 query_text 字段，当第一次出现这个digest_text时，把原始sql记录下来。 修改计算指纹的模块，对 IN或者 VALUES 后面的多个 ? 合并。这个是目前 c_tokenizer.c 文件里没有做的，用到底1点上可以避免重复记录。 效果： 多个 ? 被折叠成 ?,，有些意外情况时 ??，因为后面一些多余空格的缘故，没有像 pt-fingerprint 那样完全模糊化，像这里digest就保留了大小写、去除重复空格、保留 ` 分隔符。但仅有的几种意外情况是可以接受的。
后面的 query_text 列也有些未知情况，就是末尾会加上一些奇怪的字符，还在排除，但大体不影响需求。
代码是基于最新 v1.3.6 稳定版修改的，查看变更 https://github.com/sysown/proxysql/compare/v1.3.6...seanlook:v1.3.7-querysample_digest
多个 ? 合并只涉及到 c_tokenizer.c 文件，分别在flag=4（处理 &#39;abc&#39;,&#39;def&#39; 的情况）和flag=5（处理 1,2, 3 的情况）加入判断：
// wrap two more ? to one ?, if (*(p_r_t-2) == &amp;#39;?&amp;#39; &amp;amp;&amp;amp; (*(p_r_t-1) ==&amp;#39; &amp;#39; || *(p_r_t-1) == &amp;#39;,&amp;#39; || *(p_r_t-1) == &amp;#39;?&amp;#39;)){ *(p_r-1) = &amp;#39;,&amp;#39;; } else *p_r++ = &amp;#39;?</description>
    </item>
    
    <item>
      <title>ProxySQL之性能测试对比</title>
      <link>http://xgknight.com/posts/2017/04/proxysql%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%AF%B9%E6%AF%94/</link>
      <pubDate>Thu, 20 Apr 2017 21:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/04/proxysql%E4%B9%8B%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%AF%B9%E6%AF%94/</guid>
      <description>本文会通过sysbench对ProxySQL进行基准测试，并与直连的性能进行对比。与此同时也对 Maxscale 和 Qihu360 Atlas 放在一起参考。 提示：压测前确保把query cache完全关掉。
1. proxysql vs 直连 1.1 select nontrx ./bin/sysbench --test=/root/sysbench2/sysbench/tests/db/oltp.lua --mysql-host=10.0.100.36 --mysql-port=6033 --mysql-user=myuser --mysql-password=mypass \ --mysql-db=db15 --oltp-tables-count=20 --oltp-table-size=5000000 --report-interval=20 --oltp-dist-type=uniform --rand-init=on --max-requests=0 --oltp-test-mode=nontrx --oltp-nontrx-mode=select \ --oltp-read-only=on --oltp-skip-trx=on --max-time=120 --num-threads=2 run num-threads依次加大 2 5 10 20 50 100 200 400 {% iframe http://www.tubiaoxiu.com/p.html?s=106165b0eeca215a&amp;amp;web_mode 900 700 %}
sysbench线程并发数达到10以下，性能损失在30%以上；达到20，性能损失减少到10%左右。看到proxysql承载的并发数越高，性能损失越少；最好的时候在50线程数，相比直连损失5%。
1.2 oltp dml 混合读写测试。proxysql结果图应该与上面相差无几，因为是主要好在计算 query digest 和规则匹配，与select无异，可参考下节的图示。
sysbench 压测命令：
./bin/sysbench --test=/root/sysbench2/sysbench/tests/db/oltp.lua --mysql-host=10.0.100.34 --mysql-port=3306 --mysql-user=myuser --mysql-password=mypass \ --mysql-db=db15 --oltp-tables-count=20 --oltp-table-size=5000000 --report-interval=20 --oltp-dist-type=uniform --rand-init=on --max-requests=0 --oltp-read-only=off --max-time=120 \ --num-threads=2 run num-threads依次加大 2 5 10 16 20 50 100 200 400 分别对PrxoySQL, Maxscale, Atlas, 直连，四种情况做基准测试 2.</description>
    </item>
    
    <item>
      <title>ProxySQL之连接复用（multiplexing）以及相关问题说明</title>
      <link>http://xgknight.com/posts/2017/04/proxysql%E4%B9%8B%E8%BF%9E%E6%8E%A5%E5%A4%8D%E7%94%A8multiplexing%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%E8%AF%B4%E6%98%8E/</link>
      <pubDate>Mon, 17 Apr 2017 21:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/04/proxysql%E4%B9%8B%E8%BF%9E%E6%8E%A5%E5%A4%8D%E7%94%A8multiplexing%E4%BB%A5%E5%8F%8A%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%E8%AF%B4%E6%98%8E/</guid>
      <description>ProxySQL在连接池(persistent connection poll)的基础上，还有一个连接复用的概念 multiplexing connection，官方的wiki里没有很明确的说明，但在作者的一些 blog post 和 issue 里能找到解答： https://github.com/sysown/proxysql/issues/939#issuecomment-287489317
由于SQL可以路由，一个客户端连接上来，可能会到多个 hostgroup 发起连接。复用的意思是，一个后端DB的连接，可以“同时”被多个客户端使用。
传统的连接池，会在客户端断开连接（会话）后，把连接放回到池里。在ProxySQL中，由于连接复用，连接会在sql语句执行结束后，便将连接放回到池里（客户端会话可能并没有断开），这样便可大大提高后端连接的使用效率，而避免前段请求过大导致后端连接数疯长。
但这样做有时候并不安全，比如应用端连接时指定了 set NAMES xxx，然后执行查询，那么由于multiplexing可能导致两个语句发到不同的DB上执行，继而没有按照预期的字符集执行。proxysql考虑到了这种情况：
连接会话里创建了临时表，CREATE TEMPORARY table xxxx... select @开头的变量，如select @@hostname 手动开启了事务，start transaction, commit, rollback等等 连接设置了自己的用户变量，比如set names xxx, set autocommit x, set sql_mode=xxx, set v_uservar=xx等等 第1,2,3点会根据路由规则，会自动禁用multiplex，发到对应hostgroup后，连接未断开之前不会复用到其它客户端。具体是发到主库还是从库，与匹配的规则有关。 issue #941 和 #917 都有提到临时表丢失的问题，可以用不同的rule来避免
下面对上面几点一一说明。
1. 临时表与用户变量（验证 1, 2） 以下注意连接的会话窗口及执行顺序，admin打头的是在proxysql管理接口上执行。
-- [session 1] mysql client proxysql (ecdba@10.0.100.36:6033) [(none)]&amp;gt; select 1; +---+ | 1 | +---+ | 1 | +---+ -- [session 2] proxysql admin cli select * from stats_mysql_processlist; Empty set (0.</description>
    </item>
    
    <item>
      <title>ProxySQL之读写分离与分库路由演示</title>
      <link>http://xgknight.com/posts/2017/04/proxysql%E4%B9%8B%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E4%B8%8E%E5%88%86%E5%BA%93%E8%B7%AF%E7%94%B1%E6%BC%94%E7%A4%BA/</link>
      <pubDate>Mon, 17 Apr 2017 15:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/04/proxysql%E4%B9%8B%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E4%B8%8E%E5%88%86%E5%BA%93%E8%B7%AF%E7%94%B1%E6%BC%94%E7%A4%BA/</guid>
      <description>本文演示使用ProxySQL来完成读写分离和后端分库的一个实际配置过程，安装及配置项介绍见前文 ProxySQL之安装及配置详解。
环境
instance0: 10.0.100.100 (db0,db2,db4,db6) instance1: 10.0.100.101 (db1,db3,db5,db7) instance2: 10.0.100.102 (db2,db6,db10,db14) instance3: 10.0.100.103 (db3,db7,db11,db15) instance0 slave: 192.168.10.4:3316 instance1 slave: 192.168.10.4:3326 instance2 slave: 192.168.10.4:3336 instance3 slave: 192.168.10.4:3346 proxysql node0: 10.0.100.36 现在想达到这样一个目的：客户端应用连接上 proxysql 的ip:port，连接时指定分库db名，执行sql时自动路由到对应的实例、对应的库。考虑下面的部署结构： 任何一个proxysql节点都是对等的，路由请求到后端instance的各个database上。
1. 配置后端DB -- proxysql admin cli insert into mysql_servers(hostgroup_id,hostname,port,weight,weight,comment) values (100, &amp;#39;10.0.100.100&amp;#39;, 3307, 1, &amp;#39;db0,ReadWrite&amp;#39;), (1000, &amp;#39;10.0.100.100&amp;#39;, 3307, 1, &amp;#39;db0,ReadWrite&amp;#39;),(1000, &amp;#39;192.168.10.4&amp;#39;, 3316, 9, &amp;#39;db0,ReadOnly&amp;#39;); insert into mysql_servers(hostgroup_id,hostname,port,weight,weight,comment) values (101, &amp;#39;10.0.100.101&amp;#39;, 3307, 1, &amp;#39;db1,ReadWrite&amp;#39;), (1001, &amp;#39;10.0.100.101&amp;#39;, 3307, 1, &amp;#39;db1,ReadWrite&amp;#39;),(1001, &amp;#39;192.</description>
    </item>
    
    <item>
      <title>ProxySQL之安装及配置详解</title>
      <link>http://xgknight.com/posts/2017/04/proxysql%E4%B9%8B%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</link>
      <pubDate>Mon, 10 Apr 2017 21:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/04/proxysql%E4%B9%8B%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/</guid>
      <description>ProxySQL是一个高性能的MySQL中间件，拥有强大的规则引擎。具有以下特性：
连接池，而且是 multiplexing 主机和用户的最大连接数限制 自动下线后端DB 延迟超过阀值 ping 延迟超过阀值 网络不通或宕机 强大的规则路由引擎 实现读写分离 查询重写 sql流量镜像 支持prepared statement 支持Query Cache 支持负载均衡，与gelera结合自动failover 集这么多优秀特性于一身，那么缺点呢就是项目不够成熟，好在作者一直在及时更新，并且受到 Percona 官方的支持。
1. 安装 从 https://github.com/sysown/proxysql/releases 下载相应的版本。这里我选择 proxysql-1.3.5-1-centos67.x86_64.rpm，也是当前最新稳定版。
yum localinstall proxysql-1.3.5-1-centos67.x86_64.rpm -y 可以马上启动了：
/etc/init.d/proxysql start Starting ProxySQL: DONE! proxysql有个配置文件 /etc/proxysql.cnf，只在第一次启动的时候有用，后续所有的配置修改都是对SQLite数据库操作，并且不会更新到proxysql.cnf文件中。ProxySQL绝大部分配置都可以在线修改，配置存储在 /var/lib/proxysql/proxysql.db 中，后面会介绍它的在线配置的设计方式。
proxysql 启动后会像 mysqld 一样，马上fork一个子进程，真正处理请求，而父进程负责监控子进程运行状况，如果crash了就拉起来。
编译安装 安装高版本 gcc-4.8 # cd /etc/yum.repos.d # wget https://copr.fedoraproject.org/coprs/rhscl/devtoolset-3/repo/epel-6/rhscl-devtoolset-3-epel-6.repo \ -O /etc/yum.repos.d/rhscl-devtoolset-3-epel-6.repo # yum install -y scl-utils policycoreutils-python # yum --disablerepo=&amp;#39;*&amp;#39; --enablerepo=&amp;#39;rhscl-devtoolset-3&amp;#39; install devtoolset-3-gcc devtoolset-3-gcc-c++ devtoolset-3-binutils # yum --enablerepo=testing-devtools-2-centos-6 install devtoolset-3-gcc devtoolset-3-gcc-c++ devtoolset-3-binutils 上一步会把 GCC 安装到以下目录 /opt/rh/devtoolset-3/root/usr/bin 接下来需要修改系统的配置，使默认的 gcc 和 g++ 命令使用的是新安装的版本。启用SCL环境中新版本GCC： # scl enable devtoolset-3 bash 现在查看 g++ 的版本号： # gcc --version 编译安装proxysql # cd proxysql-master # make # make install 2.</description>
    </item>
    
    <item>
      <title>清明闲扯</title>
      <link>http://xgknight.com/posts/2017/04/%E6%B8%85%E6%98%8E%E9%97%B2%E6%89%AF/</link>
      <pubDate>Sun, 02 Apr 2017 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/04/%E6%B8%85%E6%98%8E%E9%97%B2%E6%89%AF/</guid>
      <description>这个清明假期，没有做特意的安排，4月1日晚上的时候冒出个想法——去爬七娘山。后来考虑天太热，便作罢了，正好抽一点时间整理些近来的事情。
** 关于博客 很早在朋友圈看到 多说 要关闭的消息，不久后也收到了邮件。全国第一的评论系统，说倒就倒，到底是没有好的营收模式，看到网上一堆评论说挺惋惜的，但那么多用户评论数据在上面，价值可想而知，不应遭此地步。在2014年刚用 多说 的时候，就感觉到它后台基本上没有人在维护了，自身管理后台都有不少问题，提反馈也没响应。
选择网易云跟帖，把它替换掉了，并把以前的评论数据迁移了过来，就是人和人对不上号，以前那些网友找不到自己的评论，抱歉了。不过能用就行，还是多添点内容，也已经过了纠结样式主题的年纪了。有时候看到后台的评论，或者通过其它途径辛苦找到我的，给我了继续写博的动力。
再一个就是搜索功能，以前用的 swiftype 是在去年的时候，不免费了，只提供企业版。它提供的站内搜索引擎功能，十分强大，也很美观，后台管理能看到许多的分析数据，可是它偏偏就突然收费了，而且298$/m，不能接受。也是秉着能用的原则，装上了 hexo-generator-search 模块。
网站统计，现在是cnzz和百度站长的都在用，看了下每天还是有个400-600的独立访客，想想要整一个稍微过得去的 about 页面了。见这里 http://xgknight.com/about/ 。同时也才最近才加上leancloud访问量显示功能。
噢，对了，新加了个打赏的功能，孰知坚持写博不易，意思意思。 -- updated 2017-04-28 -- 把微信打赏改成了支付宝，这样方便知道对方是谁。
** 关于职业 本职工作呢，是一名 DBA 。上周末听香港MySQL用户组主席 Ivan Ma 讲，他们那么没有很清楚的把职位分为是 MySQL DBA 还是 Oracle DBA，他们许多都是不论什么类型的数据库，包括nosql，都得上。我对自身的定位也是，MySQL可以是看家本领，必须深入理解，熟悉它的周边生态圈，积累优化经验。但是像Redis,Mongo,HBase甚至ES这些都必须要有一定的了解，还有像python/go一两门拿得出手的开发语言。
相继前后有好几位同行通过微博、QQ、微信，找到我，请教些问题。有些可能我也并不能马上明确的回答，但是要么自己做个验证，也能很快有结论，要么提供一些建议、方向，或者一些风险点，总之尽我所能。一对一讨论，是能快速学习和加深理解非常有效的途径。
在叶老师知数堂的优化班里，进去之前自己还是有一定基础的，主要是查一查知识的盲点，认识一些行业内的圈子。所以在群里，基本上不参与无关话题的讨论，偶尔回复技术相关的，再者也真没那个闲工夫。
最近一直在处理一个矛盾——职业与工作。个人花工作时间来学习研究，与外部群体讨论，短时间内在工作上可能看不到效果。我们不像开发人员，开发有项目推动，我们基本上都是问题驱动，为了解决这个问题（无论是具体的，还是平台的，甚至架构的），当我们并没有处理经验的时候，往往需要了解和对比大量资料。但最后能有多少应用在工作中的，很难说。能解决一个问题，叫工作；解决好一个问题，叫职业。同样是解决，而且一般在任期内不会复发，显然后者对个人的投入和收获，都更大。
我们的DBA工作充斥了许多的表结构审核、修改线上业务数据，以及慢sql优化、隐患问题追踪等等，也一直在思考一种好的工具平台，但是这样一个数据库运维体系的建立，前期要投入的精力和时间可想而知，而另一边，日常有源源不断的琐事或者问题要处理，到底何为紧急？虽然现在大部分工作，组内几个人好像都做得过来，但说实在的，人肉运维以及效率，都有许多可以改进的地方。然而就是需要在众多繁琐运维事务中，找个时间把该做的平台先做好。
目前还是在摸索，并有些眉目了，开发工作看来也只能靠自己了……
本文链接地址：http://xgknight.com/2017/04/02/qingming-2017/</description>
    </item>
    
    <item>
      <title>一次艰辛的字符集转换历程 ACMUG分享</title>
      <link>http://xgknight.com/posts/2017/03/%E4%B8%80%E6%AC%A1%E8%89%B0%E8%BE%9B%E7%9A%84%E5%AD%97%E7%AC%A6%E9%9B%86%E8%BD%AC%E6%8D%A2%E5%8E%86%E7%A8%8B-acmug%E5%88%86%E4%BA%AB/</link>
      <pubDate>Mon, 27 Mar 2017 21:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/03/%E4%B8%80%E6%AC%A1%E8%89%B0%E8%BE%9B%E7%9A%84%E5%AD%97%E7%AC%A6%E9%9B%86%E8%BD%AC%E6%8D%A2%E5%8E%86%E7%A8%8B-acmug%E5%88%86%E4%BA%AB/</guid>
      <description>本文的ppt是3月25日在中国MySQL用户组2017深圳活动上，我所做的一个主题分享，关于实际生产使用mysql过程中与字符集有关的一些坑。
这个总结其实自己去年一直也想去做，前后花了2个多月的时间，最后所有库无痛完成迁移转化。在2017年二月中下旬的时候微信上请教周董（去哪儿周彦韦大师）一个问题，因为以前也聊过一些，所以他突然问我要不要在3月份的活动上做个主题分享。当时有点不敢想，毕竟之前2次有关培训都是在公司内部的，而这次对外的分享，且不说台下听众有牛人存在，演讲嘉宾里面可各个都是大师级别的，所以当时没有马上答应。过了两天，偶然想到关于字符集这个经历可以讲一讲，不是为了展示自己有多牛B，只是分享下整个问题的处理经验，放低姿态。列了个提纲发给了周董，10分钟不到周董说定了。向经理请示了下没问题，这下赶着鸭子都得上了……
毕竟第一次公开在这样的场合演讲，说不紧张肯定是假的，所以早早的就在准备ppt，一边回顾，一边画图。上阵前一天晚上还在对演示稿微调，并尽量控制时间。
闲话不多说，PPT奉上：
{% pdf http://github.com/seanlook/sean-notes-comment/raw/main/static/mysql-ppt-charset-conversion-acmug-sean.pdf 1000 800 %}
IT大咖说有录视频：
http://www.itdks.com/dakashuo/detail/700 后来自己复看了一下，没啥大毛病，内容都交代清楚了，就是感觉确实舞台经验，表述上还有待加强。
同时这里是当天的活动掠影，阅读原文可看视频：
ACMUG 2017 Tech Tour 深圳站掠影 http://mp.weixin.qq.com/s/-QNRhnN0kBtLkiWVIUS-QQ 下方是中国MySQL用户组(ACMUG)的公众号，欢迎关注： 原文连接地址：http://xgknight.com/2017/03/27/mysql-ppt-charset-conversion-acmug/</description>
    </item>
    
    <item>
      <title>index merge 引起的死锁分析</title>
      <link>http://xgknight.com/posts/2017/03/index-merge-%E5%BC%95%E8%B5%B7%E7%9A%84%E6%AD%BB%E9%94%81%E5%88%86%E6%9E%90/</link>
      <pubDate>Sat, 11 Mar 2017 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/03/index-merge-%E5%BC%95%E8%B5%B7%E7%9A%84%E6%AD%BB%E9%94%81%E5%88%86%E6%9E%90/</guid>
      <description>&lt;p&gt;在看线上一个 MySQL innodb status 时，发现有死锁信息，而且出现的频率还不低。于是分析了一下，把过程记录下来。&lt;/p&gt;
&lt;h2 id=&#34;1-概要&#34;&gt;1. 概要&lt;/h2&gt;
&lt;p&gt;表结构脱敏处理：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;CREATE TABLE t_mytb1 (
  f_id int(11) unsigned NOT NULL AUTO_INCREMENT,
  f_fid int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39;,
  f_sid int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39;,
  f_mode varchar(32) NOT NULL DEFAULT &amp;#39;&amp;#39;,
  f_read int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39;,
  f_xxx1 int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39;,
  f_xxx2 int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39;,
  f_wx_zone int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39;,
  PRIMARY KEY (f_id),
  KEY idx_sid (f_sid),
  KEY idx_fid (f_fid)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;死锁信息：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;LATEST DETECTED DEADLOCK
------------------------
2017-02-28 13:58:29 7f25a3efd700
*** (1) TRANSACTION:
TRANSACTION 4907718431, ACTIVE 0.010 sec fetching rows
mysql tables in use 3, locked 3
LOCK WAIT 154 lock struct(s), heap size 30248, 10 row lock(s)
LOCK BLOCKING MySQL thread id: 13589250 block 13589247
MySQL thread id 13589247, OS thread handle 0x7f25a17e3700, query id 27061926722 11.xx.52.xx ecweb Searching rows for update
UPDATE `d_db1`.`t_mytb1` SET `f_read` = f_read+1 WHERE (f_fid=91243) AND (f_sid=100) AND (f_mode=&amp;#39;浏览器&amp;#39;)
*** (1) WAITING FOR THIS LOCK TO BE GRANTED:
RECORD LOCKS space id 13288 page no 375 n bits 352 index `PRIMARY` of table `d_db1`.`t_mytb1` trx id 4907718431 lock_mode X locks rec but not gap waiting
Record lock, heap no 245 PHYSICAL RECORD: n_fields 10; compact format; info bits 0
 0: len 4; hex 0000a63b; asc    ;;;
 1: len 6; hex 0001246304a7; asc   $c  ;;
 2: len 7; hex 7f000ac0162428; asc      $(;;
 3: len 4; hex 00016470; asc   dp;;
 4: len 4; hex 00000064; asc    d;;
 5: len 9; hex e6b58fe8a788e599a8; asc          ;;
 6: len 4; hex 0000244f; asc   $O;;
 7: len 4; hex 0000007c; asc    |;;
 8: len 4; hex 00000000; asc     ;;
 9: len 4; hex 00000000; asc     ;;

*** (2) TRANSACTION:
TRANSACTION 4907718435, ACTIVE 0.007 sec fetching rows
mysql tables in use 3, locked 3
154 lock struct(s), heap size 30248, 3 row lock(s)
MySQL thread id 13589250, OS thread handle 0x7f25a3efd700, query id 27061926757 11.xx.104.xxx ecweb Searching rows for update
UPDATE `d_db1`.`t_mytb1` SET `f_read` = f_read+1 WHERE (f_fid=91248) AND (f_sid=100) AND (f_mode=&amp;#39;浏览器&amp;#39;)
*** (2) HOLDS THE LOCK(S):
RECORD LOCKS space id 13288 page no 375 n bits 352 index `PRIMARY` of table `d_db1`.`t_mytb1` trx id 4907718435 lock_mode X locks rec but not gap
Record lock, heap no 245 PHYSICAL RECORD: n_fields 10; compact format; info bits 0
 0: len 4; hex 0000a63b; asc    ;;;  -- 42555
 1: len 6; hex 0001246304a7; asc   $c  ;;  -- 4905436327
 2: len 7; hex 7f000ac0162428; asc      $(;;
 3: len 4; hex 00016470; asc   dp;;  -- 91248
 4: len 4; hex 00000064; asc    d;;  -- 100
 5: len 9; hex e6b58fe8a788e599a8; asc          ;;
 6: len 4; hex 0000244f; asc   $O;;  -- 9295
 7: len 4; hex 0000007c; asc    |;;  -- 124
 8: len 4; hex 00000000; asc     ;;
 9: len 4; hex 00000000; asc     ;;

*** (2) WAITING FOR THIS LOCK TO BE GRANTED:
RECORD LOCKS space id 13288 page no 202 n bits 1272 index `idx_sid` of table `d_db1`.`t_mytb1` trx id 4907718435 lock_mode X locks rec but not gap waiting
Record lock, heap no 705 PHYSICAL RECORD: n_fields 2; compact format; info bits 0
 0: len 4; hex 00000064; asc    d;;  -- 100
 1: len 4; hex 0000a633; asc    3;;  -- 42547

*** WE ROLL BACK TRANSACTION (2)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;乍一看很奇怪，tx1和tx2 两个 UPDATE 各自以 f_fid 为条件更新的记录互不影响才对，即使 91243，91248 两个值有可能出现在同一条数据上（因为f_fid上是二级索引），那顶多也就是个更新锁等待，谁后来谁等待，怎么会出现互相争用对方已持有的锁，被死锁检测机制捕获？&lt;/p&gt;
&lt;p&gt;当然,把 update 语句拿到数据库中 EXPLAIN 一下就可以看出端倪。这里不妨先分析一下输出的锁情况：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;先看 Tx2 (对应trx id 4907718435)&lt;/strong&gt; :&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;RECORD LOCKS space id 13288 page no 375 n bits 352&lt;/code&gt; 告诉我们是表空间id 13288 (可从 &lt;code&gt;information_schema.INNODB_SYS_DATAFILES&lt;/code&gt; 查到对应ibd文件) 即 t_mytb1 表，第 375 号页面的 245 位置的记录被锁，并且是 idx PRIMARY 上的记录锁（注：本实例隔离级别为RC）。 Tx2正持有这把记录锁。
因为是聚集索引，显示了完整记录&lt;/li&gt;
&lt;/ol&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;0: 主键f_id=42555
1: DB_TRX_ID = 4905436327
2: DB_ROLL_PTR指向undo记录的地址
3: f_fid=91248
4: f_sid=100
   ...
&lt;/code&gt;&lt;/pre&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;然而Tx2还在等待一个记录锁（lock_mode X locks rec but not gap waiting），但这把锁来自二级索引 &lt;code&gt;idx_sid&lt;/code&gt; 索引上的记录锁。在 RC 级别下没有GAP lock，行锁除了加在符合条件的二级索引 f_sid=100 上外，还会对主键加record lock。
二级索引值：&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>MySQL根据离线binlog快速“闪回”</title>
      <link>http://xgknight.com/posts/2017/03/mysql%E6%A0%B9%E6%8D%AE%E7%A6%BB%E7%BA%BFbinlog%E5%BF%AB%E9%80%9F%E9%97%AA%E5%9B%9E/</link>
      <pubDate>Fri, 03 Mar 2017 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/03/mysql%E6%A0%B9%E6%8D%AE%E7%A6%BB%E7%BA%BFbinlog%E5%BF%AB%E9%80%9F%E9%97%AA%E5%9B%9E/</guid>
      <description>&lt;p&gt;昨天突然有个客户说误操作，自己删除了大量数据，CTO直接将我拉到一个讨论组里，说要帮他们恢复数据。他们自己挖的坑，打算让开发那边根据业务日志去恢复，被告知只记录的删除主键这样的信息，物理删除，无能为力。&lt;/p&gt;
&lt;p&gt;上服务器看了下记录的日志，发现好几台上面都有被误删的记录输出。阿里RDS虽然可以克隆一个恢复到删除时间点前的实例，但这散落的几万个id找起来费力，还有就是几个表之间关联的数据也要恢复，觉得麻烦。&lt;/p&gt;
&lt;p&gt;想到 MySQL 的闪回方案。以前看过好几篇相关文章，甚至差点自己用python撸一个来解析binlog，反转得到回滚sql，实在没空，这下要急用了。赶紧找了下网上“现成的方案”。&lt;/p&gt;
&lt;p&gt;正文开始&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;MySQL（含阿里RDS）快速闪回可以说是对数据库误操作的后悔药，flashback功能可以将数据库返回到误操作之前。但是即使oracle数据库也只支持短时间内的闪回。&lt;/p&gt;
&lt;p&gt;网上现有开源的MySQL闪回实现，原理都是解析binlog，生成反向sql: (必须为row模式)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对于 delete 操作，生成insert （DELETE_ROWS_EVENT）&lt;/li&gt;
&lt;li&gt;对于 update 操作，交换binlog里面值的顺序 （UPDATE_ROWS_EVENT）&lt;/li&gt;
&lt;li&gt;对于 insert 操作，反向生成delete （WRITE_ROWS_EVENT）&lt;/li&gt;
&lt;li&gt;对于多个event，要逆向生成sql&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;开源实现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/58daojia-dba/mysqlbinlog_flashback&#34;&gt;https://github.com/58daojia-dba/mysqlbinlog_flashback&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/danfengcao/binlog2sql/&#34;&gt;https://github.com/danfengcao/binlog2sql/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上面两种实现方式，都是通过 python-mysql-replication 包，模拟出原库的一个从库，然后 &lt;code&gt;show binary logs&lt;/code&gt; 来获取binlog，发起同步binlog的请求，再解析EVENT。但是阿里云 RDS 的binlog在同步给从库之后，** 很快就被 purge 掉了 &lt;strong&gt;。如果要恢复 ** 昨天&lt;/strong&gt; 的 ** 部分数据 **，两种方案都是拿不到binlog的。也就是闪回的时间有限。&lt;/p&gt;
&lt;p&gt;还有一些比较简单的实现，就是解析 binlog 物理文件，实现回滚，如 &lt;code&gt;binlog-rollback.pl&lt;/code&gt; ，试过，但是速度太慢。&lt;/p&gt;
&lt;p&gt;为了不影响速度，又想使用比较成熟的闪回方案，我们可以这样做：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;借助一个自建的 mysqld 实例，将已purge掉的binlog拷贝到该实例的目录下&lt;/li&gt;
&lt;li&gt;在自建实例里，提前创建好需要恢复的表（结构），因为工具需要连接上来从 &lt;code&gt;information_schema.columns&lt;/code&gt; 获取元数据信息&lt;/li&gt;
&lt;li&gt;拷贝的时候，可以替换掉mysql实例自己的binlog文件名，保持连续&lt;/li&gt;
&lt;li&gt;可能要修改 &lt;code&gt;mysql-bin.index&lt;/code&gt;，确保文件名还能被mysqld识别到&lt;/li&gt;
&lt;li&gt;重启mysql实例，&lt;code&gt;show binary logs&lt;/code&gt; 看一下是否在列表里面&lt;/li&gt;
&lt;li&gt;接下来就可以使用上面任何一种工具，模拟从库，指定一个binlog文件，开始时间，结束时间，得到回滚SQL&lt;/li&gt;
&lt;li&gt;再根据业务逻辑，筛选出需要的sql&lt;/li&gt;
&lt;/ol&gt;</description>
    </item>
    
    <item>
      <title>关于MySQL自增主键的几点问题（下）</title>
      <link>http://xgknight.com/posts/2017/02/%E5%85%B3%E4%BA%8Emysql%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E7%9A%84%E5%87%A0%E7%82%B9%E9%97%AE%E9%A2%98%E4%B8%8B/</link>
      <pubDate>Fri, 17 Feb 2017 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/02/%E5%85%B3%E4%BA%8Emysql%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E7%9A%84%E5%87%A0%E7%82%B9%E9%97%AE%E9%A2%98%E4%B8%8B/</guid>
      <description>AUTO-INC waiting 锁等待 这是生产环境出现的现象，某日下午5点业务高峰期，我们的 慢查询快照抓取程序 报出大量线程阻塞，但是1分钟以后就好了。于是分析了当时的 processlist 和 innodb status 现场记录，发现有大量的 AUTO-INC waiting：
![auto-inc-lock-wait][1]
当时想这是得多大的并发量，才会导致 AUTO_INCREMENT 列的自增id分配出现性能问题，不太愿意相信这个事实（后面就再也没出现过）。了解一番之后（见 关于MySQLz自增主键问题（上篇）），发现这个表级别的 AUTO-INC lock 就不应该在业务中存在，因为 innodb_autoinc_lock_mode为1，普通业务都是 simple inserts，获取自增id是靠内存里维护的一个互斥量（mutex counter）。
问题拿到知数堂优化班上课群里讨论过，也只是猜测是不是慢查询多了导致负载高，或者当时磁盘遇到什么物理故障阿里云那边自动恢复了。再后来怀疑是不是因为插入时带了 auto_increment 列的值（我们有个redis incr实现的自增id服务，虽然这一列有 AAUTO_INCREMENT 定义，但实际已经从发号器取id了），会导致锁的性质会变？
为了弄清这个疑问，特意去看了下mysql源码，发现如果插入的自增值比表当前AUTOINC值要大，是直接update mutex counter：
看源码的时候也打消了另一个疑虑：show engine innodb status 看到的 AUTO-INC 有没有可能不区分 表级自增锁和互斥量计数器 两种自增方案，只是告诉你自增id获取忙不过来？ 实际不是的，代码里面有明确的定义是 autoinc_lock还是autoinc_mutex：
// dict0dict.cc : #ifndef UNIV_HOTBACKUP /********************************************************************//** Acquire the autoinc lock. */ UNIV_INTERN void dict_table_autoinc_lock( /*====================*/ dict_table_t*	table)	/*!&amp;lt; in/out: table */ { mutex_enter(&amp;amp;table-&amp;gt;autoinc_mutex); } /********************************************************************//** Unconditionally set the autoinc counter.</description>
    </item>
    
    <item>
      <title>关于MySQL自增主键的几点问题（上）</title>
      <link>http://xgknight.com/posts/2017/02/%E5%85%B3%E4%BA%8Emysql%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E7%9A%84%E5%87%A0%E7%82%B9%E9%97%AE%E9%A2%98%E4%B8%8A/</link>
      <pubDate>Thu, 16 Feb 2017 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2017/02/%E5%85%B3%E4%BA%8Emysql%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE%E7%9A%84%E5%87%A0%E7%82%B9%E9%97%AE%E9%A2%98%E4%B8%8A/</guid>
      <description>前段时间遇到一个InnoDB表自增锁导致的问题，最近刚好有一个同行网友也问到自增锁的疑问，所以抽空系统的总结一下，这两个问题下篇会有阐述。
1. 划分三种插入类型 这里区分一下几种插入数据行的类型，便于后面描述：（纯逻辑上的划分）
&amp;ldquo;Simple inserts&amp;rdquo;
简单插入，就是在处理sql语句的时候，能够提前预估到插入的行数，包括 INSERT / REPLACE 的单行、多行插入，但不含嵌套子查询以及 INSERT ... ON DUPLICATE KEY UPDATE。
&amp;ldquo;Bulk inserts&amp;rdquo;
本文暂且叫做 大块插入，不能提前预知语句要插入的行数，也就无法知道分配多少个自增值，包括 INSERT ... SELECT, REPLACE ... SELECT, 以及 LOAD DATA 导入语句。InnoDB会每处理一行记录就为 AUTO_INCREMENT 列分配一个值。
&amp;ldquo;Mixed-mode inserts&amp;rdquo;
混合插入，比如在 “简单插入” 多行记录的时候，有的新行有指定自增值，有的没有，所以获得最坏情况下需要插入的数量，然后一次性分配足够的auto_increment id。比如:
# c1 是 t1 的 AUTO_INCREMENT 列 INSERT INTO t1 (c1,c2) VALUES (1,&amp;#39;a&amp;#39;), (NULL,&amp;#39;b&amp;#39;), (5,&amp;#39;c&amp;#39;), (NULL,&amp;#39;d&amp;#39;); 又比如 INSERT ... ON DUPLICATE KEY UPDATE，它在 update 阶段有可能分配新的自增id，也可能不会。
2. 三种自增模式：innodb_autoinc_lock_mode 在以 5.6 版本，自增id累加模式分为：
** 传统模式**</description>
    </item>
    
    <item>
      <title>监控MySQL你还应该收集表信息</title>
      <link>http://xgknight.com/posts/2016/12/%E7%9B%91%E6%8E%A7mysql%E4%BD%A0%E8%BF%98%E5%BA%94%E8%AF%A5%E6%94%B6%E9%9B%86%E8%A1%A8%E4%BF%A1%E6%81%AF/</link>
      <pubDate>Sun, 04 Dec 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/12/%E7%9B%91%E6%8E%A7mysql%E4%BD%A0%E8%BF%98%E5%BA%94%E8%AF%A5%E6%94%B6%E9%9B%86%E8%A1%A8%E4%BF%A1%E6%81%AF/</guid>
      <description>1. Story 也许你经常会被问到，库里某个表最近一年的内每个月的数据量增长情况。当然如果你有按月分表比较好办，挨个 show table status，如果只有一个大表，那估计要在大家都休息的时候，寂寞的夜里去跑sql统计了，因为你只能获取当前的表信息，历史信息追查不到了。
除此以外，作为DBA本身也要对数据库空间增长情况进行预估，用以规划容量。我们说的表信息主要包括：
表数据大小（DATA_LENGTH） 索引大小(INDEX_LENGTH) 行数（ROWS） 当前自增值（AUTO_INCREMENT，如果有） 目前是没有看到哪个mysql监控工具上提供这样的指标。这些信息不需要采集的太频繁，而且结果也只是个预估值，不一定准确，所以这是站在一个全局、长远的角度去监控(采集)表的。
本文要介绍的自己写的采集工具，是基于组内现有的一套监控体系：
InfluxDB：时间序列数据库，存储监控数据 Grafana：数据展示面板 Telegraf：收集信息的agent 看了下 telegraf 的最新的 mysql 插件，一开始很欣慰：支持收集 Table schema statistics 和 Info schema auto increment columns。试用了一下，有数据，但是如前面所说，除了自增值外其他都是预估值，telegraf收集频率过高没啥意义，也许一天2次就足够了，它提供的 IntervalSlow选项固定写死在代码里，只能是放缓 global status 监控频率。不过倒是可以与其它监控指标分开成两份配置文件，各自定义收集间隔来实现。 最后打算自己用python撸一个，上报到influxdb里 :) 2. Concept 完整代码见 GitHub项目地址：DBschema_gather 实现也特别简单，就是查询 information_schema 库的 COLUMNS、TABLES 两个表：
SELECT IFNULL(@@hostname, @@server_id) SERVER_NAME, %s as HOST, t.TABLE_SCHEMA, t.TABLE_NAME, t.TABLE_ROWS, t.DATA_LENGTH, t.INDEX_LENGTH, t.AUTO_INCREMENT, c.COLUMN_NAME, c.DATA_TYPE, LOCATE(&amp;#39;unsigned&amp;#39;, c.COLUMN_TYPE) COL_UNSIGNED # CONCAT(c.DATA_TYPE, IF(LOCATE(&amp;#39;unsigned&amp;#39;, c.COLUMN_TYPE)=0, &amp;#39;&amp;#39;, &amp;#39;_unsigned&amp;#39;)) FROM information_schema.</description>
    </item>
    
    <item>
      <title>一种直观记录表结构变更历史的方法</title>
      <link>http://xgknight.com/posts/2016/11/%E4%B8%80%E7%A7%8D%E7%9B%B4%E8%A7%82%E8%AE%B0%E5%BD%95%E8%A1%A8%E7%BB%93%E6%9E%84%E5%8F%98%E6%9B%B4%E5%8E%86%E5%8F%B2%E7%9A%84%E6%96%B9%E6%B3%95/</link>
      <pubDate>Mon, 28 Nov 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/11/%E4%B8%80%E7%A7%8D%E7%9B%B4%E8%A7%82%E8%AE%B0%E5%BD%95%E8%A1%A8%E7%BB%93%E6%9E%84%E5%8F%98%E6%9B%B4%E5%8E%86%E5%8F%B2%E7%9A%84%E6%96%B9%E6%B3%95/</guid>
      <description>1. Story 在没有形成自己的数据库管理平台以前，数据库实例一多（包括生产和测试环境），许多表要执行DDL会变得异常繁杂。
说个自己的经历，需要改现网的一个索引来看优化的效果，因为存在风险，不会一次全改，先只改1个库，然后逐步放开。前后验证效果可能花上一两周的时间，除非实现完整的记录了当时的ddl语句和对应的库，否则根本难以记得。这就完全依赖于个人的习惯及能力。
又比如现网出了个问题，开发追查到一个时间点，想确认那个时候有没有对库表进行过更改操作，如果没有记录表结构变更的历史，也就难以提供需要的信息。
记录差异，很早就思考过能不能用git来做。终于花了一天时间来实现，并验证、修改达到预期的效果，还算满意。
github项目地址在文后。
2. Concept 思路很简单，就是利用 mydumper 导出表时会把各表（结构）单独导成一个文件的特性，每天低峰期导出所有对象元数据：表、视图、存储过程、事件、触发器。需要过滤掉 AUTO_INCREMENT 值。
结构内容存放在一个git仓库下，通过shell脚本提交到 gitlab。所有DDL更改由原来依赖于DBA的主动记录，变成被动采集。
测试环境和生产环境表结构总会有些差异，为了兼顾同时收集两个环境的数据，设置了 environment 选项，根据当前所在运行的机器，自动判断采集哪些实例信息。
3. Usage 首先你需要能够存放表结构信息的git仓库，如gitlab，而且建议设置为私有。
安装 git 和 mydumper mydumper 0.9.1 版本需要编译安装，可以参考这里 file-mydumper-install-ubuntu14-04-sh。当然 yum 或 apt-get 安装其他版本也是一样的。 脚本会尝试自动获取 mydumper 命令的路径。 注意配置git权限的时候，最好不允许其它用户手动提交修改仓库内容。
配置db实例地址 settings.ini示例：
[environment] production=puppetmaster test=puppettestmaster [production] production_auth=your_defaultuser:yourpassword db_name1=192.168.1.100:3306 db_name2=192.168.1.101:3306 db_name3=name3.dbhost.com:3306 db_name4=192.168.1.100:3306:myuser:mypassword [test] test_auth=user1:password1 db_name1=10.0.100.1:3306 db_name2=10.0.100.1:3307 db_name3=10.0.100.2:3306 db_name4=10.0.100.3:3306:myuser1:mypassword1 上面的配置采集 production和test两个环境的表结构，识别两个环境是根据 hostname 来决定的。这样做的好吃就是这个脚本在两个环境下运行不需要做任何修改。 [production]节的名字就是 [environment]节指定的名字 production=xx dbname1=就是配置各个db，地址+端口的形式。用户名和密码可以继续用 : 跟上 production_auth=表示 production 环境下，如 dbname1没有配置用户名时，默认采用这个用户名和密码。这样设计主要是简化配置。
该数据库用户需要 select,show view,event,trigger,procedure 权限。</description>
    </item>
    
    <item>
      <title>MySQL非主从环境下数据一致性校验及修复程序</title>
      <link>http://xgknight.com/posts/2016/11/mysql%E9%9D%9E%E4%B8%BB%E4%BB%8E%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E6%A0%A1%E9%AA%8C%E5%8F%8A%E4%BF%AE%E5%A4%8D%E7%A8%8B%E5%BA%8F/</link>
      <pubDate>Sun, 20 Nov 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/11/mysql%E9%9D%9E%E4%B8%BB%E4%BB%8E%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E6%A0%A1%E9%AA%8C%E5%8F%8A%E4%BF%AE%E5%A4%8D%E7%A8%8B%E5%BA%8F/</guid>
      <description>1. 简介 项目地址：https://github.com/seanlook/px-table-checksum
主从环境下数据一致性校验经常会用 pt-table-checksum 工具，它的原理及实施过程之前写过一篇文章：生产环境使用 pt-table-checksum 检查MySQL数据一致性。但是DBA工作中还会有些针对两个表检查是否一致，而这两个表之间并没有主从关系，pt工具是基于binlog把在主库进行的检查动作，在从库重放一遍，此时就不适用了。
总会有这样特殊的需求，比如从阿里云RDS实例迁移到自建mysql实例，它的数据传输服务实现方式是基于表的批量数据提取，加上binlog订阅，但强制row模式会导致pt-table-checksum没有权限把会话临时改成statement。另一种需求是，整库进行字符集转换：库表定义都是utf8，但应用连接使用了默认的 latin1，要将连接字符集和表字符集统一起来，只能以latin1导出数据，再以utf8导入，这种情况数据一致性校验，且不说binlog解析程序不支持statement（如canal），新旧库本身内容不同，pt-table-checksum 算出的校验值也会不一样，失效。
所以才萌生了参考 pt-table-checksum 自己写了一个：px-table-checksum 。
2. 实现方法 整体思路是借鉴pt-table-checksum，从源库批量（即chunk）取出一块数据如1000行，计算CRC32值，同样的语句在目标库运行一遍，结果都存入另一个库，最后检查对应编号的chunk crc值是否一致。知道不一致还不行，得能否快速方便的修复差异，所以继续根据那些不一致的chunk，去目标库和源库找到不一致的行，是缺失，还是多余，还是被修改了，然后生成修复sql，根据指示是否自动修复。
那么问题就在于：
如何确定批次，也就是下一个chunk该怎么取？ 我还没想做到pt-table-checksum那样，可以根据负载动态调整chunk大小，甚至活跃线程数超过阀值就暂停检查，上来工作量就太大了。目前每次计算的chunk的行数是固定的，可以配置1000或2000等。 所以就要用到分页查询，根据（自增或联合）主键、唯一索引，每次limit 1000后升序取最后一条，作为下一批的起始。所以要分析表上的键情况，组合查询条件。目前仅能检查有主键或唯一所以的表。
如何保证源库和目标库，运行的sql一样？ 之前一版是目标库和源库，以多线程各自计算chunk，入库，后来才意识到严重的bug：比如同样是取1000行，如果目标库少数据，那么下一个chunk起始就不一样，比较的结果简直一塌糊涂。 所以必须保证相同编号的chunk，起点必须相同，所以想到用队列，存放在源库跑过的所有校验sql，模拟pt工具在目标库重放。考虑到要多线程同时比较多个表，队列可能吃内存过大，于是使用了redis队列。
直接在数据库中计算crc32，还是取出数据在内存里计算？ 翻了pt-table-checksum的源码，它是在数据库里计算的。但是第一节里说过，如果目标库和源库要使用不同的字符集才能读出正确的数据，只能查询出来之后再比较。所以 px-table-checksum 两种都支持，只需指定一个配置项。
同时检查多个表，源库sql挤在队列，目标库拿出来执行时过了1s，此时源库那条数据又被修改了一次同步到了目标库，会导致计算结果不一致，实则一致，怎么处理 无法处理，是px-table-checksum相比pt-table-checksum最大的缺陷。 但为了尽可能减少此类问题（比如主从延迟也可能会），特意设计了多个redis队列，目标库多个检查线程，即比如同时指定检查8个表，源库检查会有8个线程对应，但可以根据表的写入情况，配置4个redis队列（目前是随机入列），10个目标库检查线程，来减少不准确因素。 但站在我的角度往往来说，不一致的数据会被记录下来，如果不多，人工核对一下；如果较多，就再跑一遍检查，如果两次都有同一条数据不一致，那就有情况了。
3. 限制 如果检查期间源表数据，变化频繁，有可能检查的结果不准确 也就是上面第4点的问题。很明显，这个程序每个检查的事务是分开的，不像pt工具能严格保证每条检查sql的事务顺序。但有不一致的数据再排查一下就ok了。实际在我线上使用过程中，99.9%是准确的。 表上必须有主键或唯一索引 程序会检查，如果没有会退出。
varbinay,blob等二进制字段不支持修复 其实也不是完全不支持，要看怎么用的。开发如果有把字符先转成字节，再存入mysql，这种就不支持修复。是有办法可以处理，那就是从源库查时用 hex()函数，修复sql里面unhex()写回去。
4. 使用说明 该python程序基于2.7开发，2.6、3.x上没有测试。使用前需要安装 MySQLdb和hotqueue：
$ sudo pip install MySQL-python hotqueue 要比较的表和选项，使用全配置化，即不通过命令行的方式指定（原谅命令行参数使用方式会额外增加代码量）。
4.1 px-table-checksum.py 主程序，运行python px-table-checksum.py 执行一致性检查，但一定了解下面的配置文件选项。
4.2 settings_checksum.py 配置选项
CHUNK_SIZE: 每次提取的chunk行数
REDIS_INFO: 指定使用redis队列地址
REDIS_QUEUE_CNT: redis队列数量，消费者（目标库）有一一对应的线程守着队列
REDIS_POOL_CNT: 生产者（源库）redis客户端连接池。这个设计是为了缓解GIL带来的问题，把入列端与出列端分开，因为如果表多可能短时间有大量sql入队列，避免hotqueue争用</description>
    </item>
    
    <item>
      <title>让mysqldump变成并发导出导入的魔法</title>
      <link>http://xgknight.com/posts/2016/11/%E8%AE%A9mysqldump%E5%8F%98%E6%88%90%E5%B9%B6%E5%8F%91%E5%AF%BC%E5%87%BA%E5%AF%BC%E5%85%A5%E7%9A%84%E9%AD%94%E6%B3%95/</link>
      <pubDate>Thu, 17 Nov 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/11/%E8%AE%A9mysqldump%E5%8F%98%E6%88%90%E5%B9%B6%E5%8F%91%E5%AF%BC%E5%87%BA%E5%AF%BC%E5%85%A5%E7%9A%84%E9%AD%94%E6%B3%95/</guid>
      <description>1. 简介 取名mypumpkin，是python封装的一个让mysqldump以多线程的方式导出库表，再以mysql命令多线程导入新库，用于成倍加快导出，特别是导入的速度。这一切只需要在 mysqldump 或 mysql 命令前面加上 mypumpkin.py 即可，所以称作魔法。
项目地址：https://github.com/seanlook/mypumpkin
该程序源于需要对现网单库几百G的数据进行转移到新库，并对中间进行一些特殊操作（如字符集转换），无法容忍mysqldump导入速度。有人可能会提到为什么不用 mydumper，其实也尝试过它但还是放弃了，原因有：
不能设置字符集 mydumper强制使用 binary 方式来连接库以达到不关心备份恢复时的字符集问题，然而我的场景下需要特意以不同的字符集导出、再导入。写这个程序的时候正好在公众号看到网易有推送的一篇文章 (解密网易MySQL实例迁移高效完成背后的黑科技)，提到他们对mydumper的改进已支持字符集设置，可是在0.9.1版本的patch里还是没找到。 没有像 mysqldump 那样灵活控制过滤选项（导哪些表、忽略哪些表） 因为数据量之巨大，而且将近70%是不变更的历史表数据，这些表是可以提前导出转换的；又有少量单表大于50G的，最好是分库导出转换。mydumper 不具备 mysqldump 这样的灵活性 对忽略导出gtid信息、触发器等其它支持 阿里云rds 5.6 导出必须要设置 set-gtid-purged=OFF 另外有人还可能提到 mysqlpump —— 它才是我认为mysqldump应该具有的模样，语法兼容，基于表的并发导出。但是只有 mysql服务端 5.7.9 以上才支持，这就是现实和理想的距离。。。
2. 实现方法 首先说明，mysqldump的导出速度并不慢，经测试能达到50M/s的速度，10G数据花费3分钟的样子，可以看到瓶颈在于网络和磁盘IO，再怎样的导出工具也快不了多少，但是导入却花了60分钟，磁盘和网络大概只用到了20%，瓶颈在目标库写入速度（而一般顺序写入达不到IOPS限制），所以mypumpkin就诞生了 —— 兼顾myloader的导入速度和mysqldump导出的灵活性。
用python构造1个队列，将需要导出的所有表一次放到队列中，同时启动N个python线程，各自从这个Queue里取出表名，subprocess调用操作系统的mysqldump命令，导出数据到以 dbname.tablename.sql 命名的文件中。load in 与 dump out 类似，根据指定的库名或表名，从dump_dir目录找到所有sql文件，压进队列，N个线程同时调用mysql构造新的命令，模拟 &amp;lt; 操作。
参数解析从原来自己解析，到改用argparse模块，几乎做了一次重构。 对于没有指定--tables的情况，程序会主动去库里查询一下所有表名，然后过滤进队列。
load in目标库，选项做到与dump out一样丰富，可以指定导入哪些db、哪些表、忽略哪些表。
其中的重点是做到与原mysqldump兼容，因为需要对与表有关的选项（-B, -A, --tables, --ignore=），进行分析并组合成新的执行命令，考虑的异常情况非常多。
3. 限制 重要：导出的数据不保证库级别的一致性 对历史不变表，是不影响的 具体到一个表能保证一致性，这是mysqldump本身采用哪些选项决定的 不同表导出动作在不同的mysqldump命令中，无法保证事务。 在我的案例场景下，是有开发同学辅助使用一套binlog解析程序，等完成后重放所有变更，来保证最终一致性。 另，许多情况下我们导数据，并不需要完整的或者一致的数据，只是用于离线分析或临时导出，重点是快速拿数据给到开发。 不寻常选项识别 程序已经尽力做到与mysqldump命令兼容，只需要加上 mypumpkin.</description>
    </item>
    
    <item>
      <title>mysql使用utf8mb4经验吐血总结</title>
      <link>http://xgknight.com/posts/2016/10/mysql%E4%BD%BF%E7%94%A8utf8mb4%E7%BB%8F%E9%AA%8C%E5%90%90%E8%A1%80%E6%80%BB%E7%BB%93/</link>
      <pubDate>Sun, 23 Oct 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/10/mysql%E4%BD%BF%E7%94%A8utf8mb4%E7%BB%8F%E9%AA%8C%E5%90%90%E8%A1%80%E6%80%BB%E7%BB%93/</guid>
      <description>1. utf8 与 utf8mb4 异同 先看 官方手册 https://dev.mysql.com/doc/refman/5.6/en/charset-unicode-utf8mb4.html 的说明：
The character set named utf8 uses a maximum of three bytes per character and contains only BMP characters. The utf8mb4 character set uses a maximum of four bytes per character supports supplementary characters: - For a BMP character, utf8 and utf8mb4 have identical storage characteristics: same code values, same encoding, same length. - For a supplementary character, utf8 cannot store the character at all, whereas utf8mb4 requires four bytes to store it.</description>
    </item>
    
    <item>
      <title>遇到腾讯云CDB连接字符集设置一个坑</title>
      <link>http://xgknight.com/posts/2016/10/%E9%81%87%E5%88%B0%E8%85%BE%E8%AE%AF%E4%BA%91cdb%E8%BF%9E%E6%8E%A5%E5%AD%97%E7%AC%A6%E9%9B%86%E8%AE%BE%E7%BD%AE%E4%B8%80%E4%B8%AA%E5%9D%91/</link>
      <pubDate>Mon, 17 Oct 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/10/%E9%81%87%E5%88%B0%E8%85%BE%E8%AE%AF%E4%BA%91cdb%E8%BF%9E%E6%8E%A5%E5%AD%97%E7%AC%A6%E9%9B%86%E8%AE%BE%E7%BD%AE%E4%B8%80%E4%B8%AA%E5%9D%91/</guid>
      <description>最近一个与qq有关的服务迁到腾讯云上，相应的数据库也要从原阿里云RDS迁移到腾讯云CDB上，经过一番摸索，不带任何政治色彩的说，CDB跟RDS相比弱的不止一条街。比如看个错误日志还要提工单，数据库访问没有白名单，数据传输服务竞不支持源库的开启GTID，自带的后台管理是phpMyAdmin，要临时看查询日志也要提工单，当然这些都是可以容忍通过其它方法解决的，但是如果使用上带来了mysql数据库本身的影响，就用的不太爽了。
最近2个月一直在弄与字符集相关的工作，却还是在cdb踩到一个大坑。情况是这样的，我们旧的RDS上的数据库表定义都是utf8，但由于历史原因，开发一直使用 latin1 去连接的。现在要把这样的一个db迁移到CDB，腾讯云的数据传输服务出了点问题，于是想了办法用阿里云的DTS反向迁。现象是：
用Navicat客户端latin1连接，旧数据显示都ok 但程序端看到历史数据全是乱码，新数据正常 而且新数据通过navicat去看用 utf8 连接才正常 在mysql命令行下手动 set names latin1 读取旧数据ok，但新数据乱码 这明显是新写入的时候就是以 utf8 连接的，读取的时候新旧数据也以 utf8 连接。但应用端已明确设置使用 latin1 连接来读写。为了验证是否CDB的问题，在相同环境下自建了个mysql实例，一切都ok。
腾讯云工程师先是怀疑迁移有问题，后来说可能是character_set_server设置的问题，我站在2个月来处理字符集的经验看了虽然不太可能，还是配合截了几个图，在工单、电话了里撕了几个来回：
因为跟腾讯有合作关系，上头就直接联系到了腾讯云的人，这才找到问题根源：都是--skip-character-set-client-handshake惹的祸。
--character-set-client-handshake Do not ignore character set information sent by the client. To ignore client information and use the default server character set, use --skip-character-set-client-handshake; this makes MySQL behave like MySQL 4.0 一看到这个选项就恍然大悟了，官方文档FAQ里有专门介绍：A.11.11（个人感觉最后一段贴的结果有问题），大意是说为了兼容 mysql 4.0 的习惯，mysqld启动时加上 --skip-character-set-client-handshake 来忽略客户端字符集的设置，强制使用服务端character-set-server的设置。
但这个选项默认是没有开启的，当你在web控制台修改了实例字符集时，CDB自作自作主张修改了这个参数并重启 character_set_client_handshake = 0 。而这个参数在 show variables 看不到的，隐藏的比较深。正好我建实例的时候选择了utf8，然后修改为utf8mb4，但应用端要求latin1，便中枪了。
主要是以前没听过这个参数，后来发现老叶也有篇文章讲到它 MySQL字符集的一个坑，其实是很小的东西，结果排查验证问题前后花了2天。。。</description>
    </item>
    
    <item>
      <title>你可能需要一个实时抓取MySQL慢查询现场的程序</title>
      <link>http://xgknight.com/posts/2016/09/%E4%BD%A0%E5%8F%AF%E8%83%BD%E9%9C%80%E8%A6%81%E4%B8%80%E4%B8%AA%E5%AE%9E%E6%97%B6%E6%8A%93%E5%8F%96mysql%E6%85%A2%E6%9F%A5%E8%AF%A2%E7%8E%B0%E5%9C%BA%E7%9A%84%E7%A8%8B%E5%BA%8F/</link>
      <pubDate>Tue, 27 Sep 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/09/%E4%BD%A0%E5%8F%AF%E8%83%BD%E9%9C%80%E8%A6%81%E4%B8%80%E4%B8%AA%E5%AE%9E%E6%97%B6%E6%8A%93%E5%8F%96mysql%E6%85%A2%E6%9F%A5%E8%AF%A2%E7%8E%B0%E5%9C%BA%E7%9A%84%E7%A8%8B%E5%BA%8F/</guid>
      <description>Python完成的一个小程序，初衷用于杀掉 MySQL 上的异常线程，如慢查询、处于Sleep状态的，但上线运行以后，以另一种模式运行来实时发现现网的慢查询特别有用，挖掘了许多潜在问题。 项目地址：https://github.com/seanlook/myquerykill
在使用阿里云RDS的过程中，数据库出现异常，需要快速恢复。网上有许多类似的kill脚本，都是通过 mysqladmin 实现的。然而 Ali-RDS 环境有以下限制：
不提供 SUPER 权限的用户，也就是用户只能 kill 自己的线程 当连接数暴增时，外部用户无法登陆，包括控制台 为了解决上面两大问题，该 python 脚本通过在db实例上，使用多线程的方式，为每个用户保留一个连接，并实时读取指令配置文件 mysqk.ini，发现有 kill 需求时，利用对应用户已有连接找到 information_schema.processlist 中符合条件的线程，并 kill 。
说明：该脚本在9月份做过一次重写，7月份的版本（分支 old_0.5.0）是每实例每用户，对应一个线程，db实例一多线程数也太多，看得始终不太优雅，于是改成了一个db实例一个线程，维护同时维护多个用户的会话。同时新版也加入了更多的功能，如按时间窗口检查，包含或排除特定连接，邮件通知，配置项覆盖。
1. 特性 始终通过 mysql ping 维持一个长连接，并有断开自动重来机制，解决没有连接可用的尴尬 每个db实例有自己的线程，避免需要单独登陆个别用户去kill的繁复操作。 如果你具有 SUPER 权限，也可以简化配置做到兼容 能够分开应对需要杀死线程的场景： 长时间运行超过 N 秒的 Sleep 状态的事务 （一般不建议，但有时候kill它，可以快速释放连接给管理员使用） 排除一些线程不能kill，如 Binlog dump。可配置 包含特定关键字的线程要kill 出现符合条件的线程时，会对当时的processlist, engine status，lock_wait 做一个快照，并邮件发出。妈妈再也不愁没有事故现场了。 有试运行dry_run模式，即执行所有的检查过程但不真正kill 这便是开头所讲的，实时关注生产环境慢查询，而不是等出现问题被动去看slow log，严重的情况连接数可能已经爆了 支持只在时间窗口内运行，考虑到晚上一些长任务不检查 密码加密 2. 快速上手 需要pip安装MySQL-python和pycrypto两个库，只在python 2.7上有测试。
在 settings.py 里面设置连接的用户名和密码信息。这里假设同一批db的要check的认证信息是一样的，指定的用户既用于登录认证，也用于告知脚本哪些用户需要被检查。 密码要通过 prpcryptec.py 加密，加密的密钥需写入脚本本身的 KEY_DB_AUTH变量。（担心泄露的话，把mysqk.py编译成 pyc 来跑）</description>
    </item>
    
    <item>
      <title>READ-COMMITED 与 REPEATABLE-READ 事务隔离级别之间的异同</title>
      <link>http://xgknight.com/posts/2016/09/read-commited-%E4%B8%8E-repeatable-read-%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E4%B9%8B%E9%97%B4%E7%9A%84%E5%BC%82%E5%90%8C/</link>
      <pubDate>Sat, 03 Sep 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/09/read-commited-%E4%B8%8E-repeatable-read-%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E4%B9%8B%E9%97%B4%E7%9A%84%E5%BC%82%E5%90%8C/</guid>
      <description>经常会被问到 InnoDB隔离级别中 READ-COMMITED和REPEATABLE-READ 的区别，今天就整理了一下，不再从“脏读”、“幻读”这样的名词解释一样去回答了。
1. 行锁 InnoDB行锁实际锁的是索引记录，为了防止死锁的产生以及维护所需要的隔离级别，在执行sql语句的全过程中，innodb必须对所需要修改的行每条索引记录上锁。如此一来，如果你执行的 UPDATE 没有很好的索引，那么会导致锁定许多行：
update employees set store_id = 0 where store_id = 1; ---TRANSACTION 1EAB04, ACTIVE 7 sec 633 lock struct(s), &amp;lt;strong&amp;gt;heap size 96696&amp;lt;/strong&amp;gt;, 218786 row lock(s), undo log entries 1 MySQL thread id 4, OS thread handle 0x7f8dfc35d700, query id 47 localhost root show engine innodb status 上面的 employees 表 store_id 列没有索引。注意 UPDATE 已经执行完成（没有提交），但依然有 218786 个行锁没有释放，还有一个undo记录。这意味着只有一行被更改，但却持有了额外的锁。堆大小（heap size）代表了分配给锁使用的内存数量。
在 REPEATABLE-READ 级别，事务持有的 每个锁 在整个事务期间一直被持有。
在 READ-COMMITED 级别，事务里面特定语句结束之后，不匹配该sql语句扫描条件的锁，会被释放。</description>
    </item>
    
    <item>
      <title>浅析MySQL事务隔离级别与锁 分享</title>
      <link>http://xgknight.com/posts/2016/08/%E6%B5%85%E6%9E%90mysql%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E4%B8%8E%E9%94%81-%E5%88%86%E4%BA%AB/</link>
      <pubDate>Tue, 30 Aug 2016 21:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/08/%E6%B5%85%E6%9E%90mysql%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E4%B8%8E%E9%94%81-%E5%88%86%E4%BA%AB/</guid>
      <description>这段时间在公司内部准备了一个分享，主题是关于 MySQL事务与锁，准备过程内容很多，也深入弄清楚了一些以前比较迷糊的地方，加上后面的讨论也就一个半小时。
主要涉及的是乐观锁与悲观锁，InnoDB多版本并发控制的实现，以及隔离级别与各种情况加锁分析，因为涉及的主要还是开发人员，所以不是很深奥。也算花了不少心血，分享一下。
slideshare: http://www.slideshare.net/ssuser5a0bc0/my-sql-seanlook
{% pdf http://github.com/seanlook/sean-notes-comment/raw/main/static/mysql-ppt-trx_isolation-lock-seanlook.pdf 900 512 %}
原文连接地址：http://xgknight.com/2016/08/30/mysql-ppt-trx_isolation-lock/</description>
    </item>
    
    <item>
      <title>Advanced MySQL Query Tuning .pdf</title>
      <link>http://xgknight.com/posts/2016/06/advanced-mysql-query-tuning-.pdf/</link>
      <pubDate>Sat, 11 Jun 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/06/advanced-mysql-query-tuning-.pdf/</guid>
      <description>端午在家无聊，又不想学习。于是在Youtube随便逛，看到一个很不错的分享，来自 Percona Database Performance。下面是演示稿：
slideshare: http://www.slideshare.net/ssuser5a0bc0/webinar-2013-advancedquerytuning
{% pdf https://www.slideshare.net/slideshow/embed_code/key/3HLJJcJmM9KLGT %}
Youtube: https://www.youtube.com/watch?v=TPFibi2G_oo
能 条件 的可以看看。
Percona webinars上有许多类似的分享，传送门： https://www.percona.com/resources/webinars ，不少是他们CEO Peter Zaitsev 亲自上马的。
原文连接地址：http://xgknight.com/2016/06/11/mysql-advanced-query-tuning-percona/</description>
    </item>
    
    <item>
      <title>pt-online-schema-change使用说明、限制与比较</title>
      <link>http://xgknight.com/posts/2016/05/pt-online-schema-change%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E%E9%99%90%E5%88%B6%E4%B8%8E%E6%AF%94%E8%BE%83/</link>
      <pubDate>Fri, 27 May 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/05/pt-online-schema-change%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E%E9%99%90%E5%88%B6%E4%B8%8E%E6%AF%94%E8%BE%83/</guid>
      <description>如果正在看这篇文章，相信你已经知道自己的需求了。
在 mysql 5.5 版本以前，修改表结构如添加索引、修改列，需要锁表，期间不能写入，对于大表这简直是灾难。从5.5特别是5.6里，情况有了好转，支持Online DDL，相关介绍见 这篇文章，而我在实际alter table过程中还是会引起 data meta lock 问题。pt-online-schema-change是Percona-toolkit一员，通过改进原生ddl的方式，达到不锁表在线修改表结构。
1. pt-osc工作过程 创建一个和要执行 alter 操作的表一样的新的空表结构(是alter之前的结构) 在新表执行alter table 语句（速度应该很快） 在原表中创建触发器3个触发器分别对应insert,update,delete操作 以一定块大小从原表拷贝数据到临时表，拷贝过程中通过原表上的触发器在原表进行的写操作都会更新到新建的临时表 Rename 原表到old表中，在把临时表Rename为原表 如果有参考该表的外键，根据alter-foreign-keys-method参数的值，检测外键相关的表，做相应设置的处理 默认最后将旧原表删除 2. 常用选项说明 只介绍部分常用的选项
--host=xxx --user=xxx --password=xxx 连接实例信息，缩写-h xxx -u xxx -p xxx，密码可以使用参数--ask-pass 手动输入。
--alter 结构变更语句，不需要 ALTER TABLE关键字。与原始ddl一样可以指定多个更改，用逗号分隔。
绝大部分情况下表上需要有主键或唯一索引，因为工具在运行当中为了保证新表也是最新的，需要旧表上创建 DELETE和UPDATE 触发器，同步到新表的时候有主键会更快。个别情况是，当alter操作就是在c1列上建立主键时，DELETE触发器将基于c1列。
子句不支持 rename 去给表重命名。
alter命令原表就不支持给索引重命名，需要先drop再add，在pt-osc也一样。(mysql 5.7 支持 RENAME INDEX old_index_name TO new_index_name) 但给字段重命名，千万不要drop-add，整列数据会丢失，使用change col1 col1_new type constraint（保持类型和约束一致，否则相当于修改 column type，不能online）
子句如果是add column并且定义了not null，那么必须指定default值，否则会失败。
如果要删除外键（名 fk_foo），使用工具的时候外键名要加下划线，比如--alter &amp;quot;DROP FOREIGN KEY _fk_foo&amp;quot;</description>
    </item>
    
    <item>
      <title>使用pt-osc修改主键时注意</title>
      <link>http://xgknight.com/posts/2016/05/%E4%BD%BF%E7%94%A8pt-osc%E4%BF%AE%E6%94%B9%E4%B8%BB%E9%94%AE%E6%97%B6%E6%B3%A8%E6%84%8F/</link>
      <pubDate>Fri, 27 May 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/05/%E4%BD%BF%E7%94%A8pt-osc%E4%BF%AE%E6%94%B9%E4%B8%BB%E9%94%AE%E6%97%B6%E6%B3%A8%E6%84%8F/</guid>
      <description>使用 pt-online-schema-change 做在线ddl最添加普通索引、列，修改列类型、添加默认值等使用比较常规，但涉及到要修改的是主键时就有点棘手。在我修改线上实例过程中，有这样的需求，不妨先思考一下怎么做才好：
原表上有个复合主键，现在要添加一个自增id作为主键，如何进行 会涉及到以下修改动作：
删除复合主键定义 添加新的自增主键 原复合主键字段，修改成唯一索引 如果你够聪明，应该会把这三个操作放在同一个 alter table 命令执行。percona手册里有两个地方对修改主键进行了特殊注解：
&amp;ndash;alter A notable exception is when a PRIMARY KEY or UNIQUE INDEX is being created from existing columns as part of the ALTER clause; in that case it will use these column(s) for the DELETE trigger.
&amp;ndash;[no]check-alter
DROP PRIMARY KEY If &amp;ndash;alter contain DROP PRIMARY KEY (case- and space-insensitive), a warning is printed and the tool exits unless &amp;ndash;dry-run is specified.</description>
    </item>
    
    <item>
      <title>mysql 5.6 原生Online DDL解析</title>
      <link>http://xgknight.com/posts/2016/05/mysql-5.6-%E5%8E%9F%E7%94%9Fonline-ddl%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Tue, 24 May 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/05/mysql-5.6-%E5%8E%9F%E7%94%9Fonline-ddl%E8%A7%A3%E6%9E%90/</guid>
      <description>做MySQL的都知道，数据库操作里面，DDL操作（比如CREATE,DROP,ALTER等）代价是非常高的，特别是在单表上千万的情况下，加个索引或改个列类型，就有可能堵塞整个表的读写。
然后 mysql 5.6 开始，大家期待的Online DDL出现了，可以实现修改表结构的同时，依然允许DML操作(select,insert,update,delete)。在这个特性出现以前，用的比较多的工具是pt-online-schema-change，比较请参考pt-online-schema-change使用说明、限制与比较或 ONLINE DDL VS PT-ONLINE-SCHEMA-CHANGE 。
1. Online DDL 在 MySQL 5.1 （带InnoDB Plugin）和5.5中，有个新特性叫 Fast Index Creation（下称 FIC），就是在添加或者删除二级索引的时候，可以不用复制原表。对于之前的版本对于索引的添加删除这类DDL操作，MySQL数据库的操作过程为如下：
首先新建Temp table，表结构是 ALTAR TABLE 新定义的结构 然后把原表中数据导入到这个Temp table 删除原表 最后把临时表rename为原来的表名 为了保持数据的一致性，中间复制数据（Copy Table）全程锁表只读，如果有写请求进来将无法提供服务，连接数爆张。
引入FIC之后，创建二级索引时会对原表加上一个S锁，创建过程不需要重建表（no-rebuild）；删除InnoDB二级索引只需要更新内部视图，并标记这个索引的空间可用，去掉数据库元数据上该索引的定义即可。这个过程也只允许读操作，不能写入，但大大加快了修改索引的速度（不含主键索引，InnoDB IOT的特性决定了修改主键依然需要 Copy Table ）。
FIC只对索引的创建删除有效，MySQL 5.6 Online DDL把这种特性扩展到了添加列、删除列、修改列类型、列重命名、设置默认值等等，实际效果要看所使用的选项和操作类别来定。
1.1 Online DDL选项 MySQL 在线DDL分为 INPLACE 和 COPY 两种方式，通过在ALTER语句的ALGORITHM参数指定。
ALGORITHM=INPLACE，可以避免重建表带来的IO和CPU消耗，保证ddl期间依然有良好的性能和并发。 ALGORITHM=COPY，需要拷贝原始表，所以不允许并发DML写操作，可读。这种copy方式的效率还是不如 inplace ，因为前者需要记录undo和redo log，而且因为临时占用buffer pool引起短时间内性能受影响。 上面只是 Online DDL 内部的实现方式，此外还有 LOCK 选项控制是否锁表，根据不同的DDL操作类型有不同的表现：默认mysql尽可能不去锁表，但是像修改主键这样的昂贵操作不得不选择锁表。
LOCK=NONE，即DDL期间允许并发读写涉及的表，比如为了保证 ALTER TABLE 时不影响用户注册或支付，可以明确指定，好处是如果不幸该 alter语句不支持对该表的继续写入，则会提示失败，而不会直接发到库上执行。ALGORITHM=COPY默认LOCK级别 LOCK=SHARED，即DDL期间表上的写操作会被阻塞，但不影响读取。 LOCK=DEFAULT，让mysql自己去判断lock的模式，原则是mysql尽可能不去锁表 LOCK=EXCLUSIVE，即DDL期间该表不可用，堵塞任何读写请求。如果你想alter操作在最短的时间内完成，或者表短时间内不可用能接受，可以手动指定。 但是有一点需要说明，无论任何模式下，online ddl开始之前都需要一个短时间排它锁(exclusive)来准备环境，所以alter命令发出后，会首先等待该表上的其它操作完成，在alter命令之后的请求会出现等待waiting meta data lock。同样在ddl结束之前，也要等待alter期间所有的事务完成，也会堵塞一小段时间。所以尽量在ALTER TABLE之前确保没有大事务在执行，否则一样出现连环锁表。</description>
    </item>
    
    <item>
      <title>InnoDB行格式对text/blob大变长字段的影响</title>
      <link>http://xgknight.com/posts/2016/05/innodb%E8%A1%8C%E6%A0%BC%E5%BC%8F%E5%AF%B9text/blob%E5%A4%A7%E5%8F%98%E9%95%BF%E5%AD%97%E6%AE%B5%E7%9A%84%E5%BD%B1%E5%93%8D/</link>
      <pubDate>Wed, 18 May 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/05/innodb%E8%A1%8C%E6%A0%BC%E5%BC%8F%E5%AF%B9text/blob%E5%A4%A7%E5%8F%98%E9%95%BF%E5%AD%97%E6%AE%B5%E7%9A%84%E5%BD%B1%E5%93%8D/</guid>
      <description>最近在排查现网Text与Blob类型，发现有不少，在《高性能MySQL(第3版)》看到对这两种变长数据类型的处理会涉及到在磁盘上创建临时表，性能开销比较大。于是把影响blob型数据存储方式了解了一下：row_format。
1. InnoDB的Antelop与Barracuda文件格式 Innodb存储引擎保存记录，是以行的形式存放的（与之对应的是像Google BigTable这种列数据库）。在InnoDB 1.0.x版本之前，InnoDB 存储引擎提供了 Compact 和 Redundant 两种格式来存放行记录数据，这也是目前使用最多的一种格式。Redundant 格式是为兼容之前版本而保留的。
MySQL 5.1 中的 innodb_plugin 引入了新的文件格式：Barracuda（将以前的行格式 compact 和 redundant 合称为Antelope），该文件格式拥有新的两种行格式：compressed和dynamic。
在 MySQL 5.6 版本中，默认还是 Compact 行格式，也是目前使用最多的一种 ROW FORMAT。用户可以通过命令 SHOW TABLE STATUS LIKE&#39;table_name&#39; 来查看当前表使用的行格式，其中 row_format 列表示当前所使用的行记录结构类型。
mysql&amp;gt; show variables like &amp;#34;innodb_file_format&amp;#34;; +--------------------+-----------+ | Variable_name | Value | +--------------------+-----------+ | innodb_file_format | Barracuda | +--------------------+-----------+ 1 row in set mysql&amp;gt; show table status like &amp;#34;tablename%&amp;#34;\G *************************** 1. row *************************** Name: t_rf_compact Engine: InnoDB Version: 10 Row_format: Compact Rows: 4 Avg_row_length: 36864 Data_length: 147456 Max_data_length: 0 Index_length: 0 Data_free: 0 Auto_increment: 7 Create_time: 2016-05-14 20:52:58 Update_time: NULL Check_time: NULL Collation: utf8_general_ci Checksum: NULL Create_options: Comment: 1 row in set (0.</description>
    </item>
    
    <item>
      <title>InnoDB表主键设计方案</title>
      <link>http://xgknight.com/posts/2016/05/innodb%E8%A1%A8%E4%B8%BB%E9%94%AE%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%A1%88/</link>
      <pubDate>Fri, 13 May 2016 15:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/05/innodb%E8%A1%A8%E4%B8%BB%E9%94%AE%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%A1%88/</guid>
      <description>关于MySQL InnoDB表的主键设计，有必要从开发规范 http://xgknight.com/2016/05/11/mysql-dev-principle-ec/ 里拿出来，单独展开说一下。 InnoDB是一个聚集索引组织表，即行数据是按照聚集索引在物理磁盘上存储的，并且是块状结构，默认一个block是16kB。
图片来《高性能MySQL》
首先在设计表结构时，表一定要显式定义主键，自增主键，或者联合主键，或全局ID。 （所有与主键，包括其它索引，相关的字段，都要定义为NOT NULL，这是因为如果允许NULL，那么在索引的每条记录上，都要多用一个标记去记录这个列是否是NULL，占用多余的存储空间）
1. 自增主键特性 对于高并发的插入速度较快，因为每次插入新记录，都是在之前记录的右边顺序插入，不需要频繁的分裂。 表上要建立多个二级索引时，索引记录都会带上主键，根据主键去定位行数据。自增主键一般是int或bigint型，多个二级索引上面占用的空间较小。
2. 联合主键特性 每次新记录插入，都要寻找到合适的“缝隙”，插入，当插入位置空间不够时，需要做页分裂，这个需要维护成本。 二级索引带上的主键值，是联合主键的总长度，所以一个单列索引占用的空间里面，主键部分占了大部分，空间利用率不高，而且这种是 optimize table 解决不了的。 （提示：聚集索引叶子节点，就是行数据本身，所以，不需要另外的空间存储主键）
但是联合主键有一个好处：逻辑上一批数据，在物理上很有可能相邻存储，有可能检索的数据，在一个block里面，减少了读取并缓存磁盘块的数量，一个是速度的提升，一个是减小内存的消耗。 比如 (f_c_id,f_m_id,f_type) 作为联合主键，f_c_id=22299有20w条记录，每条记录平均160bytes，一个页能存16kB，即100条记录（不考虑预留），那么f_c_id=22299需要2000个page，而且是相邻的page。
举例，应用检索数据 f_c_id=22299, f_m_id IN(12345,23456) ，假设数据在块1和块10，缓存到内存。不多久检索f_c_id=22299, f_m_id=12399，刚好在块1。
如果是自增id，那么就没有这个顺序， 而是根据插入数据时间来的，那么这两条记录可能在物理上很远的地方，要多读取磁盘。
3. 全局ID 全局ID跟自增ID特性基本相同，但是它的值是从另外的服务获取的数字增长类型，不要UUID。
只在有分库（一般有全局统计需求），或其它可能需要全局唯一性的情况下，才使用，否则没必要引入多余的服务依赖。
另外，定义全局ID时，注意字段范围要满足要求，小心溢出；不要加上多余的 AUTO_INCREMENT 定义。
使用全局id还有一个好处：在做数据迁移或拆库时，可以无缝切换，因为新旧数据id不用担心重复。
4. 设计原则：自增主键 VS 联合主键 所有索引字段，特别主键，无论自增或联合主键，一定定义为 not null 表没有特殊情况下，都使用自增主键，尽量不用联合主键 特别是“可能作为联合主键”里面有的字段，会频繁update的情况，更不能做联合主键 在业务层具有唯一性的属性，如果不依赖于数据库的唯一索引来编码，也不用使用Unique Key。如果需要数据库维护唯一性，可使用Unique Key，比如将上面的联合主键定义为联合索引，再另外定义一个自增主键 如果表上有一个单列字段，已具有唯一性，可直接定义成主键，不必设置自增id 尽量用int或bigint型，如果不能，也要控制主键varchar列的长度在30以内。不要用带汉字或url类似的字段作为主键 根据上面的顺序走完，还是想用联合主键的，以下任意条件满足，可用： 表上的插入数据并发量不高 有明显的上文【联合主键】部分说到的，热点数据相邻存储的场景 出了联合主键外，其它索引的只有1-2个 与DBA协商后同意 参考： http://imysql.com/2015/10/29/mysql-faq-clustered-index.shtml
原文连接地址：http://xgknight.com/2016/05/13/mysql-innodb-primary_key/</description>
    </item>
    
    <item>
      <title>MySQL数据库开发规范-EC</title>
      <link>http://xgknight.com/posts/2016/05/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83-ec/</link>
      <pubDate>Wed, 11 May 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/05/mysql%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83-ec/</guid>
      <description>updated: 2017-11-12 本文所提规范，在我博客上可以找到多篇案例。
最近一段时间一边在线上抓取SQL来优化，一边在整理这个开发规范，尽量减少新的问题SQL进入生产库。今天也是对公司的开发做了一次培训，PPT就不放上来了，里面有十来个生产SQL的案例。因为规范大部分还是具有通用性，所以也借鉴了像去哪儿和赶集的规范，但实际在撰写本文的过程中，每一条规范的背后无不是在工作中有参照的反面例子的。如果时间可以的话，会抽出一部分或分析其原理，或用案例证明。
1. 命名规范 库名、表名、字段名必须使用小写字母，并采用下划线分割 MySQL有配置参数lower_case_table_names=1，即库表名以小写存储，大小写不敏感。如果是0，则库表名以实际情况存储，大小写敏感；如果是2，以实际情况存储，但以小写比较。 如果大小写混合使用，可能存在abc，Abc，ABC等多个表共存，容易导致混乱。 字段名显示区分大小写，但实际使⽤时不区分，即不可以建立两个名字一样但大小写不一样的字段。 为了统一规范， 库名、表名、字段名使用小写字母，不允许 - 号。 库名以 d_ 开头，表名以 t_ 开头，字段名以 f_ 开头 比如表 t_crm_relation，中间的 crm 代表业务模块名 库名，如果不是分库，两个不同db实例里面的db名，不能相同，以免混淆 视图以view_开头，事件以event_开头，触发器以trig_开头，存储过程以proc_开头，函数以func_开头 普通索引以idx_col1_col2命名，唯一索引以uk_col1_col2命名（可去掉f_公共部分）。如 idx_companyid_corpid_contacttime(f_company_id,f_corp_id,f_contact_time) 如果某些特殊情况需要在sql里面指定索引，select * from t_test using index(idx_i_abc)，这种所以如果可以，命名的时候加上 i 分隔，如idx_i_corpid, uk_i_user，方便DBA在修改索引的时候会注意到这个 i 标识，不能随意修改这个索引(名称)，否则查询会出错。当然这种情况尽量不要出现。 库名、表名、字段名禁止超过32个字符，需见名知意 库名、表名、字段名支持最多64个字符，但为了统一规范、易于辨识以及减少传输量，禁止超过32个字符
临时用的库、表名须以tmp位前缀，日期为后缀 如 tmp_t_crm_relation_0425。备份表也类似，形如 bak_t_xxxx_20160425 ，这样便于查找和知道有效期。 正常业务里用的临时表、中间表，后缀尽量不要包含 tmp 命名，以免造成歧义。
按日期时间分表须符合_YYYY[MM][DD]格式 这也是为将来有可能分表做准备的，比如t_crm_ec_record_201403，但像 t_crm_contact_at201506就打破了这种规范。 不具有时间特性的，直接以 t_tbname_001 这样的方式命名。
2. 库表基础规范 使用Innodb存储引擎 5.5版本开始mysql默认存储引擎就是InnoDB，5.7版本开始，系统表都放弃MyISAM了。
表字符集统一使用UTF8MB4 UTF8字符集存储汉字占用3个字节，存储英文字符占用一个字节 校对字符集使用默认的 utf8mb4_general_ci。特别对于使用GUI设计表结构时，要检查它生成的sql定义 连接的客户端也使用utf8，建立连接时指定charset或SET NAMES UTF8;。（对于已经在项目中长期使用latin1的，救不了了） 如果遇到EMOJ等表情符号的存储需求，可申请使用UTF8MB4字符集 所有表都要添加注释 尽量给字段也添加注释 类status型需指明主要值的含义，如&amp;quot;0-离线，1-在线&amp;quot; 控制单表字段数量 单表字段数上限30左右，再多的话考虑垂直分表，一是冷热数据分离，二是大字段分离，三是常在一起做条件和返回列的不分离。 表字段控制少而精，可以提高IO效率，内存缓存更多有效数据，从而提高响应速度和并发能力，后续 alter table 也更快。 所有表都必须要显式指定主键 主键尽量采用自增方式，InnoDB表实际是一棵索引组织表，顺序存储可以提高存取效率，充分利用磁盘空间。还有对一些复杂查询可能需要自连接来优化时需要用到。 只有需要全局唯一主键时，使用外部自增id服务 如果没有主键或唯一索引，update/delete是通过所有字段来定位操作的行，相当于每行就是一次全表扫描 少数情况可以使用联合唯一主键，需与DBA协商 对于主键字段值是从其它地方插入（非自己使用AUTO_INCREMENT生产），去掉auto_increment定义。比如一些31天表、历史月份表上，不要auto_increment属性；再必须全局id服务获取的主键。 不强制使用外键参考 即使2个表的字段有明确的外键参考关系，也不使用 FOREIGN KEY ，因为新纪录会去主键表做校验，影响性能。</description>
    </item>
    
    <item>
      <title>小心MySQL的隐式类型转换陷阱</title>
      <link>http://xgknight.com/posts/2016/05/%E5%B0%8F%E5%BF%83mysql%E7%9A%84%E9%9A%90%E5%BC%8F%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E9%99%B7%E9%98%B1/</link>
      <pubDate>Thu, 05 May 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/05/%E5%B0%8F%E5%BF%83mysql%E7%9A%84%E9%9A%90%E5%BC%8F%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E9%99%B7%E9%98%B1/</guid>
      <description>1. 隐式类型转换实例 今天生产库上突然出现MySQL线程数告警，IOPS很高，实例会话里面出现许多类似下面的sql：(修改了相关字段和值)
SELECT f_col3_id,f_qq1_id FROM d_dbname.t_tb1 WHERE f_col1_id=1226391 and f_col2_id=1244378 and f_qq1_id in (12345,23456,34567,45678,56789,67890,78901,89012,90123,901231,901232,901233) 用 explain 看了下扫描行数和索引选择情况：
mysql&amp;gt;explain SELECT f_col3_id,f_qq1_id FROM d_dbname.t_tb1 WHERE f_col1_id=1226391 and f_col2_id=1244378 and f_qq1_id in (12345,23456,34567,45678,56789,67890,78901,89012,90123,901231,901232,901233); +------+---------------+---------+--------+--------------------------------+---------------+------------+--------+--------+------------------------------------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +------+---------------+---------+--------+--------------------------------+---------------+------------+--------+--------+------------------------------------+ | 1 | SIMPLE | t_tb1 | ref | uid_type_frid,idx_corpid_qq1id | uid_type_frid | 8 | const | 1386 | Using index condition; Using where | +------+---------------+---------+--------+--------------------------------+---------------+------------+--------+--------+------------------------------------+ 共返回 1 行记录,花费 11.</description>
    </item>
    
    <item>
      <title>MySQL数字类型int与tinyint、float与decimal如何选择</title>
      <link>http://xgknight.com/posts/2016/04/mysql%E6%95%B0%E5%AD%97%E7%B1%BB%E5%9E%8Bint%E4%B8%8Etinyintfloat%E4%B8%8Edecimal%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9/</link>
      <pubDate>Fri, 29 Apr 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/04/mysql%E6%95%B0%E5%AD%97%E7%B1%BB%E5%9E%8Bint%E4%B8%8Etinyintfloat%E4%B8%8Edecimal%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9/</guid>
      <description>最近在准备给开发做一个mysql数据库开发规范方面培训，一步一步来，结合在生产环境发现的数据库方面的问题，从几个常用的数据类型说起。
int、tinyint与bigint 它们都是（精确）整型数据类型，但是占用字节数和表达的范围不同。首先没有这个表就说不过去了：
Type Storage Minimum Value Maximum Value (Bytes) (Signed/Unsigned) (Signed/Unsigned) TINYINT 1 -128 127 0 255 SMALLINT 2 -32768 32767 0 65535 MEDIUMINT 3 -8388608 8388607 0 16777215 INT 4 -2147483648 2147483647 0 4294967295 BIGINT 8 -9223372036854775808 9223372036854775807 0 18446744073709551615 只需要知道对应类型占多少字节就能推算出范围了，比如int占 4 bytes,即4*8=32bits，大约10位数字，也能理解为什么int默认显示位数是11。
遇到比较多的是tinyint和bigint，tinyint一般用于存放status,type这种数值小的数据，不够用时可能会用smallint。bigint一般用于自增主键。
为了避免数据库被过度设计，布尔、枚举类型也采用tinyint。
还有一点也是经常被提到的关于 int(M) 中M的理解，int型数据无论是int(4)还是int(11)，都已经占用了 4 bytes 存储空间，M表示的只是显示宽度(display width, max value 255)，并不是定义int的长度。
例如：
mysql&amp;gt; CREATE TABLE `tc_integer` ( `f_id` bigint(20) PRIMARY KEY AUTO_INCREMENT, `f_type` tinyint, `f_flag` tinyint(1), `f_num` smallint(5) unsigned ZEROFILL ) ENGINE=InnoDB DEFAULT CHARSET=utf8; mysql&amp;gt; desc tc_integer; +----------------+-------------------------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +----------------+-------------------------------+------+-----+---------+----------------+ | f_id | bigint(20) | NO | PRI | NULL | auto_increment | | f_type | tinyint(4) | YES | | NULL | | | f_flag | tinyint(1) | YES | | NULL | | | f_num | smallint(5) unsigned zerofill | YES | | NULL | | +----------------+-------------------------------+------+-----+---------+----------------+ 4 rows in set (0.</description>
    </item>
    
    <item>
      <title>MySQL字符数据类型char与varchar的区别</title>
      <link>http://xgknight.com/posts/2016/04/mysql%E5%AD%97%E7%AC%A6%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8Bchar%E4%B8%8Evarchar%E7%9A%84%E5%8C%BA%E5%88%AB/</link>
      <pubDate>Thu, 28 Apr 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/04/mysql%E5%AD%97%E7%AC%A6%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8Bchar%E4%B8%8Evarchar%E7%9A%84%E5%8C%BA%E5%88%AB/</guid>
      <description>数据类型差不多是接触mysql一开始就了解的内容，最近遇到几个现象如varchar自动转mediumtext，blob存储性能的问题，不得不回头明确一下关于MySQL常用数据类型的选择。
mysql手册这里 已经讲的很清楚了。它们都是定义字符串型字段时常用的类型，但它们存储和检索的方式有不同，最大长度和尾部的空格是否保留也有差别。
char类型是使用固定长度空间进行存储，范围0-255。比如CHAR(30)能放30个字符，存放abcd时，尾部会以空格补齐，实际占用空间 30 * 3bytes (utf8)。检索它的时候尾部空格会被去除。
char善于存储经常改变的值，或者长度相对固定的值，比如type、ip地址或md5之类的数据，不容易产生碎片。关于它的效率可以参考这里。
varchar类型保存可变长度字符串，范围0-65535（但受到单行最大64kb的限制）。比如用 varchar(30) 去存放abcd，实际使用5个字节，因为还需要使用额外1个字节来标识字串长度（0-255使用1个字节，超过255需要2个字节）。
varchar善于存储值的长短不一的列，也是用的最多的一种类型，节省磁盘空间。update时varchar列时，如果新数据比原数据大，数据库需要重新开辟空间，这一点会有性能略有损耗，但innodb引擎下查询效率比char高一点。这也是innodb官方推荐的类型。
如果存储时真实长度超过了char或者varchar定义的最大长度呢？
在SQL严格模式下，无论char还是varchar，如果尾部要被截断的是非空格，会提示错误，即插入失败 在SQL非严格模式下，无论char还是varchar，如果尾部要被截断的是非空格，会提示warning，但可以成功 如果尾部要被截断的是空格，无论SQL所处模式，varchar都可以插入成功但提示warning；char也可以插入成功，并且无任何提示 这里特意提到SQL的严格模式，是因为在工作中也遇到过一些坑，参考MySQL的sql_mode严格模式注意点。
贴上官方的一个表格：
Value CHAR(4) Storage Required VARCHAR(4) Storage Required &#39;&#39; &amp;rsquo; &#39; 4 bytes &#39;&#39; 1 byte &amp;lsquo;ab&amp;rsquo; &amp;lsquo;ab &#39; 4 bytes &amp;lsquo;ab&amp;rsquo; 3 bytes &amp;lsquo;abcd&amp;rsquo; &amp;lsquo;abcd&amp;rsquo; 4 bytes &amp;lsquo;abcd&amp;rsquo; 5 bytes &amp;lsquo;abcdefgh&amp;rsquo; &amp;lsquo;abcd&amp;rsquo; 4 bytes &amp;lsquo;abcd&amp;rsquo; 5 bytes 另外，mysql字段值比较时默认是不区分大小写的，这是由于他们的校对规则（一般是 utf8_general_ci）决定的，按字符比较，所以查询时 值尾部 的空格也是被忽略的，除非建表时对列指定 BINARY （校对字符集变成utf8_bin）或者select * from vc where binary v=&#39;ab &#39;;，就会按字节比较，即比较时区分大小写和尾部空格。
需要注意的是，使用varchar不能因为长度可变就随意分大空间，比如90个字节能放够的列定义成varchar(200)，因为开辟内存时是以200字节进行的，遇到需要filesort或tmp table作业可能会带来不利影响。</description>
    </item>
    
    <item>
      <title>MySQL sql_mode 说明（及处理一起 sql_mode 引发的问题）</title>
      <link>http://xgknight.com/posts/2016/04/mysql-sql_mode-%E8%AF%B4%E6%98%8E%E5%8F%8A%E5%A4%84%E7%90%86%E4%B8%80%E8%B5%B7-sql_mode-%E5%BC%95%E5%8F%91%E7%9A%84%E9%97%AE%E9%A2%98/</link>
      <pubDate>Fri, 22 Apr 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/04/mysql-sql_mode-%E8%AF%B4%E6%98%8E%E5%8F%8A%E5%A4%84%E7%90%86%E4%B8%80%E8%B5%B7-sql_mode-%E5%BC%95%E5%8F%91%E7%9A%84%E9%97%AE%E9%A2%98/</guid>
      <description>1. MySQL莫名变成了 Strict SQL Mode 最近测试组那边反应数据库部分写入失败，app层提示是插入成功，但表里面里面没有产生数据，而两个写入操作的另外一个表有数据。因为 insert 失败在数据库层面是看不出来的，于是找php的同事看下错误信息：
[Err] 1364 - Field `f_company_id` doesn&amp;#39;t have a default value 很明显2个 insert 操作，第一条成功，第二条失败了，但因为没有控制在一个事务当中，导致app里面依然提示成功，这是客户入库操作，心想如果线上也有这个问题得是多大的代价。
不说开发的问题，好端端的mysql怎么突然就部分表写入失败呢？根据上面的问题很快能猜到是 sql_mode 问题： NOT NULL 列没有默认值但代码里也没给值，在非严格模式下，int列默认为0，string列默认为&amp;rsquo;&amp;lsquo;了，所以不成问题；但在严格模式下，是直接返回失败的。
一看，果然：
mysql&amp;gt; show variables like &amp;#34;sql_mode&amp;#34;; +---------------+--------------------------------------------+ | Variable_name | Value | +---------------+--------------------------------------------+ | sql_mode | STRICT_TRANS_TABLES,NO_ENGINE_SUBSTITUTION | +---------------+--------------------------------------------+ 但是一直是没问题的的，就突然出现了，有谁会去改 sql_mode 呢，生产环境产生这个问题的风险有多大？所以必须揪出来。
先 set global sql_mode=&#39;&#39; ，让他们用着先（文后会给解决问题根本的办法），同时打开general_log看是哪一个用户有类似设置 sql_mode 命令：
1134456 Query SET autocommit=1 1134456 Query Set sql_mode=&amp;#39;NO_ENGINE_SUBSITUTION,STRICT_TRANS_TABLES&amp;#39; 1134457 Connect ecuser@10.0.200.173 on 1134457 Query /* mysql-connector-java-5.</description>
    </item>
    
    <item>
      <title>MySQL避免索引列使用 OR 条件</title>
      <link>http://xgknight.com/posts/2016/04/mysql%E9%81%BF%E5%85%8D%E7%B4%A2%E5%BC%95%E5%88%97%E4%BD%BF%E7%94%A8-or-%E6%9D%A1%E4%BB%B6/</link>
      <pubDate>Tue, 05 Apr 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/04/mysql%E9%81%BF%E5%85%8D%E7%B4%A2%E5%BC%95%E5%88%97%E4%BD%BF%E7%94%A8-or-%E6%9D%A1%E4%BB%B6/</guid>
      <description>这个亏已经吃过很多次了，在开发以前的sql代码里面，许多以 or 作为where条件的查询，甚至更新。这里举例来说明使用 or 的弊端，以及改进办法。
select f_crm_id from d_dbname1.t_tbname1 where f_xxx_id = 926067 and (f_mobile =&amp;#39;1234567891&amp;#39; or f_phone =&amp;#39;1234567891&amp;#39; ) limit 1 从查询语句很容易看出，f_mobile和f_phone两个字段都有可能存电话号码，一般思路都是用 or 去一条sql解决，但表数据量一大简直是灾难： t_tbanme1上有索引idx_id_mobile(f_xxx_id,f_mobile), idx_phone(f_phone),idx_id_email(f_id,f_email)，explain 的结果却使用了 idx_id_email 索引，有时候运气好可能走 idx_id_mobile f_xxx_id
因为mysql的每条查询，每个表上只能选择一个索引。如果使用了 idx_id_mobile 索引，恰好有一条数据，因为有 limit 1 ，那么恭喜很快得到结果；但如果 f_mobile 没有数据，那 f_phone 字段只能在f_id条件下挨个查找，扫描12w行。 or 跟 and 不一样，甚至有开发认为添加 (f_xxx_id,f_mobile,f_phone)不就完美了吗，要吐血了~
那么优化sql呢，很简单（注意f_mobile,f_phone上都要有相应的索引），方法一：
(select f_crm_id from d_dbname1.t_tbname1 where f_xxx_id = 900000 and f_mobile =&amp;#39;1234567891&amp;#39; limit 1 ) UNION ALL (select f_crm_id from d_dbname1.t_tbname1 where f_xxx_id = 900000 and f_phone =&amp;#39;1234567891&amp;#39; limit 1 ) 两条独立的sql都能用上索引，分查询各自limit，如果都有结果集返回，随便取一条就行。</description>
    </item>
    
    <item>
      <title>使用sysbench对mysql压力测试</title>
      <link>http://xgknight.com/posts/2016/03/%E4%BD%BF%E7%94%A8sysbench%E5%AF%B9mysql%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95/</link>
      <pubDate>Mon, 28 Mar 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/03/%E4%BD%BF%E7%94%A8sysbench%E5%AF%B9mysql%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95/</guid>
      <description>sysbench是一个模块化的、跨平台、多线程基准测试工具，主要用于评估测试各种不同系统参数下的数据库负载情况。关于这个项目的详细介绍请看：https://github.com/akopytov/sysbench 。 它主要包括以下几种方式的测试：
cpu性能 磁盘io性能 调度程序性能 内存分配及传输速度 POSIX线程性能 数据库性能(OLTP基准测试) sysbench的数据库OLTP测试支持MySQL、PostgreSQL、Oracle，目前主要用于Linux操作系统，开源社区已经将sysbench移植到了Windows，并支持SQL Server的基准测试。
废话不多说，开始。
1. sysbench安装 mysql版本: mysql-community-server-5.6.29 OS: CentOS 6.7 X86_64 sysbench 0.5相比0.4版本有一些变化，包括oltp测试结合了lua脚本，还多了一些隐藏选项，本文会涉及得到一部分。 目前许多仓库里已编译好的二进制sysbench还是0.4.x版本，不过现在主流也还是github上的0.5，可以从 这里下载0.5版本的rpm包直接安装，不过我选择自己编译，因为只有这个办法是通用的。
// 先安装编译依赖环境 $ sudo yum install gcc gcc-c++ automake make libtool mysql-community-devel $ cd /tmp &amp;amp;&amp;amp; git clone https://github.com/akopytov/sysbench.git $ cd /tmp/sysbench &amp;amp;&amp;amp; ./autogen.sh $ ./configure --prefix=/usr/local/sysbench-0.5 $ ./make &amp;amp;&amp;amp; sudo make install // 0.5版本需要oltp.lua测试脚本 // 如果是rpm包方式安装的，在 /usr/share/doc/sysbench/tests/db/ 下可找到 $ cd /usr/local/sysbench &amp;amp;&amp;amp; sudo mkdir -p share/tests/db $ cp /tmp/sysbench/sysbench/tests/db/*.</description>
    </item>
    
    <item>
      <title>记一次Mac mini折腾过程（鼠键共享，更换SSD）</title>
      <link>http://xgknight.com/posts/2016/01/%E8%AE%B0%E4%B8%80%E6%AC%A1mac-mini%E6%8A%98%E8%85%BE%E8%BF%87%E7%A8%8B%E9%BC%A0%E9%94%AE%E5%85%B1%E4%BA%AB%E6%9B%B4%E6%8D%A2ssd/</link>
      <pubDate>Mon, 18 Jan 2016 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2016/01/%E8%AE%B0%E4%B8%80%E6%AC%A1mac-mini%E6%8A%98%E8%85%BE%E8%BF%87%E7%A8%8B%E9%BC%A0%E9%94%AE%E5%85%B1%E4%BA%AB%E6%9B%B4%E6%8D%A2ssd/</guid>
      <description>从公司网管那捣鼓来一个“遗弃” Mac mini，说其它人觉得用起来太卡，正好我的工作PC( CPU 4×i3，MEM 8G, HDD 500G)软件开多了也觉得有些卡，特别是我使用浏览器的习惯不太好，每次搜索统一结果都要打开好多标签页对比，文章性质的觉得有用想将来记录下来就没关闭页面，一两个星期下来只Chrome使用的内存就达到4G多。不用也浪费，于是就拿Mac mini分摊一下压力。
刚拿到手时心想得有多不堪配置才使得的Mac mini卡到嫌弃的地步，看了下底面的型号，A1347——这是2014年底出的新款，没有我想象的那么旧，还好。于是找来显示器、鼠键准备开用了（在某宝上买根八字电源线）。
但是开机密码没有啊！虽然简单重装是个办法，但我还是想看看里面现在是什么样的，杀鸡焉用牛刀。直接Crack root&amp;hellip;
1. 破解Mac root密码 找到这篇文章 http://wowking.blog.51cto.com/1638252/753774 。我们平头百姓手头哪会有刻录的Mac OS光盘，而且也没移动光驱，所以方法一就不考虑了。方法二是单用户模式，毕竟 OS X 也是*nix血统，命令行几个命令倒难不到我。
可是众所周知，Mac的键盘跟普通键盘是不一样的，开机启动的时候command + S在一般美式键盘下到底能不能进入单用户模式呢？嗯，行的，按下mini的开机按钮之后不断 win + S。进入Single user model之后提示符#root&amp;gt;，逐步输入以下命令：
# 执行硬盘检测（只读）, 这一步可以省略 /sbin/fsck -y # 加载文件系统（读/写） /sbin/mount -uaw # 删除初始化设置时的OSX生成的隐藏文件”.applesetupdone” rm /var/db/.AppleSetupDone # 重启 reboot 重启后开机画面会指导你创建一个新的管理员账号，然后这个新的账号密码登陆。就是这么简单，接下来删用户抹除一切使用痕迹😄。
进去之后着实令我窃喜：OS X Yosemite, 2.6 GHZ Intel Core i5, 8G DDR3, Intel Iris 1536 MB, 1TB HDD，就这配置比得上我当前的Win PC了，高兴得捡了块宝似的。优胜美地系统与我自己的Mac Book Pro一样，无缝立马开始用。
然而面临的一个问题来了，现在2台工作电脑，配有2套鼠标键盘，切换太不方便了。于是我用大腿想了想，嗯，应该有专门的多台电脑间共享鼠键的软件。啪啪啪几下锁定两款Sharemouse、Synergy。
2. 跨平台共享鼠标键盘-synergy 先来简单说一下Sharemouse，收费，但你懂的，但这东西毕竟用的人少，要分别在在windows和Mac两个平台上找到相同版本的破解版是多么不容易。中间折腾就不说了，成功使用 V2.</description>
    </item>
    
    <item>
      <title>南山南</title>
      <link>http://xgknight.com/posts/2015/11/%E5%8D%97%E5%B1%B1%E5%8D%97/</link>
      <pubDate>Sun, 01 Nov 2015 11:59:31 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2015/11/%E5%8D%97%E5%B1%B1%E5%8D%97/</guid>
      <description>今天11月1号，深圳的天气正好从这一天凉了起来，傍晚回住处的公交车上给家里打了个电话，是爸爸接的，说家里已经有点冷了。
现在对冷没什么概念了，深圳是一个没有冬天的城市，一件外套就能过冬。也就是今天起风了出门才稍稍感觉到凉，昨天还热的不行呢——那是因为去爬山了。
南山，2年前来这里的第一个月就听说过，但两次上过梧桐山，上半年爬过凤凰山，就偏偏离自己最近的南山未曾到访。山虽然不高，但一直放着不去还能再找到人陪我去不成，于是就响应党组织号召，登山去。
周六下午，小明从公司过去，而我从家里坐公交过去，照计划的时间应该2点半可以集合，无奈在深大转车多等了20分钟，结果是小明跟其他人一起先从海关登山口上山，先到山顶者有奖，我晚十分钟到出发点，去追他们。出乎意料，迈进登山口就一直上台阶，上啊上啊上，T恤已经全湿了，我竟然还穿着紧身牛仔裤！（其实主要考虑到晚上吃饭方便）。由于平时也打打球，体力不算太差，20分钟上到了全程海拔一半的样子，还没追上，双腿力量也下降了，正好碰到没跟上大部队的两个人，就一起走了。后半程坡也小了很多，吹来一丝微风能感觉到背上一阵凉意。此时群里已经有人到观景台发图了，但奇怪的是那么一大波上去怎么才有2个人发图，原来拼的不仅仅是体力，还有手机信号……
三点半时基本上都到顶了，风景还不错，能看到深圳湾大桥（据说晚上很美），和对面的香港。
团体里大部分我是认识的，有我以前的同事，和球场上认识的伙伴。虽然我已离职近4个月，但我党组织关系还在TP，也交了党费，这才有机会和他们一起出来。还有经费，号召大家买书，于是买了《摄影的艺术》《皮囊》等，小明也为他单反买了本，我看中的是他那本室内装饰和川菜食谱，嘿嘿。
爬完山当然还有活动，自助餐——不是平时想象的哪种自助餐。蛇口是富人区，自助的当然是海鲜之类的，与大饱口福和四海一家有点像，除了种类没有后面两家多，味道和环境都还不错，感受一下。
原本以为5点半开吃，顶多2小时回去了（因为人多而且还有些不熟的），结果听说海上世界就在附近，反正刚刚为了吃回本，肚子都撑了，就走着去了。哦，想起原来当天是万圣节，可不热闹了。
常去的南山腐败地，一个海岸城，一个欢乐海岸，怎么能漏了海上世界，也是早有听说却没来过。一路望去，好多歪果仁，而且装扮忒吓人。海上世界最中心有一艘“船”叫明华号，当然甲板上开着各种餐厅。无意听到人说8点整有水秀表演，几个大男人在一顿狂拍后，终于等来了 water show 。短短的三分钟！
周六算是疯了一天，周日计划还是学点东西，上午9点起来看了看puppet视频，下午去公司简单加了个班。上周经理不在，杂事一大堆，也是身不由己，也是欠了很多技术债。
最后，晚上做了顿饭，忙活2个小时——可是三个人的两顿饭菜啊，不过挺有成就感的，因为吃完了……
11月，你好！
本文链接地址： http://xgknight.com/2015/11/01/nan-shan-hike/</description>
    </item>
    
    <item>
      <title>周末腐败地</title>
      <link>http://xgknight.com/posts/2015/10/%E5%91%A8%E6%9C%AB%E8%85%90%E8%B4%A5%E5%9C%B0/</link>
      <pubDate>Sun, 25 Oct 2015 15:44:31 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2015/10/%E5%91%A8%E6%9C%AB%E8%85%90%E8%B4%A5%E5%9C%B0/</guid>
      <description>下午一点钟才起来，今天本来也没什么安排，算不上睡懒觉，毕竟昨晚四点钟才睡。
昨天（周六）公司写字楼的物业举办了一届羽毛球赛，七点钟就起来坐地铁来到侨城东，看来公司包的场地是华侨城锦绣花园的一个社区羽毛球馆，果然住着一群有钱人。我八点35到场，热个身，大概9点钟开始抽签，抽了个7号，也就是其他谁也抽到7号那就与我对打。运气太背了，一个估计有170斤的对手笑呵呵的站在我面前。人家力气大，专打我后场球，我手臂疼痛感还没恢复，被秒了。
剩下没事只给我司的人拍照了。哎，虽然我手机拍照效果一般，但也不差，pp拍出来噪点严重，不清晰。然后觉得反正现在也没事，物业方也没找到合适的裁判，我就顺口应了句“我来吧”，裁女单。额，场面有多和谐我就不讲了，双方是挽着手上场的。本以为完事了，结果，又要裁男单，裁复赛，最后决赛。当时我想现在空下这么多场地，好好练几个球，可大家都不愿意顶替我去裁。最后前三甲决赛，就我一个喊着，“13比11，这一局比赛结束”——决赛果然精彩，双方咬着分不放。因为是循环赛，按最后每人赢的局数定名次，三人打了七局。这还是我第一次当裁判呢。
回来时都12点多了，又困又累，一同事顺路就开车送我到了西乡。本以为可以冲个澡，睡四五个小时，结果，公司客户在投诉网站使用很慢，远程到公司找了一个小时原因没结果，还趴在桌上睡着了。（程序员节还出事情呢？）
等我醒来，室友几个约好了去民治聚餐，公司催命电话又打过来了，好在运维现在不止我一个，就让星星（我领导）去解决了。
真的很庆幸能有这么一群玩耍的朋友，我们七个是13年一同进TP的，离职只剩2个了，每次好久没约，就在群里吼一句，大家都不约而同的来了。乔帮主说的对，平时工作压力大，到了这，咱们就吹牛逼，自黑，互相调侃。好家伙，一顿饭能从下午五点半吃到十点，然后转战楼上KTV。我向来不喜欢唱歌这样的场所，但去也就去了，大家都自己人，不会唱歌瞎吼也没事（雷军的Are you OK都有人点，我还怕什么），玩玩骰子也可以。
玩的真的很疯，但也很开心。几个人里面，有一对已经领证了，我们都看过他们的分分合合，在桌上听他吹自己的理想规划，心想结婚了就是不一样；另一个也是我理工同届了，经常一起开玩笑，他刚从TP离职去了一加；还有威哥，互相说对方做的饭不好吃；还有勤快的小明，善于自黑强哥，花痴文，正在创业的韦爷。
到凌晨1点半实在是困了，一晚上嗓子哑了，芥末也吃了，圆满了。打个优步回到家，看似还清醒，贫民窟的百万富翁，没5分钟我就睡着了，醒来就一点了。
晚上又去蹭原公司场地打球，不想宅家，提前把晚上的汤煲好——这样的周末过得才有意义。
本文链接地址： http://xgknight.com/2015/10/25/weekends-badminton-ktv/</description>
    </item>
    
    <item>
      <title>在女性眼里，男人会做饭是种什么体验？</title>
      <link>http://xgknight.com/posts/2015/10/%E5%9C%A8%E5%A5%B3%E6%80%A7%E7%9C%BC%E9%87%8C%E7%94%B7%E4%BA%BA%E4%BC%9A%E5%81%9A%E9%A5%AD%E6%98%AF%E7%A7%8D%E4%BB%80%E4%B9%88%E4%BD%93%E9%AA%8C/</link>
      <pubDate>Wed, 21 Oct 2015 23:56:25 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2015/10/%E5%9C%A8%E5%A5%B3%E6%80%A7%E7%9C%BC%E9%87%8C%E7%94%B7%E4%BA%BA%E4%BC%9A%E5%81%9A%E9%A5%AD%E6%98%AF%E7%A7%8D%E4%BB%80%E4%B9%88%E4%BD%93%E9%AA%8C/</guid>
      <description>原文地址：https://www.quora.com/What-do-women-think-of-men-who-can-cook 作者：Shambhavi Tripathi 翻译：Seanlook
What do women think of men who can cook? 这个问题很有意思，我想我可以很好的回答这个问题，因为我有幸认识这些人。
我的弟弟和我的两个好朋友都很擅长做饭，所以我将以他们为原型来回答。
在我回答之前呢，我想提一下我自己算得上是一个极度偏执的人，因为我很爱吃。我就是个吃货（素食），我的味蕾从未被满足过，并且7×24小时不间断的寻找美食。然而，我自己对下厨一无所知，甚至麦琪面都下不好。好了，接下来让我来开始回答，在我看来男人会做饭是怎样的。 (Image Credits: Fathers day Archives | Kitchen Remodeling)
他们对很小的细节感兴趣 大部分人去餐厅时会怎样做？好吧，我来告诉你我一般怎么做。要么根据我自己喜好点几种特定成分的菜（例如奶酪），要么心情好的时候，根据菜单上的图片来点一些新菜式。是的，这就是我点菜的水平。现在当我和我弟或者喜欢做饭的朋友一起出去时，他们会这样做：大声念出菜名，同时也会念出它包含些什么（无论菜名后面的括号里写的是什么）。他们会尝试想象一下如果自己做出来会是什么味道。如果他们还不满足于念出菜名，有可能还会叫来服务员，询问各种细节，比如制作的过程，那道菜通常要提前准备什么。他们对这个太感兴趣了！与此同时，我只好不耐烦的看这看那，心想，为什么他就不能随便点任何想吃的东西呢？
他们极度追求完美 当他们为你刚做好一道鲜汁四溢佳肴，你如狼似虎的吃着，“天呐，不能更好吃了，太美味了，简直了！”。但当他们尝了一下，脸上摆出的奇怪的表情，我至今都没理解什么意思，他们会然后点评了一下小的不足并记在脑子里避免将来还犯同样的错误。
他们很性感 我们很爱看一个男人在做饭，真的很难不爱上一个厨房里的男人。看着他用双手创造出精美的一道菜，如此动人。它超过了其它赏赐，他们做饭的姿态透着某种性感。看着他们为你准备一顿早餐或者一杯咖啡，绝对可以大幅度拉高性感指数。 (Image Credits: istock_000018935400large - Howard Falco)
他们经常给你的生活带来新体验 他们总乐意去发明新的菜式，也会学习各种你可能从没听过的烹饪方法。他们给你的生活带来新花样，这是可遇不可求的品质。
他们觉得“做饭是女人的工作”这种想法很荒谬 这些人理解的下厨，是没有那么多局限的，这件事不仅仅限制只有女性才能做，他们完全打破这个令人愤怒的事实（印度除外），他们乐意并且为做出爱心饭菜的行为感到高兴。
他们可以时刻为你做吃的 无论是中午还是半夜，只要你在他们面前表达意愿，想要他做东西给你吃，放心吧，他绝对不会拒绝你。甚至半夜在家里，我的胃由于饿在咕咕叫的时候，我请求正在忙其它事情的弟弟做点吃的，他从未说一个不字。相反，他总能带来你怎么也想不通他是如何利用以前一样的食材，做出完全超乎意料的东西来。谢谢老弟：P
他们身体比我们健康 拥有大量关于各式食物的知识，他们知道哪种食物是健康的，哪种可能对身体不好甚至是有害的。所以他们通过推荐相对均衡、健康的饮食习惯，让自己和身边的人也安全健康起来。
他们很擅长打开一个话题，特别是在陌生场合 全世界到处遍布食物，当你以一名游客或者其它身份出现在一个陌生地点时，这些会做饭的人会很轻易的跟当地人搭上话，和他们一起旅游会感到很轻松，因为他们总知道怎样不会冷场，不感到尴尬，跟陌生人可以很友好的交流。
他们是天底下所有妈妈的“菜” 把他们介绍给你妈妈认识，并告诉说他会做饭，恐怕她听不进其它事情了。你妈妈将会对他印象深刻，甚至开始讨论关于菜式做法之类的事情。几乎每位母亲都爱这一点，你妈妈可能还会对你吼道：“向他学习！你甚至连杯茶都泡不好。”。
他们绝不会要求我进厨房（最后但我喜欢） 由于他们知道我对做饭没有一点概念，所以我可以很舒适的待在任意地方。他们从不会指指点点，也不会让你上前帮忙，依然总是会做出美味佳肴来满足我和身边的人。
MEN WHO CAN COOK ARE AMAZING AND A BLESSING. THEY ARE INTERNATIONALLY IN DEMAND AND TOTALLY RESPECTE.
本文链接地址：http://xgknight.com/2015/10/21/what-do-women-think-of-men-who-can-cook/</description>
    </item>
    
    <item>
      <title>回家看看（国庆）</title>
      <link>http://xgknight.com/posts/2015/09/%E5%9B%9E%E5%AE%B6%E7%9C%8B%E7%9C%8B%E5%9B%BD%E5%BA%86/</link>
      <pubDate>Wed, 30 Sep 2015 11:59:31 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2015/09/%E5%9B%9E%E5%AE%B6%E7%9C%8B%E7%9C%8B%E5%9B%BD%E5%BA%86/</guid>
      <description>汽车在公路上一路奔驰，车厢内很安静，大部分人闭目休息，能确定的是司机是清醒的，而我在后面靠窗的位置，取掉眼镜，不太清晰的望着窗外。一片片无人问津小树林，一片片因下雨而污浊的池塘水，一片片村庄、农田……﻿
是的，老毛病又犯了，又要发感慨了。﻿﻿
昨天这个时候还在深圳地铁上，忙忙碌碌，人挤人。每天朝七晚九，周末睡不醒，完全没有7月份换工作那会儿打了鸡血一样，与自己的约定也始终没坚持。早在一个月前，实在想不到国庆去哪，也是因为种种压力，澳门的计划，四川的计划，没法任性的说走就走，于是就选择了回家，去见见老同学们，去参加婚礼，去看看父母，去看看自己。﻿﻿
昨天在列车上，看完了『侣行1』，作者带我们去探寻索马里的恐怖之都摩加迪沙，体验被枪抵住胸膛的心跳；带我们去北极的奥伊米亚康，在地冻天寒的雪地上露营；还深入乌克兰切尔诺贝利核电站，挑战核辐射恐惧；最后去感受毁灭与美学兼具的马鲁姆火山，看岩浆翻滚，体验生死，把命交给爱人。当然，不必羡慕，不必自悔，但哪怕我们生活做出他们百分之一的改变，至少深藏一颗不羁的内心，不要再一成不变，不要再泥潭深陷，就会变得不再慵懒，变得有趣。﻿﻿
能折腾，有信仰，这是我对他们四人团队的极简总结。而这正是我还没走出的迷途，Yes和No用错地方。﻿﻿
人一生会遇到形形色色的人，相信每个人背后都有故事。这些人会对你产生重大影响的人，一双手都可以数的过来，而时常能陪在身边的更是屈指可数。与他们去经历欢笑与泪水，去经历生死与难忘，这样才懂得珍惜，不会恶语相向。很喜欢道士下山范伟讲的那段话，“人生七十古来稀，十年少小，十年老弱，还有五十年，五十年再分成日夜，只有二十五年的光景了，再加上 刮风下雨，三灾六病，人这一辈子 还能剩下多少好日子。”。工作，努力尽心就好，对自己做的事情负责；生活，本应多样。(写完这段，良辰都想吐了)﻿﻿
火车上还看电影『遗弃』，差一点陷入平常悬疑片的路子，特别是女主开始怀疑自己的时候，好了，不剧透了，小电影里值得一看。﻿﻿
凌晨1点到的九江，以亲友马上过来接我为由，逃离出站口过分“热烈”的拉客仪式，不下十个说有小妹儿的，“我们这都这么叫”，终于在一公里开外的地方找到一个宾馆，尼玛，还是双标。抓紧时间睡了四个小时就滚了。
本文链接地址： http://xgknight.com/2015/09/30/the-way-home-20151001/</description>
    </item>
    
    <item>
      <title>nice is not nice</title>
      <link>http://xgknight.com/posts/2015/07/nice-is-not-nice/</link>
      <pubDate>Tue, 14 Jul 2015 00:49:31 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2015/07/nice-is-not-nice/</guid>
      <description>看到身边朋友在玩一个叫 nice 的应用，也试用了一把。
从下载量来说它是LOFTER的2倍，它们都可以划分为图片社交。这样说对于网易乐乎来说是不公平的，lofter定位是轻博客，类似于国外的tumblr，生产高质量的内容，尤其是图片。（jianshu倾向于文字，类似国外的medium）
而nice呢，注重图片几乎到放弃文字的地步，简单的通过打标签来注解图片，炫耀的意思不言而喻，而恰好它打的是陌生人社交的牌，大家都互相不认识，不会引起熟人间拉仇恨的嫌疑。陌生人之间也丝毫不吝啬自己的赞，这种低成本却又能给对方带来好感的点赞行为，实际都是虚伪在作怪。我因为应用要求上传了一个阿狸的头像，几分钟内也能收到十多个赞，我当时都蒙了。但是确实喜欢听到被点赞的通知，这大概能解释为什么女生偏爱这个app——全nice内容无非就是自拍照、吃的什么、逛街——无特效，不发图。
在nice里，你会发现所有人都过着小资生活。它不是一个发泄的场地，也不适合记录生活，因为它是短暂的，一个人可能接触nice一到两个月基本就淡出了。有时候想想用nice的人其实是自私的，因为你的图（背后）往往不止你一人，但因为几乎全来自陌生人点赞，满足的是个人的虚荣心，而图中那一刻的其他人无非是个陪衬。不然为何不发惹朋友圈呢……
可能有人出来批判我了，女生爱美怎么啦，注孤生。也许我喜欢的只是对生活一种简简单单的表达。你为何不愿在朋友圈发同样的，难道是因为缺少标签的功能吗，no！ 难道是文艺青年号称要逃离朋友圈，也不对！一万个哈姆雷特！
在nice久了，刷够了别人的美图，忍不住自己也要上图。要有上图的资本，就要打破原来的计划去寻找“素材”，会不会对身边平凡的生活感到厌倦——我YY的。
人人都有爱美之心，无可厚非，但吸取更有营养的内容，增加自己的涵养，戒除浮躁，懂心交流，才是高情商的选择。
&amp;ndash; 玛德，在dropbox上下个插图搞了一个小时
本文链接地址： http://xgknight.com/2015/07/14/nice-is-not-nice/</description>
    </item>
    
    <item>
      <title>EC的第一天</title>
      <link>http://xgknight.com/posts/2015/07/ec%E7%9A%84%E7%AC%AC%E4%B8%80%E5%A4%A9/</link>
      <pubDate>Tue, 07 Jul 2015 00:49:31 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2015/07/ec%E7%9A%84%E7%AC%AC%E4%B8%80%E5%A4%A9/</guid>
      <description>第一天入职 EC，总体感觉还不错，就是不知道日后的工作怎样。eva给我们五个介绍了公司的制度和福利，公共免费wifi，下午四点下午茶有水果，办公电脑不限网（中午休息时间竟然有人直接打dota，还有看动漫的）。sunny跟我们签的2年合同。好了夸完说说其他的感受。
公司产品——EC营客通。主要这一个产品，有web、PC、android、IOS平台，而且主要卖点是与腾讯qq无缝连接，同时也能连接手机通讯录、邮箱、excel，号称“连接一切”，不然怎么叫 Easy Connection 。试用了移动端，其实功能很简单:支持各种数据来源的导入，加比较全的手机通讯录功能，，再加定时提醒功能（这不是最近我在试用的 『滴答清单』的功能吗），最后是外勤签到和统计的功能。并没有多少先进的科学方法，或令人眼前一亮的新功能。
PC端的功能稍微复杂一点，但界面简直就是qq的副本，没了qq秀和游戏广告。这不禁让我想到了企业qq RTX，四像四不像。我想ec存在的价值在于，让员工有意识的通过工具去区分工作和生活。至于要做中国的Salesforce，路途还非常非常遥远，因为它“不止连接”。
至于我很早就了解到的纷享销客，内部培训的时候除了说方向不一样外，还有贬低对手的意思，什么操作性crm与分析型crm。试用了一把，纷享销客也有分析统计预测的功能，走的路线确实完全不一样，似乎fxiaoke更注重于流程审批、知识共享、外勤签到等功能。究竟哪一个是以后的方向，还是各自结合，还很难说。salesforce估值400多亿肯定是有它的道理，如果2年之内没达到sf现在的原型，就很难有更大发展了。
晕，怎么上班第一天胡乱评价自家产品。
以后上下班要挤地铁高峰期了，告别了班车福利，似乎以前坐班车从窗户旁看到了公车上的自己。
现在在想，第二份工作要给自己角色上一个怎样的转变呢，我隐约的感觉到不在甘于这个小弟的角色，而是需要主动在运维团队里推进工作、提出建设性意见的人。听桂哥和超哥的意思，以后工作的关键词大概是kvm, docker, zabbix, saltstack，还是希望能够接触到数据库、开发和架构方面的内容。加油↖(^ω^)↗！
本文链接地址： http://xgknight.com/2015/07/07/ec-the-first-day/</description>
    </item>
    
    <item>
      <title>解答一个关于日志系统的思路</title>
      <link>http://xgknight.com/posts/2015/06/%E8%A7%A3%E7%AD%94%E4%B8%80%E4%B8%AA%E5%85%B3%E4%BA%8E%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%80%9D%E8%B7%AF/</link>
      <pubDate>Tue, 09 Jun 2015 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2015/06/%E8%A7%A3%E7%AD%94%E4%B8%80%E4%B8%AA%E5%85%B3%E4%BA%8E%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%80%9D%E8%B7%AF/</guid>
      <description>在一个群里看到一个面试题，试着去解答一下，毕竟正好花时间了解过日志这方面的内容。
希望能达到的使用场景：
在写业务逻辑时也能进行结构化的log, 并且log被转移到一个数据库， 一个UI前端以这个log数据库为支持， 可以可视化各种指标， 并且保留未来可以对指标进行alarm的可能性
希望从两个方面考虑这个问题：
技术通路实现。 在每一步会用些什么技术? 一些核心组件比如log采集和log数据库有哪些已有方案， 是否有优劣？ 从运维角度看， 这套系统可能在哪些方面有需要考量的地方。 比如log采集是否会影响业务进程？ log数据库的运维可能遇到哪些问题？ 可以看出问题提出者比较在意解决这些问题过程中的思维方式和学习能力，弱化实践经验的要求。
首先根据要求确认一下要达到效果：
log日志采集 log存储 log展示 alarm报警(附加) 1 确定日志流向/架构 因为一开始脑海里也不知道原型是怎样的，就是以前用过linux自带的rsyslog功能感觉很类似：在日志服务器上通过配置rsyslog存入mysql的插件，而其它的各个服务器上默认rsyslog都是开启的，修改conf的系统日志、mail、cron等不输出到本地，而是指向mysql数据库。前端通过loganalyzer从数据库获取数据，图形化显示（简陋到不想说了。。。），但是显示的柱形图/饼图没有什么意义，默认对系统messages处理比较方便，要记录nginx或业务逻辑的log还需做其它额外操作。
但rsyslog并不是一无是处，它的整个架构特别是消息队列的设计，跟后面要讲的许多分布式日志系统是很像的。所以脑海里日记采集的原型出来了：
业务逻辑的日志输出到文件file，服务上的日志采集客户端agent实时监控这个logfile，作为输入；日志中心服务器server接受来自agent的消息，存入后端数据库。另有一个UI从这个数据库取得数据显示，并提供搜索、统计图表。 然而有以下几个问题需要考虑，这也就是为什么出现各种开源解决方案： 日志产生数量过大，不能及时发送到server怎么办 可以使用队列或redis来缓冲 日志中心服务器server故障怎么办，肯定不能丢失日志，即可靠性 有的解决办法是对 log server 做集群，通过zookeeper来同步配置；有的是在agent上本地暂时存放，等恢复后重新传输，redis就可以承担这个角色 考虑到这个日志平台的可扩展性，新的日志来源input不一定是file，比如rsyslog 至少需要支持常用的input 是否支持过滤功能 filter可以在日志发送之前就把不匹配的日志内容排除掉 log结构化 收集的日志初始是一长字符串，为了后面使用方便，需要将日志结构化存储（后面会有说明） 存储采用关系型数据库对海量日志存储，性能肯定很大问题 log日志存储没有一致性的要求，甚至可以说一条日志根本就没意义，而是需要通过大量的日志，通过分析、比较趋势具备用处。于是日志的存储各显大招，主流有两种：hadoop分布式文件系统HDFS，elasticsearch（后面简称es）全文搜索引擎，它们都具备很强的可伸缩性和多节点高可用性 由于存储方式的不同，数据分析与展示也就有各自的阵营 HDFS一般采用MapReduce处理数据，es既可以通过其丰富的插件显示或搜索数据，也可以通过推荐使用的kibana来展示数据 总结下来大致流程图如下：
2 log结构化 当然可能你一直存在这样一个疑问：log的结构化问题处理
代码里logger的内容大概是timestamp,log_level,module,message&amp;hellip; ，一下是nginx的access示例：
172.16.30.88 - [08/Jun/2015:00:08:38 +0800] &amp;#34;POST /notice/statement_findStatementVByPage.htm?1433637553824 HTTP/1.1&amp;#34; 200 114 &amp;#34;http://service.tp-link.net/&amp;#34; &amp;#34;Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)&amp;#34; 处理这条非结构话的字符串或消息，无非就是在它发送到日志中心之前格式化，像最简单的rsyslog处理方法是通过数据库表字段Mapping来存放，而es则是通过编写Grok规则来结构化，如将IP、日期、请求方式、响应状态码、响应时间等组合成json字符串。（然而Grok写起来是非常痛苦的，以至于官方github上专门维护了一份通用规则表）</description>
    </item>
    
    <item>
      <title>Linux进阶培训-tplink</title>
      <link>http://xgknight.com/posts/2014/10/linux%E8%BF%9B%E9%98%B6%E5%9F%B9%E8%AE%AD-tplink/</link>
      <pubDate>Mon, 06 Oct 2014 16:32:49 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/2014/10/linux%E8%BF%9B%E9%98%B6%E5%9F%B9%E8%AE%AD-tplink/</guid>
      <description>本文没啥实际内容，是给新人做linux培训的第二课进阶篇，主要着眼于体系，把一些工具混个眼熟。
目录 Linux磁盘管理(进阶) Linux内存管理 Linux进程管理(进阶) Linux网络管理(进阶) Linux系统状态监控与调优 常见服务 Linux安全策略 其他 Linux磁盘管理（进阶） ext4文件系统格式 Inode、block、superblock、MBR VFS LVM pv、lv、vg lvdisplay、lvextend、vgdisplay、pvcreate… RAID raid0、raid1、raid5、raid10 r/w速度、磁盘利用率、安全性的权衡 磁盘IO性能 dd、iostat、iotop I/O等待 Linux内存管里（基础） 物理内存与虚拟内存 Swap space，分页存取 buffer与cache区分 内存监控命令 free、vmstat /proc文件系统 Linux进程管理（进阶） 进程与线程 进程优先级 进程监控命令 pidstat、lsof strace（系统调用跟踪） 后台进程 Ctrl+z、jobs、bg、fg、&amp;amp;、nohup screen Linux的网络管理 一些概念
防火墙
路由/网关
子网掩码
网络接口（参数）
MAC
TCP/IP协议
应用层协议
Linux网络管理 iptables
Linux网络管理 主机网络流量监控 iftop、iptraf、sar tcpdump抓包 wireshark数据包分析工具 ##Linux网络管理
iproute2 ip、ss Linux系统状态监控与调优 一些工具 sar、sysstat perf、logwatch 一些配置文件 sysctl.conf limits.conf Linux安全策略 禁止root直接登录 锁定不使用的账号 关闭ipv6 启用防火墙 定期检查日志 … Linux常见服务 tcp_wrappers SSH postfix FTP NFS/Samba DNS Apache/nginx … Linux其他 Linux开机过程分析 pam模块解读lsmod 编译make、ldd、ldconfig、gcc、gdb ACL Linux集群 内核模块 linux编程 … 本文链接地址：http://xgknight.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: apache+3tomcat+jk+memcached集群环境搭建 date: 2014-10-29 10:21:25 updated: 2015-03-26 00:46:23 tags: [apache, tomcat, 集群, mod_jk, memcached, centos] categories: [Linux, Web_Server] 注意本文不讨论原理，只讲述具体的搭建过程，而且步骤都经过了整理，否则过程可能会出现其他异常，请自行google。apache与tomcat整合的方式除了jk之外，使用apache自带的mod_ajp_proxy模块也可以很方便的完成。 先来看一下架构图： 属于正式环境中原session复制方案的改进。
1. 所需软件包 jrrt-3.1.2-1.6.0-linux-x64.bin（或jdk1.6.0_33） jvm httpd-2.2.26.tar.gz web服务器，处理静态资源 apache-tomcat-6.0.32.tar.gz 应用服务器，Servlet容器处理动态请求 tomcat-connectors-1.2.30-src.tar.gz apache与tomcat整合插件mod_jk.so tomcat-native.tar.gz APR加速tomcat，提高线程并发能力。使用tomcat自带版本。 memcached-session-manager 使用msm解决多tomcat集群时session同步问题所需jar包 asm-3.2.jar, couchbase-client-1.2.2.jar, kryo-1.04.jar, kryo-serializers-0.11.jar msm-kryo-serializer-1.6.5.jar memcached-session-manager-1.6.5.jar memcached-session-manager-tc6-1.6.5.jar minlog-1.2.jar, reflectasm-1.01.jar spymemcached-2.10.2.jar 2. 安装过程 2.1 JDK 下载将JRockit二进制安装文件，赋予可执行权限
# pwd /apps/test/java # chmod o+x jrrt*.bin # ./jrrt-3.1.2-1.6.0-linux-x64.bin 可不必为整个linux环境设置JAVA_HOME=&amp;quot;/apps/test/java/jrrt-3.1.2-1.6.0&amp;quot;，在tomcat中指定即可。
2.2 编译安装apache 因为tomcat-native依赖于apr，所以这里先直接从 httpd-2.2.26/srclib 目录下安装apache自带的apr和apr-util。
[root@cachets httpd-2.2.26]# pwd /apps/test/soft_src/httpd-2.2.26 [root@test httpd-2.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 我为何厌恶百度的产品 date: 2015-02-28 15:21:25 updated: 2015-02-28 16:46:23 tags: feelings categories: Feel 今天因为使用百度云同步盘出错，导致我的文件永远丢失，忍无可忍又给“百度倾听”发了条牢骚。
事情是这样的，我在 MarkdownPad2 修改最近写的3篇文章，文章正好在百度云同步盘的同步目录下，因为一直养成了一边编辑一边Ctrl+S保存的习惯，难道由于这3篇文章反复修改，百度云同步盘竟然支撑不住？弹出窗口大概是说同步出错，需要重启应用（近期出现过好几次），随手点了个确定，MarkdownPad2提示我当前编辑的文件不存在，是否继续保留在窗口，反正文章修改完了，也没多想，duang，悲剧发生了，两个小星期的成果都不见了。还在失落当中……
为什么叫“又”呢，因为在去年1月份的时候也在手机上使用过百度云同步盘，不记得是同步什么，也不是文件丢失。Android版有一个“仅在wifi下同步”的选项，像我这种3G流量哪够同步文件使用啊，当时还觉得挺贴心的，开着应用在后台一上午，中午吃饭拿起手看时，尼玛提示我本月流量已超50多M，也给百度意见反馈写了200多字的声讨书，结果几天后回复的内容不知是从哪摘抄的一段无价值的内容。还有一次是登录注销的问题，20多天后才回复邮件，结尾还不忘带上小米的广告，简直让用户抓狂。（邮件正文就不贴了，每每出现这样的问题都十分狂躁，不少脏话）
我想这样的同步工具最多对于百度是个附属产品，并不能带来多大收益，在团队投入上并不尽心。给我自己的教诲是，选择产品或工具，不能因为公司名声大而就给予信任，一个公司能够把一件事情做好了就会迎来不错的口碑，选择它的主打产品。说到这里不得不继续吐槽了，百度搜索应该是它的命脉了，但对于我用习惯了google来说，没有条件不得不使用百度搜索，索引到的结果，唉~ 大！惊！失！色！
如此种种，不得不让我怀疑百度其他产品的使用问题。
无奈 Dropbox 在国内被封，也只有偶尔在家用电脑时打开VPN才能访问，被百度云同步盘伤过那么多次心之后，感觉再也不会用了，还是老老实实挂VPN吧，虽麻烦但也免去了不必要的担忧。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 搭建docker内网私服（docker-registry with nginx&amp;amp;ssl on centos） date: 2014-11-13 20:21:25 updated: 2014-12-25 15:46:23 tags: [docker, centos, docker-registry, nginx, ssl] categories: [Virtualization, Docker] 主要思路： 1. Docker Registry 说明 关于如何创建和使用本地仓库，其实已经有很多文章介绍了。因为docker技术正处于发展和完善阶段，所以有些文章要么内容已经过时，要么给出了错误的配置，导致无法正常创建仓库。本文记录的是个人完整的搭建过程，docker version为1.1.2。
官方提供了Docker Hub网站来作为一个公开的集中仓库。然而，本地访问Docker Hub速度往往很慢，并且很多时候我们需要一个本地的私有仓库只供网内使用。
Docker仓库实际上提供两方面的功能，一个是镜像管理，一个是认证。前者主要由docker-registry项目来实现，通过http服务来上传下载；后者可以通过docker-index（闭源）项目或者利用现成认证方案（如nginx）实现http请求管理。
docker-registry既然也是软件应用，自然最简单的方法就是使用官方提供的已经部署好的镜像registry。官方文档中也给出了建议，直接运行sudo docker run -p 5000:5000 registry命令。这样确实能启动一个registry服务器，但是所有上传的镜像其实都是由docker容器管理，放在了/var/lib/docker/&amp;hellip;.某个目录下。而且一旦删除容器，镜像也会被删除。因此，我们需要想办法告诉docker容器镜像应该存放在哪里。registry镜像中启动后镜像默认位置是/tmp/registry，因此直接映射这个位置即可，比如到本机的/opt/data/registry目录下。
2. 在CentOS上搭建docker私服 2.1 安装docker-registry 方法有多种，直接运行下面的命令：
# docker run -d -e SETTINGS_FLAVOR=dev -e STORAGE_PATH=/tmp/registry -v /opt/data/registry:/tmp/registry -p 5000:5000 registry 如果本地没有拉取过docker-registry，则首次运行会pull registry，运行时会映射路径和端口，以后就可以从/opt/data/registry下找到私有仓库都存在哪些镜像，通过主机的哪个端口可以访问。 你也可以把项目 https://github.com/docker/docker-registry.git 克隆到本地，然后使用Dockerfile来build镜像：
# git clone https://github.com/docker/docker-registry.git # cd docker-registry &amp;amp;&amp;amp; mkdir -p /opt/data/registry # docker build -t &amp;#34;local-sean&amp;#34; .</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: docker常用管理命令（上） date: 2014-10-31 20:21:25 updated: 2014-11-05 15:46:23 tags: [docker, command] categories: [Linux, Docker] 本文只记录docker命令在大部分情境下的使用，如果想了解每一个选项的细节，请参考官方文档，这里只作为自己以后的备忘记录下来。
根据自己的理解，总的来说分为以下几种： 容器生命周期管理 — docker [run|start|stop|restart|kill|rm|pause|unpause] 容器操作运维 — docker [ps|inspect|top|attach|events|logs|wait|export|port] 容器rootfs命令 — docker [commit|cp|diff] 镜像仓库 — docker [login|pull|push|search] 本地镜像管理 — docker [images|rmi|tag|build|history|save|import] 其他命令 — docker [info|version]
看一个变迁图 1. 列出机器上的镜像（images） # docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE ubuntu 14.10 2185fd50e2ca 13 days ago 236.9 MB … 其中我们可以根据REPOSITORY来判断这个镜像是来自哪个服务器，如果没有 / 则表示官方镜像，类似于username/repos_name表示Github的个人公共库，类似于regsistory.example.com:5000/repos_name则表示的是私服。 IMAGE ID列其实是缩写，要显示完整则带上--no-trunc选项
2. 在docker index中搜索image（search） Usage: docker search TERM # docker search seanlo NAME DESCRIPTION STARS OFFICIAL AUTOMATED seanloook/centos6 sean&amp;#39;s docker repos 0 搜索的范围是官方镜像和所有个人公共镜像。NAME列的 / 后面是仓库的名字。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: docker常用管理命令（下） date: 2014-11-05 16:21:25 updated: 2014-11-05 19:46:23 tags: [docker, command,linux] categories: [Virtualization, Docker] 本文承接docker专题(2)：docker常用管理命令（上）。
1. 开启/停止/重启container（start/stop/restart） 容器可以通过run新建一个来运行，也可以重新start已经停止的container，但start不能够再指定容器启动时运行的指令，因为docker只能有一个前台进程。 容器stop（或Ctrl+D）时，会在保存当前容器的状态之后退出，下次start时保有上次关闭时更改。而且每次进入attach进去的界面是一样的，与第一次run启动或commit提交的时刻相同。
CONTAINER_ID=$(docker start &amp;lt;containner_id&amp;gt;) docker stop $CONTAINER_ID docker restart $CONTAINER_ID 关于这几个命令可以通过一个完整的实例使用：docker如何创建一个运行后台进程的容器并同时提供shell终端。
2. 连接到正在运行中的container（attach） 要attach上去的容器必须正在运行，可以同时连接上同一个container来共享屏幕（与screen命令的attach类似）。 官方文档中说attach后可以通过CTRL-C来detach，但实际上经过我的测试，如果container当前在运行bash，CTRL-C自然是当前行的输入，没有退出；如果container当前正在前台运行进程，如输出nginx的access.log日志，CTRL-C不仅会导致退出容器，而且还stop了。这不是我们想要的，detach的意思按理应该是脱离容器终端，但容器依然运行。好在attach是可以带上 --sig-proxy=false来确保CTRL-D或CTRL-C不会关闭容器。
# docker attach --sig-proxy=false $CONTAINER_ID 3. 查看image或container的底层信息（inspect） inspect的对象可以是image、运行中的container和停止的container。
查看容器的内部IP # docker inspect --format=&amp;#39;{\{.NetworkSettings.IPAddress}}&amp;#39; $CONTAINER_ID 172.17.42.35 （注：由于代码块解析的问题，上面NetworkSettings前面的 \ 去掉） 4. 删除一个或多个container、image（rm、rmi） 你可能在使用过程中会build或commit许多镜像，无用的镜像需要删除。但删除这些镜像是有一些条件的：
同一个IMAGE ID可能会有多个TAG（可能还在不同的仓库），首先你要根据这些 image names 来删除标签，当删除最后一个tag的时候就会自动删除镜像； 承上，如果要删除的多个IMAGE NAME在同一个REPOSITORY，可以通过docker rmi &amp;lt;image_id&amp;gt;来同时删除剩下的TAG；若在不同Repo则还是需要手动逐个删除TAG； 还存在由这个镜像启动的container时（即便已经停止），也无法删除镜像； TO-DO 如何查看镜像与容器的依存关系
** 删除容器 ** docker rm &amp;lt;container_id/contaner_name&amp;gt;</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 【转+改】Docker核心技术预览 date: 2014-12-18 13:21:25 updated: 2014-12-18 15:46:23 tags: [docker, linux, lxc, cgroup, aufs] categories: [Virtualization, Docker] 本文简单介绍docker使用到的部分核心技术，但不做深入探究，因为每一个技术都是一个独立的项目，有机会再分别详细介绍。 来源地址：http://www.infoq.com/cn/articles/docker-core-technology-preview
Linux Namespace （实例隔离）## The purpose of each namespace is to wrap a particular global system resource in an abstraction that makes it appear to the processes within the namespace that they have their own isolated instance of the global resource.
每个用户实例之间相互隔离，互不影响。一般的硬件虚拟化方法给出的方法是VM，而LXC给出的方法是container，更细一点讲就是kernel namespace。其中pid、net、ipc、mnt、uts、user等namespace将container的进程、网络、消息、文件系统、UTS(&amp;ldquo;UNIX Time-sharing System&amp;rdquo;)和用户空间隔离开。
pid namespace 不同用户的进程就是通过pid namespace隔离开的，且不同 namespace 中可以有相同pid。所有的LXC进程在docker中的父进程为docker进程，每个lxc进程具有不同的namespace。同时由于允许嵌套，因此可以很方便的实现 Docker in Docker。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 在 CentOS 6.x上安装 docker.io成功 date: 2014-10-26 19:45:25 updated: 2014-10-27 10:46:23 tags: [docker, centos,linux] categories: [Virtualization, Docker] docker是什么就不多说了，见docker基础原理介绍。 docker容器最早受到RHEL完善的支持是从最近的CentOS 7.0开始的，官方说明是只能运行于64位架构平台，内核版本为2.6.32-431及以上（即&amp;gt;=CentOS 6.5，运行docker时实际提示3.8.0及以上），升级内核请参考CentOS 6.x 内核升级（2.6.32 -&amp;gt; 3.10.58）过程记录 需要注意的是CentOS 6.5与7.0的安装是有一点点不同的，CentOS-6上docker的安装包叫docker-io，并且来源于Fedora epel库，这个仓库维护了大量的没有包含在发行版中的软件，所以先要安装EPEL，而CentOS-7的docker直接包含在官方镜像源的Extras仓库（CentOS-Base.repo下的[extras]节enable=1启用）。前提是都需要联网，具体安装过程如下。 ###1. 禁用selinux###
# getenforce enforcing # setenforce 0 permissive # vi /etc/selinux/config SELINUX=disabled ... ###2. 安装 Fedora EPEL### epel-release-6-8.noarch.rpm包在发行版的介质里面已经自带了，可以从rpm安装。
# yum install epel-release-6-8.noarch.rpm //或 yum -y install http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm 如果出现GPG key retrieval failed: [Errno 14] Could not open/read file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6问题，请在线安装epel，下载RPM-GPG-KEY-EPEL-6文件。 这一步执行之后，会在/etc/yum.repos.d/下生成epel.repo、epel-testing.repo两个文件，用于从Fedora官网下载rpm包。 ###3. 检查内核版本###
# uname -r 2.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: Docker简介 date: 2014-12-18 11:21:25 updated: 2014-12-18 18:46:23 tags: [docker, linux] categories: [Virtualization, Docker] 1. docker是什么 Docker is an open-source engine that automates the deployment of any application as a lightweight, portable, self-sufficient container that will run virtually anywhere.
Docker是 PaaS 提供商dotCloud开源的一个基于 LXC 的高级容器引擎， 源代码托管在 Github 上, 基于go语言并遵从Apache2.0协议开源。Docker近期非常火热，无论是从 GitHub 上的代码活跃度，还是Redhat宣布在RHEL7中正式支持Docker，都给业界一个信号，这是一项创新型的技术解决方案。就连 Google 公司的 Compute Engine 也支持 docker 在其之上运行，国内“BAT”先锋企业百度Baidu App Engine(BAE)平台也是以Docker作为其PaaS云基础。
Docker产生的目的就是为了解决以下问题：
环境管理复杂：从各种OS到各种中间件再到各种App，一款产品能够成功发布，作为开发者需要关心的东西太多，且难于管理，这个问题在软件行业中普遍存在并需要直接面对。Docker可以简化部署多种应用实例工作，比如Web应用、后台应用、数据库应用、大数据应用比如Hadoop集群、消息队列等等都可以打包成一个Image部署。 云计算时代的到来：AWS的成功，引导开发者将应用转移到云上, 解决了硬件管理的问题，然而软件配置和管理相关的问题依然存在 (AWS cloudformation是这个方向的业界标准, 样例模板可参考这里)。Docker的出现正好能帮助软件开发者开阔思路，尝试新的软件管理方法来解决这个问题。 虚拟化手段的变化：云时代采用标配硬件来降低成本，采用虚拟化手段来满足用户按需分配的资源需求以及保证可用性和隔离性。然而无论是KVM还是Xen，在 Docker 看来都在浪费资源，因为用户需要的是高效运行环境而非OS，GuestOS既浪费资源又难于管理，更加轻量级的LXC更加灵活和快速。 LXC的便携性：LXC在 Linux 2.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 开源容器集群管理系统Kubernetes架构及组件介绍 date: 2015-02-03 13:21:25 updated: 2014-02-03 15:46:23 tags: [docker, linux, kubernetes] categories: [Virtualization, Docker] 本文来源于Infoq的一篇文章（见参考部分），并在难懂的地方自己理解的基础上做了修改。实际在ubuntu上部署 kubernetes 操作另见 文章 。
Together we will ensure that Kubernetes is a strong and open container management framework for any application and in any environment, whether in a private, public or hybrid cloud. &amp;ndash;Urs Hölzle, Google
Kubernetes 作为Docker生态圈中重要一员，是Google多年大规模容器管理技术的开源版本，是产线实践经验的最佳表现。如Urs Hölzle所说，无论是公有云还是私有云甚至混合云，Kubernetes将作为一个为任何应用，任何环境的容器管理框架无处不在。正因为如此，目前受到各大巨头及初创公司的青睐，如Microsoft、VMWare、Red Hat、CoreOS、Mesos等，纷纷加入给Kubernetes贡献代码。随着Kubernetes社区及各大厂商的不断改进、发展，Kuberentes将成为容器管理领域的领导者。
接下来我们一起探索Kubernetes是什么、能做什么以及怎么做。
1. 什么是Kubernetes Kubernetes是Google开源的容器集群管理系统，使用Golang开发，其提供应用部署、维护、扩展机制等功能，利用Kubernetes能方便地管理跨机器运行容器化的应用，其主要功能如下：
使用Docker对应用程序包装(package)、实例化(instantiate)、运行(run)。 以集群的方式运行、管理跨机器的容器。 解决Docker跨机器容器之间的通讯问题。 Kubernetes的自我修复机制使得容器集群总是运行在用户期望的状态。 当前Kubernetes支持GCE、vShpere、CoreOS、OpenShift、Azure等平台，除此之外，也可以直接运行在物理机上。
这个官方给出的完整的架构图：（可在新标签页打开查看大图）
2. Kubernetes的主要概念 2.1 Pods 在Kubernetes系统中，调度的最小颗粒不是单纯的容器，而是抽象成一个Pod，Pod是一个可以被创建、销毁、调度、管理的最小的部署单元。把相关的一个或多个容器（Container）构成一个Pod，通常Pod里的容器运行相同的应用。Pod包含的容器运行在同一个Minion(Host)上，看作一个统一管理单元，共享相同的volumes和network namespace/IP和Port空间。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 在ubuntu上部署Kubernetes管理docker集群示例 date: 2015-02-07 13:21:25 updated: 2014-02-07 15:46:23 tags: [docker, linux, kubernetes] categories: [Virtualization, Docker] 本文通过实际操作来演示Kubernetes的使用，因为环境有限，集群部署在本地3个ubuntu上，主要包括如下内容：
部署环境介绍，以及Kubernetes集群逻辑架构 安装部署Open vSwitch跨机器容器通信工具 安装部署Etcd和Kubernetes的各大组件 演示Kubernetes管理容器和服务 关于 Kubernetes 系统架构及组件介绍见这里。
1. 部署环境及架构 vSphere: 5.1 操作系统: ubuntu 14.04 x86_64 Open vSwith版本: 2.0.2 Kubernetes: v0.7.2 Etcd版本: 2.0.0-rc.1 Docker版本: 1.4.1 服务器信息： Role Hostname IP Address APIServer kubernetes 172.29.88.206 Minion minion1 172.29.88.207 Minion minion2 172.29.88.208 在详细介绍部署Kubernetes集群前，先给大家展示下集群的逻辑架构。从下图可知，整个系统分为两部分，第一部分是Kubernetes APIServer，是整个系统的核心，承担集群中所有容器的管理工作；第二部分是minion，运行Container Daemon，是所有容器栖息之地，同时在minion上运行Open vSwitch程序，通过GRE Tunnel负责minions之间Pod的网络通信工作。 2. 安装Open vSwitch及配置GRE 为了解决跨minion之间Pod的通信问题，我们在每个minion上安装Open vSwtich，并使用GRE或者VxLAN使得跨机器之间P11od能相互通信，本文使用GRE，而VxLAN通常用在需要隔离的大规模网络中。对于Open vSwitch的介绍请参考另一篇文章Open vSwitch。
sudo apt-get install openvswitch-switch bridge-utils 安装完Open vSwitch和桥接工具后，接下来便建立minion0和minion1之间的隧道。首先在minion1和minion2上分别建立OVS Bridge：</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: docker如何创建一个运行后台进程的容器并同时提供shell终端 date: 2014-11-03 20:21:25 updated: 2014-11-07 15:46:23 tags: [docker, shell, linux] categories: [Virtualization, Docker] 只看标题还不是很明显，本文实现docker的这样一种比较常用的功能：通过docker run启动一个容器后，容器中已经运行了一个后台进程（这里以监听80端口的nginx为例），同时进入一个shell终端可供操作，而不受限于只能在前台运行nginx与运行shell终端之间的一种。这个例子实现了，那么其他类似的运行多任务docker就可以以此类推。另外本文还提供了一种在docker容器内部安装软件（vim）的方法，对于定制自己需要的镜像大有帮助。 你可能需要先阅读docker专题(2)：docker常用管理命令（上）、docker专题(2)：docker常用管理命令（下）来理解更多。
1. 已经pull了官方的nginx 1.7.6的镜像（也可以从私服获取）## # docker images|grep nginx nginx 1.7.6 561ed4952ef0 10 days ago 100 MB 2. 根据官方指示启动这个容器 先做好自己要显示的页面 # echo &amp;#34;&amp;lt;h2 &amp;gt;This is nginx official container running &amp;lt;/h2&amp;gt; &amp;lt;br /&amp;gt; static files:/tmp/doccker/index.html&amp;#34; &amp;gt; /tmp/docker/index.html 使用官方image启动一个容器，名字nginx_dist，把host的目录（包含刚才的html）映射到容器中nginx server的root，绑定80端口：
# docker run --name nginx_dist -v /tmp/docker:/usr/share/nginx/html:ro \ &amp;gt; -p 80:80 -d nginx:1.7.6 1b10b08d7905517a26c72ce8b17b719aaea5e5eac0889263db8b017427e3c8f7 # docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 1b10b08d7905 nginx:1 nginx -g &amp;#39;daemon off 51 seconds ago Up 48 seconds 443/tcp, 0.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: Docker集中化web界面管理平台shipyard date: 2014-12-29 13:21:25 updated: 2014-12-29 15:46:23 tags: [docker, linux, shipyard] categories: [Virtualization, Docker] Shipyard（github）是建立在docker集群管理工具Citadel之上的可以管理容器、主机等资源的web图形化工具。包括core和extension两个版本，core即shipyard主要是把多个 Docker host上的 containers 统一管理（支持跨越多个host），extension即shipyard-extensions添加了应用路由和负载均衡、集中化日志、部署等。
1. 几个概念 engine 一个shipyard管理的docker集群可以包含一个或多个engine（引擎），一个engine就是监听tcp端口的docker daemon。shipyard管理docker daemon、images、containers完全基于Docker API，不需要做其他的修改。另外，shipyard可以对每个engine做资源限制，包括CPU和内存；因为TCP监听相比Unix socket方式会有一定的安全隐患，所以shipyard还支持通过SSL证书与docker后台进程安全通信。
rethinkdb RethinkDB是一个shipyard项目的一个docker镜像，用来存放账号（account）、引擎（engine）、服务密钥（service key）、扩展元数据（extension metadata）等信息，但不会存储任何有关容器或镜像的内容。一般会启动一个shipyard/rethinkdb容器shipyard-rethinkdb-data来使用它的/data作为数据卷供另外rethinkdb一个挂载，专门用于数据存储。
2. 搭建过程 修改tcp监听 Shipyard 要管理和控制 Docker host 的话需要先修改 Docker host 上的默认配置使其监听tcp端口(可以继续保持Unix socket）。有以下2种方式
sudo docker -H tcp://0.0.0.0:4243 -H unix:///var/run/docker.sock -d 启动docker daemon。如果为了避免每次启动都写这么长的命令，可以直接在/etc/init/docker.conf中修改。 修改/etc/default/docker的DOCKER_OPTS DOCKER_OPTS=&amp;quot;-H tcp://127.0.0.1:4243 -H unix:///var/run/docker.sock&amp;quot;。这种方式在我docker version 1.4.1 in ubuntu 14.04上并没有生效。 重启服务 $ sudo docker -H tcp://0.0.0.0:4243 -H unix:///var/run/docker.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: Dockerfile指令详解 date: 2014-11-17 15:21:25 updated: 2014-11-17 15:46:23 tags: [docker, dockerfile, linux] categories: [Virtualization, Docker] Docker可以从Dockerfile中一步一步的读取指令来自动的创建镜像，常使用Dockerfile来创建用户自定义的镜像。格式如下：
# Comment INSTRUCTION arguments 虽然前面的指令大小写不敏感，但习惯性的还是建议大写。docker是严格按照顺序（#注释起来的忽略）运行指令的。 下面逐个来介绍几个必要的指令。
FROM FROM &amp;lt;image&amp;gt; 或 FROM &amp;lt;image&amp;gt;:&amp;lt;tag&amp;gt; 在Dockerfile中第一条非注释INSTRUCTION一定是FROM，它决定了以哪一个镜像作为基准，&amp;lt;image&amp;gt;首选本地是否存在，如果不存在则会从公共仓库下载（当然也可以使用私有仓库的格式）。
RUN RUN &amp;lt;commnad&amp;gt; 或 RUN [&amp;#34;executable&amp;#34;, &amp;#34;param1&amp;#34;, &amp;#34;param2&amp;#34;] RUN指令会在当前镜像的顶层执行任何命令，并commit成新的（中间）镜像，提交的镜像会在后面继续用到。 上面看到RUN后的格式有两种写法。
shell格式，相当于执行/bin/sh -c &amp;quot;&amp;lt;command&amp;gt;&amp;quot;：
RUN apt-get install vim -y exec格式，不会触发shell，所以$HOME这样的环境变量无法使用，但它可以在没有bash的镜像中执行，而且可以避免错误的解析命令字符串：
RUN [&amp;#34;apt-get&amp;#34;, &amp;#34;install&amp;#34;, &amp;#34;vim&amp;#34;, &amp;#34;-y&amp;#34;] 或 RUN [&amp;#34;/bin/bash&amp;#34;, &amp;#34;-c&amp;#34;, &amp;#34;apt-get install vim -y&amp;#34;] 与shell风格相同 ENTRYPOINT ENTRYPOINT命令设置在容器启动时执行命令，如果有多个ENTRYPOINT指令，那只有最后一个生效。有以下两种命令格式：
ENTRYPOINT [&amp;#34;executable&amp;#34;, &amp;#34;param1&amp;#34;, &amp;#34;param2&amp;#34;] 数组/exec格式，推荐 或 ENTRYPOINT command param1 param2 shell格式 比如：</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 只怕时间走的太过匆忙，忘记了躲在角落中的我 date: 2014-12-31 00:21:25 updated: 2014-12-31 00:46:23 tags: [feelings, 总结] categories: Feel 青春是一道明媚的伤痕，疼的酣畅淋漓，走的跌跌撞撞，她不顾一切遍体鳞伤，但仍庆幸，生命中仍有人为她执着与疯狂。
很久没有静下来总结过自己了，拥有大把的自由时间反而没有停下来写写东西。还记得上一次这种类似的总结是在毕业那会儿，qq空间里被各种日志刷屏，于是自己也写过一篇，只是没发，现在也找不到去哪里了。这里就唠一唠过去的2014吧。
完全想不起来2014上半年做过什么事情，就像7月1号换房子之后时间河流断开了一样。一年总的说来，没什么太大变化，很失败。定过的计划，下过的决心，好像没有几件做成的。就拿体重来说，天天喊着要多吃饭，要增肥，可偏偏不爱吃长相不好的肉。这里可能就有拉仇恨的嫌疑了，毕竟嚷嚷要减肥的比要增肥的多的去了。爹妈没生好只能后天自己努力了，于是买了个电子秤，天天在家“吃饱了cheng”——唉声叹气远比眉开眼笑次数多，为了身体也是蛮拼的了。
相比以前来说，比较欣慰的是运动的频率多了，从夏热天一直到10月份，基本每周都会和小明去游泳。经常感到郁闷的是在游泳池里游泳怎么小明还要带上一瓶脉动，我就从来没感到过口渴……不说了，池里的水没少喝，到现在蛙泳还不敢游到中点，真是废。天变凉后，正巧室友要出国，把全新的羽毛球拍放我这，于是不出意外每周都会跟峰哥他们去打球，逐渐的爱上在球场上酣畅淋漓的感觉，从一开始只是玩玩，到有意识的练技术，再到看电视里的比赛，不知不觉快成为一种习惯了，这个习惯与能不能邂逅到运动型的妹子无关 -_-#，是不是，经常去隔壁王叔叔家打洞的小明。。
曾经我是一个比较宅的人，很少出去离校旅行但也不玩游戏，就莫名其妙的忙碌。我讨厌宅，更害怕一个人，所以六七月份找房子的时候从没考虑过单间，人是需要同伴才不会孤独，哪怕是走在路上看到个漂亮姑娘可以来吐槽的“腐友”。但同时我也经常会很安静，比如在下班车上跑到人少座位，一个人占着两个座，靠外的放包，靠窗的看外面，从疲惫的眼睛上取下眼镜，不必看得太清，单曲循环或随机播放着手机里的歌曲，成了装逼犯。下半年也随同事、朋友去阳江、阳朔玩过，爬了两次梧桐山，部门活动也没缺席过，算是改变闷*的历程吧。还计划过找时间去厦门转转，去哈尔滨看雪（不要问我雪是谁），由于种种原因都被搁浅了。
除了频率并不算高的体育锻炼和户外运动，酒桌、KTV也没少去，刚来公司那会儿的几个同事现在也成了最好的朋友，年轻的同龄人在一起也没什么束缚，谁谁过生日撮一顿，好久没聚了就到谁家吃火锅。KTV倒不是我乐意去的地方，玩玩游戏、骰子还可以，唱歌也就只能吧唧跟着吼两句，不能认真。从前就没练过，五音不全，也回不到过去傲娇耍个性，也许我有其它过人之处我自己都没发现呢！如果非到打击我说，“上帝给我关上了一扇门，又顺手帮我关了一扇窗”，那就是逼我破门向前了。
其它方面，可能因为本身一年来并没有什么成就，没攒下多少money，还过着这样安逸的生活，所有偶尔会“痛心疾首”一番，在手机上做个笔记计划点什么，劲头一过又看电视、玩手机去了，还时常忘记给爸妈打电话，即使说在电话里说来说去就那些内容。记得有一次脚踝无缘无故疼起来，最严重的时候都站不住了，成功了领到了来深圳第一份病历，这事在朋友圈散开后让我哥告诉了爸妈，随后几天每天都打电话来问好些没，果然是亲生的…这里还要谢谢周围还有网上留言关心过我的人，岁月淘沙能留下的是何其珍贵。中秋之前特意去广州看过爸妈，前几个月也从香港带了些药去，只是岁月不饶人，而我还太年轻，哥哥生意刚有起色而嫂子马上生小孩，怎么越想压力越大呢，难道这就是属羊的命不好？偶还是相信事在人为吧！
其实有时候觉得我还是挺幸运的，周围很多人都是学习的对象。人不是要成为谁，有的人会侃，有的人会耍，还有的人思考问题敏捷、思维方式不同，可能说起来有点虚无但真真切切是我从不同的人身上感受到的。虽然不必互相过分对比，但我认为正能量的东西还是很愿意去多多接触。根深，暑假来我这逗留过一段时间，它是少数让我觉得读研还是有用的几人，想到什么便说什么，敢于闯荡（有爱大声说啊）；德义，也是跟我睡过同一张床铺的，有明确的规划和目标，有见解（高富帅带我飞）；小明，活泼可爱任性又偶尔带点深沉（求别喷），经常能想他人之未想，会做饭。等等这些优秀的朋友、同学、同事，让我偶尔觉得无所适从，告诉自己未来还有很多事情要做……
工作方面，虽然占据了大部分时间，但并没有那么多可说的，能说的都是槽点。不是吐槽一下网络管理课那群没脑子的，就是工作没啥事闲着淡腾，用同样的话反复回答为什么加班——没事才加班。其实真不是非要加班，因为确实是不加班回家也没事做，看电视玩手机到晚上依然要1点睡觉，正如前面说的就目前这个阶段来说，何必过得太安逸呢。都说在TP的员工成熟起来会很慢，所以闲着闲着就需要自己去思考出路。IT运维的工作（DBA?），在这样有限的环境里，只能靠自己去学习，所以有80%时间我是借着工作内容关联或技术调研的名义在学着其它东西，零碎时间逛逛社区和问答网站。也买了些数据分析与金融方面的书，只是一直没有看过，这也将成为2015年计划的一部分了，权当小说看了。
规划性的东西这里就不说了，自己有个底就行，太过形式或太过庄重都不好。只说一个字，不要闹“2015年新年计划就是搞定2014年那些原定于2013年完成的安排，不为别的，只为兑现2012年时 要完成2011年计划的诺言。”的笑话就OK。
回头看，整篇写起来还真是天马行空，想到哪写到哪，连标题都想不到好一点的，没什么逻辑、文采可言，只是做个记录，剩下的交给心情……</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 五一回来了 date: 2015-05-03 07:01:25 updated: 2015-05-04 00:01:25 tags: feelings categories: Feel ———————— 只是无聊，轻松的写点东西，在 LOFTER上是不需要写标题的
失算了，下午四点到了汽车站，没能买到16:10的汽车，最早也要晚上六点到深圳侨社那班。这原本打算七点就可到深圳，淡定的去会展中心吃个饭啥的，说话算数太不好意思了。
两个小时的等车时间真够无聊的，比在哥哥家里兼工作室要好些。这两天说过来玩，其实也是带任务来的——为哥哥的天猫手表店拍实物图片，借我的MAC一用做背景。我问他卡斯曼、卡西欧官方没给你宝贝图片吗，他说不是，是想拍出自己的特色放在介绍里。千篇一律大家都去旗舰店买了，谁来照顾我们的手表店。想想也是，现在都讲究情怀！看到房间里单反、灯光箱、360度转动盘（不晓得是个什么gui），我几百块的小叶紫檀貔貅手串都派上用场了。看到用心到连饭都没时间煮的份上，我要不要帮忙推广一下呢。
本来打算是今天早点回深圳，可听他说下午还有几块手表要拍，大概要2个小时，我又怎么能无耻的坚持带走电脑呢。临走的时候，哥跟我在qq上说了一句“大老远让你从深圳跑中山来，也没弄点好吃的（也没带你去珠海玩——自己脑补的），太忙太赶了”。八月份再过来，那时候丽景名筑的房子也装修好了，开个入住仪式。昨天也去新房子看了一眼，线路已经全部埋好了，正在给洗手间做防水测试，厅中间还是一堆沙子，只有天花板刷好了乳石灰。六月份能够装修完成，八月份入住，想想那个时候过去，大飘窗、高低儿童床、乐视tv，比现在这个出租屋要好的多了去。可是，可是，这意味着一个很大的问题，哥哥收入用于装修屋子（简单八万的样子），家里在建的四层楼房怎么办？ 昨天跟家里视频，老爸正在算这一笔账，告诉我个数字，30-40万，毛坯房。现在在农村修个房子（四层可以俯瞰全村了）的成本，差不多可以在中小城市买一个90平的。老一辈人还是希望待在家里吧。鸭梨好大，只能这么形容了。
终于上车了，迅速占领了一个排前靠窗的位置坐了下来，正准备戴上耳机听听音乐，一个50来岁的中年人来到旁边坐了下来，他太太坐斜对面靠近走廊。然后问我说几号座位，我坐了他位置，原本他跟他太太一起坐。于是我就说现在不都没按位置坐吗，正跟他讨论如果真有人计较这个时，让就让呗，有个年青人人过来指着大叔的位置说这是他位置。好吧既然有人认真了，我就收一收我这“乡下来”的不按座位乘车的土鳖气息，但大叔为什么要骗我他跟他太太是一起的邻座。算了，小事不提，滚到了最后一排48号，还好不是正中间走廊的位置，不然一个急刹车就该跟司机say hi了。
不确定到深圳的时间，很抱歉。再写眼睛就花了。ps:刚才汽车颠的一下我敢说飞出了一米高。
——零点更新
等车2个小时不说，路上竟然堵车，虎门大桥原本20分钟的路程竟然走了一个多小时，到晚上将近十点才落车，下车的地方也真特么偏僻，来回半天都没见着竹子林地铁站，果断叫了个的士，到深大地铁站转地铁。法克，那司机竟给绕，原本走深南大道起步价的路程，省省的开到30块，差评投诉！连翻不顺！洗洗睡。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 五一去哪儿 date: 2015-05-01 11:01:25 updated: 2015-05-01 11:01:25 tags: feelings categories: Feel 五一去哪儿，我实在想不到更俗的标题了。去中山。说实在真不想去，我哥非要我带Mac回去让他拍照，给手表做陪衬。ps: 汽车就七个人，车厢也特么烂了，晃晃感觉要散了😳
反正车上无聊，随便说说什么吧！昨晚，嗯，应该是失眠了。第二天睡到下午起来，窝在家里没事做（早知道就不那么快把《权利的游戏》看完了），五点的时候我竟然跑去公司加班了！
加班也没做啥事，帮另一个同事调通了一个网络，然后在自己博客上更新了篇文章。赖到将近晚上八点半才走，本想在猫眼买张西乡天虹『左耳』的电影票，但没位置，想到一天没怎么吃饭（在公司吃了几包肉松饼和华夫饼干），在家门口沃尔玛楼下的爱尚堡点了份豪华午餐，坐了半个多小时起身才回去。晚上走在小区了，总有股淡淡的花香，却从来说不出名字，风吹的头发飘起，真的不是一般爽呢。但因为已经有十点多了，还是加快步伐推开了乌漆抹黑的家门，另外两个室友，一个回宜昌老家参加哥哥婚礼去了，一个去了阴盛阳衰的川大同学会。
虽然今天还要赶车，但早睡这种事情很少发生在我身上。于是打开了电视，体育频道一个人没啥看的，央视一台播放什么劳动光荣的纪录片，五分钟换台了，想想还是去看宣传了很久的芒果台『真正男子汉』。额，杜海涛给我们的笑星形象永远不那么容易消失，这是节目，但也是在军队里，看着他总觉特意的去达到一种节目效果，他来部队参加训练是减肥。王宝强，真是个逗比，在教官检查违禁物品时宝宝那种呆萌老土的模样，笑抽了我，而且在后面打靶时的表现，蛮喜欢他的，他来部队是为了还原『士兵突击』里的许三多形象，想做一名真正的战士，这让我想到了不久前看过吴京的战狼，几次有一种每人都应该去参军的经历。我有个表弟（表哥？），就在去年过年时还跟我一起睡过，五年当兵回来，看他手持真枪的照片，威风凛凛。刘昊然，17岁，想在军队里完成他的成人礼，这名演员以后必火。袁弘，教官说他是一匹还没被驯服的野马，有血性，真男人。郭晓东，40岁的人，有过当兵的经历，可是带病参训，老婆不错😱。张丰毅，将近60岁的人，看过他不少电影，不是折腾，是表率。
看完已经零点半了，什么，明天（5.2）去中山的东西还没收拾，可怕的拖延症。然后就是下了『澳门风云2』『天将雄狮』在手机上打发车上的时间，给充电宝充电、收拾衣服什么的。到了两点多，躺在床上却睡不着觉，空调开着第二天就闹肚子，不开又微热。眼睛眯着眯着，突然有个想法或想说什么，就打开笔记就记录了下来，好奇怪。其中有一个就是突然有个做APP的点子，想法不错，五一假后再查查资料。
现在汽车正在路上飞驰，也坐满了人，旁边那个人的肉能不能不要碰我。就这样，再写下去手机电量怕是不足以支撑一部电影了。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 完全解决Github Pages邮件两次warning（DNS解析问题） date: 2014-11-08 01:21:25 updated: 2014-11-09 00:46:23 tags: [github,troubleshooting] categories: Github 之所以有本文是由于Github前后两次发了2封不同的警告邮件，都是关于DNS配置的。因为xgknight.com刚申请下来时我也是参考其他博客，在seanlook.github.com仓库下面建立了一个CNAME文件，内容：xgknight.com，然后去DNSPod绑定域名和IP（207.97.227.245）访问也就没事了。然而几天之后每次deploy博客的时候都会受到一封build warning邮件（见本文最后），后来参考下面的文章：
解决GitHub Pages Warning邮件提醒 一步步在GitHub上创建博客主页-最新版 — 自定义域名的新玩法 Faster, More Awesome GitHub Pages 和 GitHub Pages Legacy IP Deprecation 但显然第一篇有点拆东墙补西墙，只是换了个离自己最近的服务器，CDN根本就没用上，也是因为我dig seanlook.github.io +nostats +nocomments +nocmd之后把IP改成了103.245.222.133，才有了第二封邮件的warning（见本文最后）。第二篇倒是跟官方（第三条）是同一个意思，但是博主放弃了原本的顶级域名而是用www子域名。 首先根据邮件提示，明确一下最终目的：
使用顶级域名xgknight.com来访问站点 子域名www.xgknight.com跳转到xgknight.com 充分Github Pages提供的cdn加速功能 两份邮件大概是同一个意思，说Github Pages正在进行重大的升级来提供更快的访问速度，所以我们指定的域名解析的IP在不就的将来将要废弃，需要指向一个合法的IP，第二封邮件说的更明确了，为了使用CDN加速功能，需要增加CNAME的子域名解析记录。
如果你正在使用顶级域名（example.com）而不是子域名（如www.example.com），并且你的DNS解析服务提供商不支持ALIAS记录，那么唯一的选择就是使用A记录，但这种配置没有办法利用CDN加速了（依然可以应对DoS攻击）。如果切换成子域名或使用支持ALIAS的DNS解析上，都可以利用CDN和应对DoS。
不料我现在的情形正是，使用顶级域名xgknight.com，DNSPod不支持ALIAS记录。虽然目前不使用CDN加速访问起来没感觉有多大问题，但对于我这种有轻微强迫症并追求完美的人来说，就是看不惯这个warnning。DNS解析服务不想换成付费的支持ALIAS的DNSimple，那么难道只能启用www子域名了吗？对于有些已经对你的网站做了链接的地方，随便修改域名可不是什么好事。于是我就尝试了下面的设置： 在DNSPod中去掉其它映射记录，添加CNAME记录的顶级域名映射到seanlook.github.com，github仓库下的CNAME文件也是顶级域名xgknight.com。经过这样设置后访问xgknight.com发现完全没有问题： 中国境内的ping值：
$ ping xgknight.com 正在 Ping github.map.fastly.net [103.245.222.133] 具有 32 字节的数据: 来自 103.245.222.133 的回复: 字节=32 时间=215ms TTL=42 来自 103.245.222.133 的回复: 字节=32 时间=210ms TTL=42 来自 103.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: php5.3连接oracle的客户端及pdo_oci模块安装 date: 2015-03-10 01:21:25 updated: 2015-03-10 10:46:23 tags: [oracle, php] categories: Linux php连接oracle数据库虽然不是最佳拍档，但组内开发确实有这样需求。如果没有参考合适的文档，这个过程还是挺折磨人的，下面是一个记录，原型是国外的一篇博客 Installing PDO_OCI and OCI8 PHP extensions on CentOS 6.4 64bit。
假设你已经安装好php的环境，php版本为5.3，要连接的oracle服务器是 11g R2，操作系统版本CentOS 6.4 x86_64。如果没有安装php，可以通过以下命令安装：
# yum install php php-pdo # yum install php-devel php-pear php-fpm php-gd php-ldap \ php-mbstring php-xml php-xmlrpc php- zlib zlib-devel bc libaio glibc 假如web服务器使用apache。
1. 安装InstantClient instantclient是oracle的连接数据库的简单客户端，不用安装一个500Moracle客户端就可以连接oracle数据库，有windows和linux版本。从 这里 选择需要的版本下载，只需Basic和Devel两个rpm包。
安装 # rpm -ivh oracle-instantclient11.2-basic-11.2.0.4.0-1.x86_64.rpm # rpm -ivh oracle-instantclient11.2-devel-11.2.0.4.0-1.x86_64.rpm 软链接 # ln -s /usr/include/oracle/11.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: iptables常用实例备查（更新中） date: 2014-02-26 01:21:25 updated: 2014-02-26-12 00:46:23 tags: [iptables,安全] categories: Linux 1. 普通规则 1.1 操作规则 iptables -nL 查看本机关于iptables的设置情况，默认查看的是-t filter，可以指定-t nat
iptables-save &amp;gt; iptables.rule 会保存当前的防火墙规则设置，命令行下通过iptables配置的规则在下次重启后会失效，当然这也是为了防止错误的配置防火墙。默认读取和保存的配置文件地址为/etc/sysconfig/iptables。
设置chain默认策略
iptables -P INPUT DROP iptables -P FORWARD ACCEPT iptables -P OUTPUT ACCEPT 将 INPUT 链默认处理策略设置为DROP，前提是已经存在一条可以访问22端口的规则。这里要说明的是，在添加这类拒绝访问的规则之前，一定要想好执行完，会不会把自己关在防火墙外面，不然就傻眼了。像下面这句。
1.2 限制访问规则 iptables -I INPUT 1 -m state --state RELATED,ESTABLISHED -j ACCEPT 把这条语句插在input链的最前面（第一条），对状态为ESTABLISHED,RELATED的连接放行。 这条规则在某种情况下甚至比下面开放ssh服务都重要：① 如果INPUT连默认为DROP，② INPUT链默认为INPUT，但存在这条规则-A INPUT -j REJECT --reject-with icmp-host-prohibited，上面两种情况下都必须添加--state RELATED,ESTABLISHED为第一条，否则22端口无法通行，把自己锁在防火墙外面了。 有了这条规则，可保证只要当前ssh没有关闭，哪怕防火墙忘记开启22端口，也可以继续连接。
iptables -A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT 允许所有，不安全，默认。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: iptables防火墙原理详解 date: 2014-02-23 01:21:25 updated: 2014-02-23-12 00:46:23 tags: [iptables,安全] categories: Linux 1. netfilter与iptables Netfilter是由Rusty Russell提出的Linux 2.4内核防火墙框架，该框架既简洁又灵活，可实现安全策略应用中的许多功能，如数据包过滤、数据包处理、地址伪装、透明代理、动态网络地址转换(Network Address Translation，NAT)，以及基于用户及媒体访问控制(Media Access Control，MAC)地址的过滤和基于状态的过滤、包速率限制等。Iptables/Netfilter的这些规则可以通过灵活组合，形成非常多的功能、涵盖各个方面，这一切都得益于它的优秀设计思想。
Netfilter是Linux操作系统核心层内部的一个数据包处理模块，它具有如下功能：
网络地址转换(Network Address Translate) 数据包内容修改 以及数据包过滤的防火墙功能 Netfilter 平台中制定了数据包的五个挂载点（Hook Point，我们可以理解为回调函数点，数据包到达这些位置的时候会主动调用我们的函数，使我们有机会能在数据包路由的时候改变它们的方向、内容），这5个挂载点分别是PRE_ROUTING、INPUT、OUTPUT、FORWARD、POST_ROUTING。
Netfilter 所设置的规则是存放在内核内存中的，而 iptables 是一个应用层的应用程序，它通过 Netfilter 放出的接口来对存放在内核内存中的 XXtables（Netfilter的配置表）进行修改。这个XXtables由表tables、链chains、规则rules组成，iptables在应用层负责修改这个规则文件。类似的应用程序还有 firewalld 。
1.1 filter、nat、mangle等规则表 filter表
主要用于对数据包进行过滤，根据具体的规则决定是否放行该数据包（如DROP、ACCEPT、REJECT、LOG）。filter 表对应的内核模块为iptable_filter，包含三个规则链：
INPUT链：INPUT针对那些目的地是本地的包 FORWARD链：FORWARD过滤所有不是本地产生的并且目的地不是本地(即本机只是负责转发)的包 OUTPUT链：OUTPUT是用来过滤所有本地生成的包 nat表
主要用于修改数据包的IP地址、端口号等信息（网络地址转换，如SNAT、DNAT、MASQUERADE、REDIRECT）。属于一个流的包(因为包 的大小限制导致数据可能会被分成多个数据包)只会经过这个表一次。如果第一个包被允许做NAT或Masqueraded，那么余下的包都会自动地被做相同的操作，也就是说，余下的包不会再通过这个表。表对应的内核模块为 iptable_nat，包含三个链：
PREROUTING链：作用是在包刚刚到达防火墙时改变它的目的地址 OUTPUT链：改变本地产生的包的目的地址 POSTROUTING链：在包就要离开防火墙之前改变其源地址 mangle表
主要用于修改数据包的TOS（Type Of Service，服务类型）、TTL（Time To Live，生存周期）指以及为数据包设置Mark标记，以实现Qos(Quality Of Service，服务质量)调整以及策略路由等应用，由于需要相应的路由设备支持，因此应用并不广泛。包含五个规则链——PREROUTING，POSTROUTING，INPUT，OUTPUT，FORWARD。
raw表
是自1.2.9以后版本的iptables新增的表，主要用于决定数据包是否被状态跟踪机制处理。在匹配数据包时，raw表的规则要优先于其他表。包含两条规则链——OUTPUT、PREROUTING
iptables中数据包和4种被跟踪连接的4种不同状态：
NEW：该包想要开始一个连接（重新连接或将连接重定向） RELATED：该包是属于某个已经建立的连接所建立的新连接。例如：FTP的数据传输连接就是控制连接所 RELATED出来的连接。--icmp-type 0 ( ping 应答) 就是--icmp-type 8 (ping 请求)所RELATED出来的。 ESTABLISHED ：只要发送并接到应答，一个数据连接从NEW变为ESTABLISHED,而且该状态会继续匹配这个连接的后续数据包。 INVALID：数据包不能被识别属于哪个连接或没有任何状态比如内存溢出，收到不知属于哪个连接的ICMP错误信息，一般应该DROP这个状态的任何数据。 1.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: iscsi网络存储介绍及客户端配置操作 date: 2015-04-28 01:21:25 updated: 2015-04-29 10:46:23 tags: iscsi categories: Linux 本文不介绍iSCSI服务端的搭建过程，不然就会很累赘。主题就是怎么去完成iscsi网络存储的挂载过程，并顺带介绍一些必要的概念。
1. iscsi介绍与initiator安装 1.1 iSCSI介绍 iSCSI简单来说，就是把SCSI指令通过TCP/IP协议封装起来，在以太网中传输。iSCSI 可以实现在IP网络上传递和运行SCSI协议，使其能够在诸如高速千兆以太网上进行数据存取，实现了数据的网际传递和管理。基于iSCSI建立的存储区域网（SAN）与基于光纤的FC-SAN相比，具有很好的性价比。
iSCSI属于端到端的会话层协议，它定义的是SCSI到TCP/IP的映射（如下图），即Initiator将SCSI指令和数据封装成iSCSI协议数据单元，向下提交给TCP层，最后封装成IP数据包在IP网络上传输，到达Target后通过解封装还原成SCSI指令和数据，再由存储控制器发送到指定的驱动器，从而实现SCSI命令和数据在IP网络上的透明传输。它整合了现有的存储协议SCSI和网络协议TCP/IP，实现了存储与TCP/IP网络的无缝融合。在本文中，将把发起器Initiator称为客户端，将目标器Target称为服务端以方便理解。
iSCSI 服务端和客户端的通讯就是一个在网络上封包和解包的过程，在网络的一端，数据包被封装成包括TCP/IP头、iSCSI 识别包和SCSI 数据三部分内容，传输到网络另一端时，这三部分内容分别被顺序地解开。为了保证安全，iSCSI 有约定操作顺序。在首次运行时，客户端（initiator）设备需要登录到服务端（target）中。任何一个接收到没有执行登录过程的客户端的iSCSI PDU （iSCSI rotocol Data Units，iSCSI 协议数据单元）服务端都将生成一个协议错误，并且关闭连接。在关闭会话之前，服务端可能发送回一个被驳回的iSCSI PDU。
在工作时，iSCSI使SCSI数据块由原来的SCSI总线连接扩展到internet上，这一过程有些产品通过硬件来实现，这种硬件产品被简称为TOE（TCP Offload Engine），随着近年来服务器芯片技术的不断发展，服务器处理能力日益强劲，目前更为普遍的是通过软件来实现SCSI数据块的封装过程。这种软件通常被称为iSCSI Initiator软件/驱动。Initiator软件可以将以太网卡虚拟为iSCSI卡，接受和发送iSCSI数据报文，通过普通以太网卡来进行网络连接，但是需要占用CPU资源。另外的TOE和HBA连接转换方式都需要专门的硬件设备来完成，虽然相对昂贵但执行效率高，也可以减轻主机CPU的负载。本文客户端采用Initiator驱动的连接方式。
1.2 Initiator安装 在Linux 2.6内核中提供了iscsi驱动，iSCSI 驱动（driver）使主机拥有了通过IP网络访问存储的能力，但还需要一个具体的客户端工具（Linux用户空间组件）初始化iSCSI驱动，即iscsi-initiator-utils，也是大家常说的open-iscsi。
# rpm -qa|grep iscsi iscsi-initiator-utils-6.2.0.873-10.el6.x86_64 iscsi-initiator-utils-devel-6.2.0.873-10.el6.x86_64 # rpm -qi iscsi-initiator-utils （yum install iscsi-initiator-utils iscsi-initiator-utils-devel） 这个安装将iscsid、iscsiadm安装到 /sbin 目录下，它还将把默认的配置文件安装到/etc/iscsi/目录下：
/etc/iscsi/iscsid.conf：所有刚发起的iSCSI session默认都将使用这个文件中的参数设定。 /etc/iscsi/initiatorname.iscsi：软件iSCSI initiator的intiator名称配置文件。 确保iscsid和iscsi两个服务器开机自启动，chkconfig --list |grep iscsi，在iscsi启动的时候，iscsid和iscsiadm会读取这两个配置文件。
service iscsid [status|start] service iscsi status 查看iscisi的信息，只有在连接成功后才输出 这里可能遇到start始终没有启动成功的信息输出，请继续往下执行discovery，一般会启动iscsid。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 高效Linux bash快捷键及alias总结 date: 2014-03-09 01:21:25 updated: 2015-05-10 00:46:23 tags: [bash,linux] categories: Linux bash快捷键 习惯使用编辑的快捷键可以大大提高效率，记忆学习过程要有意识的忽略功能键、方向键和数字小键盘。以下快捷键适用在bash处于默认的Emacs模式下，是由一个名为Readline的库实现的，用户可以通过命令bind添加新快捷键，或者修改系统中已经存在的快捷键。（如果你有set -o vi，就处于 vi 模式就不适用了）
另外下面的内容并不包含所有快捷键，只是我个人适用频率最高的几种，但相信已经可以大大提高工作效率了。以下所有 Alt 键可以以 Esc 键代替。
Ctrl + l ：清除屏幕，同clear
Ctrl + a ：将光标定位到命令的开头
Ctrl + e ：与上一个快捷键相反，将光标定位到命令的结尾
Ctrl + u ：剪切光标之前的内容，在输错命令或密码
Ctrl + k ：与上一个快捷键相反，剪切光标之后的内容
Ctrl + y ：粘贴以上两个快捷键所剪切的内容。Alt+y粘贴更早的内容
Ctrl + w ：删除光标左边的参数（选项）或内容（实际是以空格为单位向前剪切一个word）
Ctrl + / ：撤销，同Ctrl+x + Ctrl+u
Ctrl + f ：按字符前移（右向），同→
Ctrl + b ：按字符后移（左向），同←
Alt + f ：按单词前移，标点等特殊字符与空格一样分隔单词（右向），同Ctrl+→</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 在Linux上使用logwatch分析监控日志文件 date: 2014-08-23 01:21:25 updated: 2014-08-23 10:46:23 tags: [logwatch, linux,日志] categories: [Linux] 1. 介绍 在维护Linux服务器时，经常需要查看系统中各种服务的日志，以检查服务器的运行状态。 如登陆历史、邮件、软件安装等日志。系统管理员一个个去检查会十分不方便；且大多时候，这会是一种被动的检查，即只有在发现系统运行异常时才会想到去查看日志以获取异常的信息。那么如何主动、集中的分析这些日志，并产生报告，定时发送给管理员就会显得十分重要。
logwatch 是一款用 Perl 语言编写的开源日志解析分析器。它能对原始的日志文件进行解析并转换成结构化格式的文档，也能根据您的使用情况和需求来定制报告。logwatch 的主要目的是生成更易于使用的日志摘要，并不是用来对日志进行实时的处理和监控的。正因为如此，logwatch 通常被设定好时间和频率的自动定时任务来调度运行或者是有需要日志处理的时候从命令行里手动运行。一旦日志报告生成，logwatch 可以通过电子邮件把这报告发送给您，您可以把它保存成文件或者直接显示在屏幕上。
Logwatch 报告的详细程度和报告覆盖范围是完全可定制化的。Logwatch 的日志处理引擎也是可扩展的，从某种意义上来说，如果您想在一个新的应用程序中使用 logwatch 功能的话，只需要为这个应用程序的日志文件编写一个日志处理脚本（使用 Perl 语言），然后挂接到 logwatch 上就行。
logwatch 有一点不好的就是，在它生成的报告中没有详细的时间戳信息，而原来的日志文件中是存在的。您只能知道被记录下来的一段时间之内的特定事件，如果想要知道精确的时间点的信息，就不得不去查看原日志文件了。
2. 安装与配置说明 2.1 安装 无论在Debian系还是Redhat系上，安装logwatch都非常简单：
# apt-get install logwatch //Debian、Ubuntu.etc # yum install logwatch -y //Redhat、Centos.etc 以下内容基于 CentOS 6.x，其余系统相差不大。
2.2 配置 2.2.1 配置文件说明 安装后的目录文件说明： /usr/share/logwatch default.conf/ # 配置目录 logwatch.conf # 主配置文件，收件人，级别等 logfiles/ # 定义待分析服务的日志文件组路径，相对于/var/log(*.conf) services/ # 自定义需分析日志的Service目录(*.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: linux进程后台运行的几种方式 date: 2014-02-20 11:21:25 updated: 2014-02-20 18:46:23 tags: [linux, shell, 后台进程,screen] categories: Linux Ctrl+z/bg/nohup/setsid/&amp;amp; 在Linux中，如果要让进程在后台运行，一般情况下，我们在命令后面加上&amp;amp;即可，实际上，这样是将命令放入到一个作业队列中了：
# ./rsync.sh &amp;amp; # jobs 对于已经在前台执行的命令，也可以重新放到后台执行，首先按ctrl+z暂停已经运行的进程，然后使用bg命令将停止的作业放到后台运行：bg %1，放回前台运行：%1。
但是如上方到后台执行的进程，其父进程还是当前终端shell的进程，而一旦父进程退出，则会发送hangup信号给所有子进程，子进程收到hangup以后也会退出。如果我们要在退出shell的时候继续运行进程，则需要使用nohup忽略hangup信号，或者setsid将将父进程设为init进程(进程号为1)：
# nohup ./rsync.sh &amp;amp; # setsid ./rsync.sh &amp;amp; 或 # (./rsync.sh &amp;amp;) ////在一个subshell中执行 # ps -ef|grep rsync nohup 的用途就是让提交的命令忽略 hangup 信号，标准输出和标准错误缺省会被重定向到 nohup.out 文件中。。一般我们可在结尾加上&amp;quot;&amp;amp;&amp;ldquo;来将命令同时放入后台运行，也可用&amp;rdquo; &amp;gt; log.out 2&amp;gt;&amp;amp;1&amp;quot;来更改缺省的重定向文件名。
上面的试验演示了使用nohup/setsid加上&amp;amp;使进程在后台运行，同时不受当前shell退出的影响。那么对于已经在后台运行的进程，该怎么办呢？可以使用disown命令：
# jobs # disown -h %1 # ps -ef|grep rsync 效果与setid相同，但是disown后无法通过jobs命令查看了。
screen 还有一种更加强大的方式是使用screen，首先创建一个断开模式的虚拟终端，然后用-r选项重新连接这个虚拟终端，在其中执行的任何命令，都能达到nohup的效果，这在有多个命令需要在后台连续执行的时候比较方便。
GNU Screen是一款由GNU计划开发的用于命令行终端切换的自由软件。用户可以通过该软件同时连接多个本地或远程的命令行会话，并在其间自由切换，可以看作是窗口管理器的命令行界面版本。它提供了统一的管理多个会话的界面和相应的功能。
# yum install screen -y 常用screen参数：</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: CentOS 6 服务器安全配置指南（通用） date: 2014-09-07 01:21:25 updated: 2014-09-07-12 00:46:23 tags: [安全,ssh] categories: Linux Linux是一个开放式系统，可以在网络上找到许多现成的程序和工具，这既方便了用户，也方便了黑客，因为他们也能很容易地找到程序和工具来潜入Linux系统，或者盗取Linux系统上的重要信息。不过，只要我们仔细地设定Linux的各种系统功能，并且加上必要的安全措施，就能让黑客们无机可乘。一般来说，对Linux系统的安全设定包括取消不必要的服务、限制远程存取、隐藏重要资料、修补安全漏洞、采用安全工具以及经常性的安全检查等。
本文是可参考的实际操作，不涉及如IP欺骗这样的原理，而且安全问题也不算几行命令就能预防的，这里只是linux系统上基本的安全加固方法，后续有新的内容再添加进来。
注：所有文件在修改之前都要进行备份如 cp /etc/passwd{,.dist}
1. 禁用不使用的用户 注意：不建议直接删除，当你需要某个用户时，自己重新添加会很麻烦。也可以usermod -L或passwd -l user锁定。
cp /etc/passwd{,.bak} 修改之前先备份 vi /etc/passwd 编辑用户，在前面加上#注释掉此行
注释的用户名：
# cat /etc/passwd|grep ^# #adm:x:3:4:adm:/var/adm:/sbin/nologin #lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin #shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown #halt:x:7:0:halt:/sbin:/sbin/halt #uucp:x:10:14:uucp:/var/spool/uucp:/sbin/nologin #operator:x:11:0:operator:/root:/sbin/nologin #games:x:12:100:games:/usr/games:/sbin/nologin #gopher:x:13:30:gopher:/var/gopher:/sbin/nologin #ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin #nfsnobody:x:65534:65534:Anonymous NFS User:/var/lib/nfs:/sbin/nologin #postfix:x:89:89::/var/spool/postfix:/sbin/nologin 注释的组：
# cat /etc/group|grep ^# #adm:x:4:adm,daemon #lp:x:7:daemon #uucp:x:14: #games:x:20: #gopher:x:30: #video:x:39: #dip:x:40: #ftp:x:50: #audio:x:63: #floppy:x:19: #postfix:x:89: 2. 关闭不使用的服务 # chkconfig --list |grep &#39;3:on&#39; 邮件服务，使用公司邮件服务器：</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: lsyncd实时同步搭建指南——取代rsync+inotify date: 2015-05-06 01:21:25 updated: 2015-05-07 12:46:23 tags: [rsync,inotify,lsyncd，文件同步] categories: Linux 1. 几大实时同步工具比较 1.1 inotify + rsync 最近一直在寻求生产服务服务器上的同步替代方案，原先使用的是inotify + rsync，但随着文件数量的增大到100W+，目录下的文件列表就达20M，在网络状况不佳或者限速的情况下，变更的文件可能10来个才几M，却因此要发送的文件列表就达20M，严重减低的带宽的使用效率以及同步效率；更为要紧的是，加入inotifywait在5s内监控到10个小文件发生变化，便会触发10个rsync同步操作，结果就是真正需要传输的才2-3M的文件，比对的文件列表就达200M。使用这两个组合的好处在于，它们都是最基本的软件，可以通过不同选项做到很精确的控制，比如排除同步的目录，同步多个模块或同步到多个主机。
搭建过程参考 Linux下同步工具inotify+rsync使用详解 。
1.2 sersync 后来听同事说 sersync 这么个工具可以提高同步的性能，也解决了同步大文件时出现异常的问题，所以就尝试了一下。sersync是国内的一个开发者开源出来的，使用c++编写，采用多线程的方式进行同步，失败后还有重传机制，对临时文件过滤，自带crontab定时同步功能。网上看到有人说性能还不错，说一下我的观点：
国产开源，文档不是很全，在2011年之后就没更新了（googlecode都要快关闭了，其实可以转交其他人维护），网上关于它的使用和讨论都止于10年了 采用xml配置文件的方式，可读性比较好，但是有些原生的有些功能没有实现就没法使用了 无法实现多目录同步，只能通过多个配置文件启动多个进程 文件排除功能太弱。这个要看需求，不是每个人都需要排除子目录。而对于我的环境中，这个功能很重要，而且排除的规则较多 虽然提供插件的功能，但很鸡肋，因为软件本身没有持续更新，也没有看到贡献有其它插件出现（可能是我知识面不够，还用不到里面的refreshCDN plugin）。 虽然不懂c++，但大致看了下源码 FileSynchronize，拼接rsync命令大概在273行左右，最后一个函数就是排除选项，简单一点可以将--exclude=改成--eclude-from来灵活控制。有机会再改吧。
另外，在作者的文章 Sersync服务器同步程序 项目简介与设计框架 评论中，说能解决上面 rsync + inotify中所描述的问题。阅读了下源码，这个应该是没有解决，因为在拼接rsync命令时，后面的目的地址始终是针对module的，只要执行rsync命令，就会对整个目录进行遍历，发送要比对的文件列表，然后再发送变化的文件。sersync只是减少了监听的事件，减少了rsync的次数——这已经是很大的改进，但每次rsync没办法改变。（如有其它看法可与我讨论）
其实我们也不能要求每一个软件功能都十分健全，关键是看能否满足我们当下的特定的需求。所谓好的架构不是设计出来的，而是进化来的。目前使用sersync2没什么问题，而且看了它的设计思路应该是比较科学的，特别是过滤队列的设计。双向同步看起来也是可以实现。
1.3 lsyncd 废话说这么多，本文就是介绍它了。有些博客说lsyncd是谷歌开源的，实际不是了，只是托管在了googlecode上而已，幸运的是已经迁移到github了：https://github.com/axkibe/lsyncd 。
Lysncd 实际上是lua语言封装了 inotify 和 rsync 工具，采用了 Linux 内核（2.6.13 及以后）里的 inotify 触发机制，然后通过rsync去差异同步，达到实时的效果。我认为它最令人称道的特性是，完美解决了 inotify + rsync海量文件同步带来的文件频繁发送文件列表的问题 —— 通过时间延迟或累计触发事件次数实现。另外，它的配置方式很简单，lua本身就是一种配置语言，可读性非常强。lsyncd也有多种工作模式可以选择，本地目录cp，本地目录rsync，远程目录rsyncssh。
实现简单高效的本地目录同步备份（网络存储挂载也当作本地目录），一个命令搞定。
2. 使用 lsyncd 本地目录实时备份 这一节实现的功能是，本地目录source实时同步到另一个目录target，而在source下有大量的文件，并且有部分目录和临时文件不需要同步。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: markdown语法备忘笔记 date: 2014-10-25 01:21:25 tags: [markdown, hexo博客] categories:
其它 updated: 2014-10-27 10:46:23 ##1. 什么是markdown##
##2. 我选择的markdown编辑器## 首先选择适合自己的markdown编辑器需要考虑几个方面： 平台：Mac OS X, Windows, Online, 插件形式 预览：实时预览、html预览 语法：选定某一款后，适应自己的习惯，不必太复杂 其它：如主题，快捷键，同步等
###首先来说一下以下几款为什么我没选用：（纯属个人喜好）###
Sublime Text的插件markdown preview，编辑和预览是分离的，在浏览器里预览。 CuteMarkEd，独立编辑器，支持多平台，不知道为什么我的编辑和预览窗口字体都那么丑。 MarkdownPad，独立编辑器，windows下口碑比较好的，但我把曾经写好的md文章放进去，格式不太对，应该是语法上略有差别，其它都还好。它多标签页的形式可以加分。 社区活跃，新功能反馈及时，例如 toc replace vim或emacs的markdown插件，windows平台下我还是正常一点吧。 ###习惯采用的编辑器### Haroopad，不得不说韩国人开发的软件体验上超赞，与segmentfault的文章写作一样，左右实时预览，多种主题可选。如果能实现多标签页就更好了。各平台上都可以使用，还有vim编辑模式。 马克飞象，google浏览器插件，专为印象笔记开发的浏览器markdown扩展，用起来特别舒服，自动保存在本地缓存，没有导出html格式或浏览器在线预览的功能，但比MaDe好用多了。（现在有离线客户端版） 在线markdown编辑器（首先你得有网络） [github]：不用多说 MaHua：与Mac OS X上相传甚广的Mou风格类似 cmd markdown：大牛开发的 ##3. 常用markdown语法## 标题/粗斜体 文章内容较多时，可以用标题分段：
# 一级标题 # ## 大标题 ## ### 小标题 ### sf只有三级标题
粗体/斜体 *斜体文本*　或　_斜体文本_　显示成　斜体文本 **粗体文本**　或　__粗体文本__　显示成　粗体文本 ***粗斜体文本***　或　___粗斜体文本___　显示成　粗斜体文本</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 管理多tomcat服务shell脚本（CentOS） date: 2014-10-29 18:21:25 updated: 2014-10-29 11:46:23 tags: [tomcat, script, shell] categories: Tomcat 该脚本改自csdn上的一个shell，忘记出处了，只记得它能够简单的通过service tomcat [stop|start|restart]来方便的管理Linux服务器上的tomcat，这可以满足大部分人的需求，然而并不适合我所管理的CentOS上的tomcat应用：通过端口区分的3台tomcat集群。如果每一次管理tomcat或查看日志，都cd /apps/test/tomcat0/log/然后切换到另外一个cd ../../或cd /apps/test/tomcat1/log/，麻烦至极。因此“懒人”创造了这个脚本tomcat：
#!/bin/bash # author: Sean Chow (seanlook7@gmail.com) # # # chkconfig: 345 80 15 # description: Multiple tomcats service management script. # Source function library. . /etc/rc.d/init.d/functions # 第几个tomcat tcNo=$1 tcName=tomcat$1 basedir=/apps/test/$tcName tclog=${basedir}/logs/catalina.$(date +%Y-%m-%d).out RETVAL=0 start(){ checkrun if [ $RETVAL -eq 0 ]; then echo &amp;#34;-- Starting tomcat...&amp;#34; $basedir/bin/startup.sh touch /var/lock/subsys/${tcNo} checklog status else echo &amp;#34;-- tomcat already running&amp;#34; fi } # 停止某一台tomcat，如果是重启则带re参数，表示不查看日志，等待启动时再提示查看 stop(){ checkrun if [ $RETVAL -eq 1 ]; then echo &amp;#34;-- Shutting down tomcat.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: ProxySQL高可用方案 date: 2017-07-15 21:32:49 tags: [mysql, 中间件, proxysql] categories:
MySQL updated: 2017-07-18 21:32:49 MySQL的高可用方案现在如 MHA, Galera, InnoDB Cluster，一旦在上游使用中间件之后，中间件本身可能成为单点。所以本文要介绍的是对于ProxySQL自身高可用的方案对比。 首先ProxySQL自身是通过Angel进程的形式运行，即proxysql如果有崩溃，主进程会自动拉起来。但如果是无响应或者网络故障，则需要另外的机制去做到服务的高可用。本文总结了四种方法。
ProxySQL有关介绍，请参考： http://xgknight.com/2017/04/10/mysql-proxysql-install-config/
1. 与应用一起部署 所有部署应用的地方，都会部署proxysql节点，当这个proxysql挂掉之后，只影响本机的应用。而且不需要多经过一层网络。 但带来的问题是，如果应用节点很多，proxy的数量也会增加：
会导致proxysql的配置不容易管理 proxysql对后端db健康检查的请求成倍增加 限制每个用户或后端db的 max_connections 特性用不了 2. 集中式部署，多ip引用 后端一个db集群，对应中间两个以上的 proxysql 节点，前端应用配置多个ip地址，随机挑选一个使用，完全无状态。仅需要多经过一次网络代理。 这种方式的好处是，不需要再对数据库这种基础服务，多引入一个软件来实现高可用（如下节的keepalive或consul），由应用端获取数据库连接的代码逻辑处理。
但是因为proxysql访问地址是写在配置文件里面的，如果一个节点挂掉，随机挑选还是会落地这个失败的节点。所以优化方案是，ip列表里面默认取某一个，失败之后再选取下一个重试。
示例代码：
proxysql_addr_list = [&amp;#39;192.168.1.175&amp;#39;, &amp;#39;192.168.1.176&amp;#39;, &amp;#39;192.168.1.177&amp;#39;] proxysql_addr_list_len = 3 hostname = &amp;#39;this_hostname_for_hash_loadbalance&amp;#39; def get_dbconnection(): list_index = hash(hostname) % proxysql_addr_list_len dbconn = None try: dbconn = DBConnect(dbhost=proxysql_addr_list[ list_index ], dbport=3306) # timeout 1000ms except: if (list_index + 1) == proxysql_addr_list_len: list_index = -1 # like Circular Array dbconn = DBConnec(dbhost=proxysql_addr_list[ list_index + 1 ], dbport=3306) # if failed again, through exception return dbconn 上述并不完美，比如可以改用环形数组轮巡，允许重试其它更多的ip。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: ProxySQL监控方案 date: 2017-07-16 21:32:49 tags: [mysql, 中间件, proxysql] categories:
MySQL updated: 2017-07-18 21:32:49 ProxySQL能监控的信息不多，而且大部分是统计信息，不是性能数据。
mysql&amp;gt; show tables from stats; +--------------------------------+ | tables | +--------------------------------+ | global_variables | | stats_mysql_commands_counters | | stats_mysql_connection_pool | | stats_mysql_global | | stats_mysql_processlist | | stats_mysql_query_digest | | stats_mysql_query_digest_reset | | stats_mysql_query_rules | +--------------------------------+ 主要关心的指标都在表 stats_mysql_global 里面，源代码 diamond 目录下有个 proxysqlstat.py 脚本，是通过SHOW MYSQL STATUS命令，由diamond收集进程将指标上报到Graphite。有以下几个Metrics：
并发数 Active_Transactions Questions 连接相关 Client_Connections_connected Server_Connections_connected Server_Connections_aborted 内存相关 Query_Cache_Entries Query_Cache_Memory_bytes SQLite3_memory_bytes ConnPool_memory_bytes 流量相关 mysql_backend_buffers_bytes mysql_frontend_buffers_bytes mysql_session_internal_bytes 其它 MySQL_Monitor_Workers MySQL_Thread_Workers 但是这些远远不够，还有以下更值得关心的指标： 表 stats_mysql_connection_pool:</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 使用 Xtrabackup 在线对MySQL做主从复制 date: 2015-12-14 10:21:25 updated: 2015-12-14 00:46:23 tags: [mysql, 主从复制, 备份] categories:
MySQL 1. 说明 1.1 xtrabackup mysqldump对于导出10G以下的数据库或几个表，还是适用的，而且更快捷。一旦数据量达到100-500G，无论是对原库的压力还是导出的性能，mysqldump就力不从心了。Percona-Xtrabackup备份工具，是实现MySQL在线热备工作的不二选择，可进行全量、增量、单表备份和还原。（但当数据量更大时，可能需要考虑分库分表，或使用 LVM 快照来加快备份速度了）
2.2版本 xtrabackup 能对InnoDB和XtraDB存储引擎的数据库非阻塞地备份，innobackupex通过perl封装了一层xtrabackup，对MyISAM的备份通过加表读锁的方式实现。2.3版本 xtrabackup 命令直接支持MyISAM引擎。
XtraBackup优势 ：
无需停止数据库进行InnoDB热备 增量备份MySQL 流压缩到传输到其它服务器 能比较容易地创建主从同步 备份MySQL时不会增大服务器负载 1.2 replication 为什么要做主从复制？ 我想这是要在实施以前要想清楚的问题。是为了实现读写分离，减轻主库负载或数据分析？ 为了数据安全，做备份恢复？主从切换做高可用？ 大部分场景下，以上三个问号一主一从都能够解决，而且任何生产环境都建议你至少要有一个从库，假如你的读操作压力特别大，甚至要做一主多从，还可以不同的slave扮演不同的角色，例如使用不同的索引，或者不同的存储引擎，或使用一个小内存server做slave只用于备份。（当然slave太多也会对master的负载和网络带宽造成压力，此时可以考虑级联复制，即 A-&amp;gt;B-&amp;gt;C ）
还有需要考虑的是，一主一从，一旦做了主从切换，不通过其它HA手段干预的话，业务访问的还是原IP，而且原主库很容易就作废了。于是 主-主 复制就产生了，凭借各自不同的 server-id ，可以避免 “A的变化同步到B，B应用变化又同步到A” 这样循环复制的问题。但建议是，主主复制，其中一个主库强制设置为只读，主从切换后架构依然是可用的。
复制过程是slave主动向master拉取，而不是master去推的，所以理想情况下做搭建主从时不需要master做出任何改变甚至停服，slave失败也不影响主库。
复制类型
基于语句的复制：STATEMENT，在主服务器上执行的SQL语句，在从服务器上执行同样的语句，有可能会由于SQL执行上下文环境不同而是数据不一致，例如调用NOW()函数。MySQL在5.7.7以前默认采用基于语句的复制，在 5.7.7 及以后版本默认改用 row-based。 基于行的复制：ROW，把改变的内容复制过去，而不是把命令在从服务器上执行一遍。从mysql5.0开始支持，能够严格保证数据完全一致，但此时用mysqlbinlog去分析日志就没啥意义。因为任何一条update语句，都会把涉及到的行数据全部set值，所以binlog文件会比较大。 （遇到的一个坑是，迁移时，从库改正了字段默认值定义，但数据在主库更改后，即使产生的新数据默认值是正确的，但基于行的复制依然用不正确的值字段全部更新了） 混合类型的复制: MIXED，默认采用基于语句的复制，一旦发现基于语句的无法精确的复制时，就会采用基于行的复制。 mysql系统库mysql库里面表的日志记录格式需要说明：在通过如INSERT、UPDATE、DELETE、TRUNCATE等方式直接修改数据的语句，使用 binlog_format指定的方式记录，但使用GRANT、ALTER、CREATE、RENAME等改动的mysql库里数据的，会强制使用statement-based方式记录binlog。
可以在线修改二进制日志类型，如SET SESSION binlog_format=MIXED;，需要SUPER权限。
复制类型还可以分为 异步复制和半同步复制。 通常没说明指的都是异步，即主库执行完Commit后，在主库写入Binlog日志后即可成功返回客户端，无需等等Binlog日志传送给从库，一旦主库宕机，有可能会丢失日志。而半同步复制，是等待其中一个从库也接收到Binlog事务并成功写入Relay Log之后，才返回Commit操作成功给客户端；如此半同步就保证了事务成功提交后至少有两份日志记录，一份在主库Binlog上，另一份在从库的Relay Log上，从而进一步保证数据完整性；半同步复制很大程度取决于主从网络RTT（往返时延），以插件 semisync_master/semisync_slave 形式存在。 原理 (1) master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）； (2) slave将master的binary log events拷贝到它的中继日志(relay log)； (3) slave重做中继日志中的事件，将改变反映它自己的数据。 该过程的第一部分就是master记录二进制日志。在每个事务更新数据完成之前，master在二进制日志记录这些改变。MySQL将事务串行的写入二进制日志，即使事务中的语句都是交叉执行的。在事件写入二进制日志完成后，master通知存储引擎提交事务。 下一步将master的binary log拷贝到它自己的中继日志。首先，slave开始一个工作线程——I/O线程。I/O线程在master上打开一个普通的连接，请求从指定日志文件的指定位置之后的日志内容，然后开始binlog dump process。Binlog dump process从master的二进制日志中读取事件，如果已经跟上master，它会睡眠并等待master产生新的事件。I/O线程将这些事件写入中继日志。 SQL slave thread（SQL从线程）处理该过程的最后一步。SQL线程从中继日志读取事件，并重放其中的事件而更新slave的数据，使其与master中的数据一致。只要该线程与I/O线程保持一致，中继日志通常会位于OS的缓存中，所以中继日志的开销很小。 此外，在master中也有一个工作线程：和其它MySQL的连接一样，slave在master中打开一个连接也会使得master开始一个线程。复制过程有一个很重要的限制——复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: MySQL增量备份与恢复实例 date: 2014-12-05 09:21:25 updated: 2014-05 17:00:46:23 tags: [mysql, database, binlog, backup] categories: MySQL 小量的数据库可以每天进行完整备份，因为这也用不了多少时间，但当数据库很大时，就不太可能每天进行一次完整备份了，这时候就可以使用增量备份。增量备份的原理就是使用了mysql的binlog日志。 本次操作的MySQL版本为5.5.40 for Linux (x86_64)。
增量备份要确保打开了二进制日志，参考mysql的日志系统：
mysql&amp;gt; show variables like &amp;#39;%log_bin%&amp;#39;; 首先对pak数据库做一个完整备份：
$ mysqldump -h localhost -upak -ppwd -P3306 --master-data=2 --single-transaction --opt pak &amp;gt; pak_bak_full.sql 这时候就会得到一个全备文件pak_bak_full.sql。mysqldump操作会导致滚动一次log，假设新的binlog文件是mysql-bin.000002。
1. 模拟插入数据和误操作 a. 在pak库的某个表插入一些数据，然后执行flush logs命令。这时将会产生一个新的二进制日志文件mysql-bin.000003，mysql-bin.000002则保存了全备过后的所有更改，既增加记录的操作也保存在了mysql-bin.00002中。
b. 再在pak库中的t_user表中增加两条记录，然后误删除t_user表。t_user中增加记录的操作和删除表的操作都记录在mysql-bin.000003中。
2. 开始恢复 恢复过程不要记录日志：
mysql &amp;gt; set global sql_log_bin=0; 3. 首先导入全备数据 $ mysql -h localhost -upak -ppwd &amp;lt; pak_bak_full.sql 或 mysql&amp;gt; source /path/backup/pak_bak_full.sql 我们也可以看到全备时的binlog位置：</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: MySQL备份命令mysqldump参数说明与示例 date: 2014-12-05 20:21:25 updated: 2014-07 17:00:46:23 tags: [mysql, database, mysqldump, backup] categories: MySQL 1. 语法选项说明 -h, --host=name 主机名
-P[ port_num], --port=port_num 用于连接MySQL服务器的的TCP/IP端口号
--master-data 这个选项可以把binlog的位置和文件名添加到输出中，如果等于1，将会打印成一个CHANGE MASTER命令；如果等于2，会加上注释前缀。并且这个选项会自动打开--lock-all-tables，除非同时设置了--single-transaction（这种情况下，全局读锁只会在开始dump的时候加上一小段时间，不要忘了阅读--single-transaction的部分）。在任何情况下，所有日志中的操作都会发生在导出的准确时刻。这个选项会自动关闭--lock-tables。
-x, --lock-all-tables 锁定所有库中所有的表。这是通过在整个dump的过程中持有全局读锁来实现的。会自动关闭--single-transaction和--lock-tables。
--single-transaction 通过将导出操作封装在一个事务内来使得导出的数据是一个一致性快照。只有当表使用支持MVCC的存储引擎（目前只有InnoDB）时才可以工作；其他引擎不能保证导出是一致的。当导出开启了--single-transaction选项时，要确保导出文件有效（正确的表数据和二进制日志位置），就要保证没有其他连接会执行如下语句：ALTER TABLE, DROP TABLE, RENAME TABLE, TRUNCATE TABLE，这会导致一致性快照失效。这个选项开启后会自动关闭--lock-tables。
-l, --lock-tables 对所有表加读锁。（默认是打开的，用--skip-lock-tables来关闭，上面的选项会把关闭-l选项）
-F, --flush-logs 在开始导出前刷新服务器的日志文件。注意，如果你一次性导出很多数据库（使用 -databases=或--all-databases选项），导出每个库时都会触发日志刷新。例外是当使用了--lock-all-tables或--master-data时：日志只会被刷新一次，那个时候所有表都会被锁住。所以如果你希望你的导出和日志刷新发生在同一个确定的时刻，你需要使用--lock-all-tables，或者--master-data配合--flush-logs。
--delete-master-logs 备份完成后删除主库上的日志。这个选项会自动打开``&amp;ndash;master-data`。
--opt 同-add-drop-table, --add-locks, --create-options, --quick, --extended-insert, --lock-tables, --set-charset, --disable-keys。（默认已开启，--skip-opt关闭表示这些选项保持它的默认值）应该给你为读入一个MySQL服务器的尽可能最快的导出，--compact差不多是禁用上面的选项。
-q, --quick
不缓冲查询，直接导出至stdout。（默认打开，用--skip-quick来关闭）该选项用于转储大的表。
--set-charset 将SET NAMES default_character_set加到输出中。该选项默认启用。要想禁用SET NAMES语句，使用--skip-set-charset。
--add-drop-tables 在每个CREATE TABLE语句前添加DROP TABLE语句。默认开启。
--add-locks 在每个表导出之前增加LOCK TABLES并且之后UNLOCK TABLE。(为了使得更快地插入到MySQL)。默认开启。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 生产环境使用 pt-table-checksum 检查MySQL数据一致性 date: 2015-12-29 10:21:25 updated: 2015-12-29 00:46:23 tags: [mysql, 主从复制, percona] categories:
MySQL 公司数据中心从托管机房迁移到阿里云，需要对mysql迁移（Replication）后的数据一致性进行校验，但又不能对生产环境使用造成影响，pt-table-checksum 成为了绝佳也是唯一的检查工具。
pt-table-checksum 是 Percona-Toolkit 的组件之一，用于检测MySQL主、从库的数据是否一致。其原理是在主库执行基于statement的sql语句来生成主库数据块的checksum，把相同的sql语句传递到从库执行，并在从库上计算相同数据块的checksum，最后，比较主从库上相同数据块的checksum值，由此判断主从数据是否一致。检测过程根据唯一索引将表按row切分为块（chunk），以为单位计算，可以避免锁表。检测时会自动判断复制延迟、 master的负载， 超过阀值后会自动将检测暂停，减小对线上服务的影响。
pt-table-checksum 默认情况下可以应对绝大部分场景，官方说，即使上千个库、上万亿的行，它依然可以很好的工作，这源自于设计很简单，一次检查一个表，不需要太多的内存和多余的操作；必要时，pt-table-checksum 会根据服务器负载动态改变 chunk 大小，减少从库的延迟。
为了减少对数据库的干预，pt-table-checksum还会自动侦测并连接到从库，当然如果失败，可以指定--recursion-method选项来告诉从库在哪里。它的易用性还体现在，复制若有延迟，在从库 checksum 会暂停直到赶上主库的计算时间点（也通过选项--设定一个可容忍的延迟最大值，超过这个值也认为不一致）。
为了保证主数据库服务的安全，该工具实现了许多保护措施：
自动设置 innodb_lock_wait_timeout 为1s，避免引起 默认当数据库有25个以上的并发查询时，pt-table-checksum会暂停。可以设置 --max-load 选项来设置这个阀值 当用 Ctrl+C 停止任务后，工具会正常的完成当前 chunk 检测，下次使用 --resume 选项启动可以恢复继续下一个 chunk 工作过程 直接看 nettedfish 的说明：
1. 连接到主库：pt工具连接到主库，然后自动发现主库的所有从库。默认采用show full processlist来查找从库，但是这只有在主从实例端口相同的情况下才有效。 3. 查找主库或者从库是否有复制过滤规则：这是为了安全而默认检查的选项。你可以关闭这个检查，但是这可能导致checksum的sql语句要么不会同步到从库，要么到了从库发现从库没有要被checksum的表，这都会导致从库同步卡库。 5. 开始获取表，一个个的计算。 6. 如果是表的第一个chunk，那么chunk-size一般为1000；如果不是表的第一个chunk，那么采用19步中分析出的结果。 7. 检查表结构，进行数据类型转换等，生成checksum的sql语句。 8. 根据表上的索引和数据的分布，选择最合适的split表的方法。 9. 开始checksum表。 10. 默认在chunk一个表之前，先删除上次这个表相关的计算结果。除非–resume。 14. 根据explain的结果，判断chunk的size是否超过了你定义的chunk-size的上限。如果超过了，为了不影响线上性能，这个chunk将被忽略。 15.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: nginx做负载均衡器以及proxy缓存配置 date: 2015-06-02 01:21:25 updated: 2015-06-02 00:46:23 tags: [nignx, 负载均衡, 缓存] categories: [Linux, Nginx] 关于nginx的安装和基本配置请参考nginx，本文在原基础上完成以下几个功能：
结合proxy和upstream模块实现nginx负载均衡 结合nginx_upstream_check_module模块实现后端服务器的健康检查 使用nginx-sticky-module扩展模块实现Cookie会话黏贴（session-sticky效果） 使用proxy模块实现静态文件缓存 使用ngx_cache_purge实现更强大的缓存清除功能 1. 安装及模块说明 上面提到的3个模块都属于第三方扩展模块，需要提前下好源码，然后编译时通过--add-moudle=src_path一起安装。
注意：
使用 nginx_upstream_check_module(简记为m1) 时要先为nginx打上相应版本的patch，我的nginx版本为 1.6.3，所以patch对应 m1 解压后目录下的check_1.5.12+.patch，所以进入nginx源码目录，执行 patch -p1 &amp;hellip;（见下方示例） nginx-sticky-module-ng(简记为m2) 模块可以单独使用，但是因为m1监控检查的方式是依赖于m2的，所以要使用m2，还要对m1打上patch，进入m2源码目录，执行 patch -p0&amp;hellip; 编译示例：（CentOS 6.5 x86_64, nginx 1.6.3）
# yum -y install gcc gcc-c++ make libtool zlib zlib-devel openssl openssl--devel pcre pcre-devel # cd nginx-1.6.3 # patch -p1 &amp;lt; ../nginx_upstream_check_module-0.3.0/check_1.5.12+.patch # cd ../nginx-sticky-module-ng-1.2.5 # patch -p0 &amp;lt; .</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: nginx服务器安装及配置文件详解 date: 2015-05-17 01:21:25 updated: 2015-05-28 00:46:23 tags: nignx categories: [Linux, Nginx] nginx在工作中已经有好几个环境在使用了，每次都是重新去网上扒博客，各种编译配置，今天自己也整理一份安装文档和nginx.conf配置选项的说明，留作以后参考。像负载均衡配置（包括健康检查）、缓存（包括清空缓存）配置实例，请参考 http://xgknight.com/2015/05/17/nginx-install-and-config ，ssl加密请参考 http://xgknight.com/2015/05/28/nginx-ssl/ 。
1. 安装nginx 1.1 选择稳定版本 我们编译安装nginx来定制自己的模块，机器CentOS 6.2 x86_64。首先安装缺少的依赖包：
# yum -y install gcc gcc-c++ make libtool zlib zlib-devel openssl openssl-devel pcre pcre-devel 这些软件包如果yum上没有的话可以下载源码来编译安装，只是要注意编译时默认安装的目录，确保下面在安装nginx时能够找到这些动态库文件（ldconfig）。
从 http://nginx.org/en/download.html 下载稳定版nginx-1.6.3.tar.gz到/usr/local/src下解压。
为了后续准备我们另外下载2个插件模块：nginx_upstream_check_module-0.3.0.tar.gz —— 检查后端服务器的状态，nginx-goodies-nginx-sticky-module-ng-bd312d586752.tar.gz（建议在/usr/local/src下解压后将目录重命名为nginx-sticky-module-ng-1.2.5） —— 后端做负载均衡解决session sticky问题（与upstream_check模块结合使用需要另外打补丁，请参考nginx负载均衡配置实战）。
请注意插件与nginx的版本兼容问题，一般插件越新越好，nginx不用追新，稳定第一。nginx-1.4.7，nginx-sticky-module-1.1，nginx_upstream_check_module-0.2.0，这个搭配也没问题。sticky-1.1与nginx-1.6版本由于更新没跟上编译出错。（可以直接使用Tengine，默认就包括了这些模块）
[root@cachets nginx-1.6.3]# pwd /usr/local/src/nginx-1.6.3 [root@cachets nginx-1.6.3]# ./configure --prefix=/usr/local/nginx-1.6 --with-pcre \ &amp;gt; --with-http_stub_status_module --with-http_ssl_module \ &amp;gt; --with-http_gzip_static_module --with-http_realip_module \ &amp;gt; --add-module=../nginx_upstream_check_module-0.3.0 [root@cachets nginx-1.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: Nginx+Keepalived实现站点高可用 date: 2015-05-18 01:21:25 updated: 2015-05-18 00:46:23 tags: [nignx, keepalived, 高可用] categories: [Linux, Nginx] 公司内部 OA 系统要做线上高可用，避免单点故障，所以计划使用2台虚拟机通过 Keepalived 工具来实现 nginx 的高可用（High Avaiability），达到一台nginx入口服务器宕机，另一台备机自动接管服务的效果。（nginx做反向代理，实现后端应用服务器的负载均衡）快速搭建请直接跳至 第2节。
1. Keepalived介绍 Keepalived是一个基于VRRP协议来实现的服务高可用方案，可以利用其来避免IP单点故障，类似的工具还有heartbeat、corosync、pacemaker。但是它一般不会单独出现，而是与其它负载均衡技术（如lvs、haproxy、nginx）一起工作来达到集群的高可用。
1.1 VRRP协议 VRRP全称 Virtual Router Redundancy Protocol，即 虚拟路由冗余协议。可以认为它是实现路由器高可用的容错协议，即将N台提供相同功能的路由器组成一个路由器组(Router Group)，这个组里面有一个master和多个backup，但在外界看来就像一台一样，构成虚拟路由器，拥有一个虚拟IP（vip，也就是路由器所在局域网内其他机器的默认路由），占有这个IP的master实际负责ARP相应和转发IP数据包，组中的其它路由器作为备份的角色处于待命状态。master会发组播消息，当backup在超时时间内收不到vrrp包时就认为master宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master，保证路由器的高可用。
在VRRP协议实现里，虚拟路由器使用 00-00-5E-00-01-XX 作为虚拟MAC地址，XX就是唯一的 VRID （Virtual Router IDentifier），这个地址同一时间只有一个物理路由器占用。在虚拟路由器里面的物理路由器组里面通过多播IP地址 224.0.0.18 来定时发送通告消息。每个Router都有一个 1-255 之间的优先级别，级别最高的（highest priority）将成为主控（master）路由器。通过降低master的优先权可以让处于backup状态的路由器抢占（pro-empt）主路由器的状态，两个backup优先级相同的IP地址较大者为master，接管虚拟IP。
与heartbeat/corosync等比较 直接摘抄自 http://www.linuxidc.com/Linux/2013-08/89227.htm ：
Heartbeat、Corosync、Keepalived这三个集群组件我们到底选哪个好，首先我想说明的是，Heartbeat、Corosync是属于同一类型，Keepalived与Heartbeat、Corosync，根本不是同一类型的。Keepalived使用的vrrp协议方式，虚拟路由冗余协议 (Virtual Router Redundancy Protocol，简称VRRP)；Heartbeat或Corosync是基于主机或网络服务的高可用方式；简单的说就是，Keepalived的目的是模拟路由器的高可用，Heartbeat或Corosync的目的是实现Service的高可用。
所以一般Keepalived是实现前端高可用，常用的前端高可用的组合有，就是我们常见的LVS+Keepalived、Nginx+Keepalived、HAproxy+Keepalived。而Heartbeat或Corosync是实现服务的高可用，常见的组合有Heartbeat v3(Corosync)+Pacemaker+NFS+Httpd 实现Web服务器的高可用、Heartbeat v3(Corosync)+Pacemaker+NFS+MySQL 实现MySQL服务器的高可用。总结一下，Keepalived中实现轻量级的高可用，一般用于前端高可用，且不需要共享存储，一般常用于两个节点的高可用。而Heartbeat(或Corosync)一般用于服务的高可用，且需要共享存储，一般用于多节点的高可用。这个问题我们说明白了。
又有博友会问了，那heartbaet与corosync我们又应该选择哪个好啊，我想说我们一般用corosync，因为corosync的运行机制更优于heartbeat，就连从heartbeat分离出来的pacemaker都说在以后的开发当中更倾向于corosync，所以现在corosync+pacemaker是最佳组合。
1.2 Keepalived + nginx keepalived可以认为是VRRP协议在Linux上的实现，主要有三个模块，分别是core、check和vrrp。core模块为keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析。check负责健康检查，包括常见的各种检查方式。vrrp模块是来实现VRRP协议的。本文基于如下的拓扑图：
+-------------+ | uplink | +-------------+ | + MASTER keep|alived BACKUP 172.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: nginx配置location总结及rewrite规则写法 date: 2015-05-17 15:21:25 updated: 2015-05-17 15:46:23 tags: [nignx, rewrite] categories: [Linux, Nginx] 1. location正则写法 一个示例：
location = / { # 精确匹配 / ，主机名后面不能带任何字符串 [ configuration A ] } location / { # 因为所有的地址都以 / 开头，所以这条规则将匹配到所有请求 # 但是正则和最长字符串会优先匹配 [ configuration B ] } location /documents/ { # 匹配任何以 /documents/ 开头的地址，匹配符合以后，还要继续往下搜索 # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条 [ configuration C ] } location ~ /documents/Abc { # 匹配任何以 /documents/Abc 开头的地址，匹配符合以后，还要继续往下搜索 # 只有后面的正则表达式没有匹配到时，这一条才会采用这一条 [ configuration CC ] } location ^~ /images/ { # 匹配任何以 /images/ 开头的地址，匹配符合以后，停止往下搜索正则，采用这一条。 [ configuration D ] } location ~* \.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: nginx配置ssl加密（单双向认证、部分https） date: 2015-05-28 15:21:25 updated: 2015-05-28 15:46:23 tags: [nignx, ssl] categories: [Linux, Nginx] nginx下配置ssl本来是很简单的，无论是去认证中心买SSL安全证书还是自签署证书，但最近公司OA的一个需求，得以有个机会实际折腾一番。一开始采用的是全站加密，所有访问http:80的请求强制转换（rewrite）到https，后来自动化测试结果说响应速度太慢，https比http慢慢30倍，心想怎么可能，鬼知道他们怎么测的。所以就试了一下部分页面https（不能只针对某类动态请求才加密）和双向认证。下面分节介绍。
默认nginx是没有安装ssl模块的，需要编译安装nginx时加入--with-http_ssl_module选项。
关于SSL/TLS原理请参考 这里，如果你只是想测试或者自签发ssl证书，参考 这里 。
提示：nignx到后端服务器由于一般是内网，所以不加密。
1. 全站ssl 全站做ssl是最常见的一个使用场景，默认端口443，而且一般是单向认证。
server { listen 443; server_name example.com; root /apps/www; index index.html index.htm; ssl on; ssl_certificate ../SSL/ittest.pem; ssl_certificate_key ../SSL/ittest.key; # ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2; # ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP; # ssl_prefer_server_ciphers on; } 如果想把http的请求强制转到https的话：
server { listen 80; server_name example.me; rewrite ^ https://$server_name$request_uri? permanent; ### 使用return的效率会更高 # return 301 https://$server_name$request_uri; } ssl_certificate证书其实是个公钥，它会被发送到连接服务器的每个客户端，ssl_certificate_key私钥是用来解密的，所以它的权限要得到保护但nginx的主进程能够读取。当然私钥和证书可以放在一个证书文件中，这种方式也只有公钥证书才发送到client。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 记一次错误卸载软件包导致Linux系统崩溃的修复解决过程 date: 2014-11-03 01:21:25 updated: 2014-11-07 00:46:23 tags: [linux, 系统管理,troubleshooting] categories: Linux 首先问题产生的缘由很简单，是我一同事在安装oracle一套软件时，按照要求需要binutils软件包的32位版本，然而在Oracle Linux已经装有64位，按理说是可以安装i686的，我猜应该是32位的版本低于这个已有的64位所以导致冲突而安装失败，因此同事就用yum remove binutils，这个命令也奇葩，由于是root权限导致依赖于它的200多个软件包也被卸载，最终导致网络断开，系统崩溃，在vSphere虚拟机上重新启动发现再也起不来。下面看问题：
1. Kernel panic - not syncing: Attempted to kill init! 这个错误时在重新启动Oracle Linux一开始就出现，查阅的相关资料得知Kernel panic问题一般是由驱动模块终端处理终端问题导致的（不懂。。。），一开始我以为是驱动程序依赖于binutils导致被卸载，因此第一反应是想办法把缺失的软件装回去。实际上，是由于安全访问控制模块selinux的问题，参考类似问题。于是检查vi /etc/selinux/config时发现SELINUX=disables，拼写错误，应为disabled。 当再次启动没再出现该错误时，我高兴的认为原来这么简单就帮同事解决了，事实这根本还没到200多个软件包缺失而导致系统崩溃那一步。
2. 系统启动加载条完成后，一直hang住不动 这无疑要使用LiveCD修复系统了，参考Ultimate method to install package from linux rescue mode或Using Rescue Mode to Fix..Problems。因为知道出问题前做过什么操作，下面直接上解决问题的过程。
2.1 将系统DVD安装镜像加载到光驱 再次重启就自动进入安装界面，我们当然选择rescue mode： 一路按照提示确定（可以不配置network，这里就不贴图了，很简单），最终会提供给用户一个shell终端，对应的是从DVD光驱加载进来的系统，执行chroot /mnt/sysimage才会进入到原损坏的Linux系统，还好yum和rpm命令还可以使用，悲剧的是我并不知道yum remove命令卸载了哪些软件包。
2.2 安装缺失的软件包 这里得谢天谢地yum命令的安装卸载日志/var/log/yum.log，这个日志里清楚的记录了installed和erased的所有软件包，用rpm是不可能了，因为270多个包的依赖关系难以解决，只能通过yum方式，而由于rescue模式没有配置网络，因此只能使用本地镜像源。
在rescue系统下挂载光驱到待修复系统中的/media目录 bash-4.1# mount /dev/cdrom /mnt/sysimage/media chroot进入待修复系统 bash-4.1# chroot /mnt/sysimage 手动编辑一个仓库源（真实待修复的系统） sh-4.1# cd /etc/yum.repos.d/ &amp;amp;&amp;amp; vi Oracle-Media.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: OpenLDAP(2.4.3x)服务器搭建及配置说明 date: 2015-01-21 01:21:25 updated: 2015-01-21 10:46:23 tags: [LDAP, slapd] categories: [Linux, OpenLDAP] 本文采用的是从源码编译安装，适合Ubuntu和CentOS平台，通过apt-get或yum方式安装参考补充部分。openldap原理介绍参考这里。
环境： Ubuntu: 14.04.1 (trusty), x86_64 OpenLDAP: 2.4.31 Berkery DB: 5.1.29
1 安装 1.1 准备编译环境和依赖包 # apt-get install build-essential # apt-get install libssl-dev 下载openldap-2.4.31.tgz和db-5.1.29.NC.tar.gz并解压：
# cd /usr/local/src src# wget ftp://ftp.openldap.org/pub/OpenLDAP/openldap-release/openldap-2.4.31.tgz # wget http://download.oracle.com/berkeley-db/db-5.1.29.NC.tar.gz # tar -zxf openldap-2.4.31.tgz # tar -zxf db-5.1.29.NC.tar.gz # cd db-5.1.29.NC/build_unix/ # ../dist/configure --prefix=/usr/local/berkeleydb-5.1 # make &amp;amp;&amp;amp; make install 建议人工指定--prefix，默认会安装到/usr/local/BerkeleyDB.5.1。上面的make过程会比较长，另外如果gcc版本在4.7及以上，可能会出现如下warning，可以忽略：
../src/dbinc/atomic.h:179:19: warning: conflicting types for built-in function ‘__atomic_compare_exchange’ [enabled by default] 1.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: LDAP服务器的概念和原理简单介绍 date: 2015-01-15 01:21:25 updated: 2015-01-15 10:46:23 tags: [LDAP, sasl, Kerberos] categories: [Linux, OpenLDAP] 1. 目录服务 目录是一个为查询、浏览和搜索而优化的专业分布式数据库，它呈树状结构组织数据，就好象Linux/Unix系统中的文件目录一样。目录数据库和关系数据库不同，它有优异的读性能，但写性能差，并且没有事务处理、回滚等复杂功能，不适于存储修改频繁的数据。所以目录天生是用来查询的，就好象它的名字一样。
目录服务是由目录数据库和一套访问协议组成的系统。类似以下的信息适合储存在目录中：
企业员工信息，如姓名、电话、邮箱等； 公用证书和安全密钥； 公司的物理设备信息，如服务器，它的IP地址、存放位置、厂商、购买时间等； LDAP是轻量目录访问协议(Lightweight Directory Access Protocol)的缩写，LDAP是从X.500目录访问协议的基础上发展过来的，目前的版本是v3.0。与LDAP一样提供类似的目录服务软件还有ApacheDS、Active Directory、Red Hat Directory Service 。
2. LDAP特点 LDAP的结构用树来表示，而不是用表格。正因为这样，就不能用SQL语句了 LDAP可以很快地得到查询结果，不过在写方面，就慢得多 LDAP提供了静态数据的快速查询方式 Client/server模型，Server 用于存储数据，Client提供操作目录信息树的工具 这些工具可以将数据库的内容以文本格式（LDAP 数据交换格式，LDIF）呈现在您的面前 LDAP是一种开放Internet标准，LDAP协议是跨平台的Interent协议 3. LDAP组织数据的方式 4. 基本概念 在浏览LDAP相关文档时经常会遇见一些概念，下面是常见概念的简单解释。
4.1 Entry 条目，也叫记录项，是LDAP中最基本的颗粒，就像字典中的词条，或者是数据库中的记录。通常对LDAP的添加、删除、更改、检索都是以条目为基本对象的。
dn：每一个条目都有一个唯一的标识名（distinguished Name ，DN），如上图中一个 dn：&amp;ldquo;cn=baby,ou=marketing,ou=people,dc=mydomain,dc=org&amp;rdquo; 。通过DN的层次型语法结构，可以方便地表示出条目在LDAP树中的位置，通常用于检索。
rdn：一般指dn逗号最左边的部分，如cn=baby。它与RootDN不同，RootDN通常与RootPW同时出现，特指管理LDAP中信息的最高权限用户。
Base DN：LDAP目录树的最顶部就是根，也就是所谓的“Base DN&amp;quot;，如&amp;quot;dc=mydomain,dc=org&amp;quot;。
4.2 Attribute 每个条目都可以有很多属性（Attribute），比如常见的人都有姓名、地址、电话等属性。每个属性都有名称及对应的值，属性值可以有单个、多个，比如你有多个邮箱。
属性不是随便定义的，需要符合一定的规则，而这个规则可以通过schema制定。比如，如果一个entry没有包含在 inetorgperson 这个 schema 中的objectClass: inetOrgPerson，那么就不能为它指定employeeNumber属性，因为employeeNumber是在inetOrgPerson中定义的。
LDAP为人员组织机构中常见的对象都设计了属性(比如commonName，surname)。下面有一些常用的别名：
属性 别名 语法 描述 值(举例) commonName cn Directory String 姓名 sean surname sn Directory String 姓 Chow organizationalUnitName ou Directory String 单位（部门）名称 IT_SECTION organization o Directory String 组织（公司）名称 example telephoneNumber Telephone Number 电话号码 110 objectClass 内置属性 organizationalPerson 4.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: LDIF修改ldap记录或配置示例 date: 2015-01-22 01:21:25 updated: 2015-01-22 10:46:23 tags: [LDAP, ldif] categories: [Linux, OpenLDAP] 可以说LDIF文件是OpenLDAP操作数据或修改配置的一切来源，下面是实际通过客户端工具操作的具体示例。（openldap安装及配置过程见这里）。
1. 添加组织或条目 创建一个Marketing部门，添加一个dn记录：
# cat add_entry.ldif dn: ou=Marketing, dc=example,dc=com changetype: add objectclass: top objectclass: organizationalUnit ou: Marketing dn: cn=Pete Minsky,ou=Marketing,dc=example,dc=com changetype: add objectclass: person objectclass: organizationalPerson objectclass: inetOrgPerson cn: Pete Minsky sn: Pete ou: Marketing description: sb, sx description: sx uid: pminsky # ldapmodify -xWD &amp;#39;cn=admin,dc=example,dc=com&amp;#39; -f add_entry.ldif 或去掉changetype后 # ldapmodify -a -xWD &amp;#39;cn=admin,dc=example,dc=com&amp;#39; -f add_entry.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: OpenSSL 与 SSL 数字证书概念贴 date: 2015-01-15 01:21:25 updated: 2015-01-15 10:46:23 tags: [openssl, ssl,加密] categories: 安全 SSL/TLS 介绍见文章 SSL/TLS原理详解。 如果你想快速自建CA然后签发数字证书，请移步 基于OpenSSL自建CA和颁发SSL证书 。
首先简单区分一下HTTPS、SSL、OpenSSL三者的关系：
SSL是在客户端和服务器之间建立一条SSL安全通道的安全协议，而OpenSSL是TLS/SSL协议的开源实现，提供开发库和命令行程序。常说的HTTPS是HTTP的加密版，底层使用的加密协议是SSL。
1. PKI、CA与证书 PKI 就是 Public Key Infrastructure 的缩写，翻译过来就是公开密钥基础设施。它是利用公开密钥技术所构建的，解决网络安全问题的，普遍适用的一种基础设施;是一种遵循既定标准的密钥管理平台,它能够为所有网络应用提供加密和数字签名等密码服务及所必需的密钥和证书管理体系。
PKI既不是一个协议，也不是一个软件，它是一个标准，在这个标准之下发展出的为了实现安全基础服务目的的技术统称为PKI。可以说CA(认证中心)是PKI的核心，而数字证书是PKI的最基本元素，还有如apache等服务器、浏览器等客户端、银行等应用，都是pki的组件。这篇文章可以帮助理解：PKI/CA 技术的介绍 。
1.1 CA 为保证用户之间在网上传递信息的安全性、真实性、可靠性、完整性和不可抵赖性
CA 机构，又称为证书认证中心 (Certificate Authority) 中心，是一个负责发放和管理数字证书的第三方权威机构，它负责管理PKI结构下的所有用户(包括各种应用程序)的证书，把用户的公钥和用户的其他信息捆绑在一起，在网上验证用户的身份。CA机构的数字签名使得攻击者不能伪造和篡改证书。
认证中心主要有以下5个功能：
证书的颁发：接收、验证用户(包括下级认证中心和最终用户)的数字证书的申请。可以受理或拒绝 证书的更新：认证中心可以定期更新所有用户的证书，或者根据用户的请求来更新用户的证书 证书的查询：查询当前用户证书申请处理过程；查询用户证书的颁发信息，这类查询由目录服务器ldap来完成 证书的作废：由于用户私钥泄密等原因，需要向认证中心提出证书作废的请求；证书已经过了有效期，认证中心自动将该证书作废。认证中心通过维护证书作废列表 (Certificate Revocation List,CRL) 来完成上述功能。 证书的归档：证书具有一定的有效期，证书过了有效期之后就将作废，但是我们不能将作废的证书简单地丢弃，因为有时我们可能需要验证以前的某个交易过程中产生的数字签名，这时我们就需要查询作废的证书。 1.2 Certificate 1.2.1 X.509标准 &amp;ldquo;SSL证书&amp;quot;这个词是一个相对较大的概念，整个PKI体系中有很多SSL证书格式标准。PKI的标准规定了PKI的设计、实施和运营，规定了PKI各种角色的&amp;quot;游戏规则&amp;rdquo;，提供数据语法和语义的共同约定。x.509是PKI中最重要的标准，它定义了公钥证书的基本结构，可以说PKI是在X.509标准基础上发展起来的：
SSL公钥证书 证书废除列表CRL(Certificate revocation lists 证书黑名单) 参考 http://en.wikipedia.org/wiki/X.509 。
另外一个常用的标准是PKCS#12，通常采用pfx,p12作为文件扩展名，openssl和java的keytool工具都可以用作生产此类格式的证书。
1.2.2 ssl公钥证书格式 1. 证书版本号(Version) 版本号指明X.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 基于OpenSSL自建CA和颁发SSL证书 date: 2015-01-18 01:21:25 updated: 2015-01-18 10:46:23 tags: [openssl, ssl,ca] categories: 安全 关于SSL/TLS介绍见文章 SSL/TLS原理详解。 关于证书授权中心CA以及数字证书等概念，请移步 OpenSSL 与 SSL 数字证书概念贴 。
openssl是一个开源程序的套件、这个套件有三个部分组成：一是libcryto，这是一个具有通用功能的加密库，里面实现了众多的加密库；二是libssl，这个是实现ssl机制的，它是用于实现TLS/SSL的功能；三是openssl，是个多功能命令行工具，它可以实现加密解密，甚至还可以当CA来用，可以让你创建证书、吊销证书。
默认情况ubuntu和CentOS上都已安装好openssl。CentOS 6.x 上有关ssl证书的目录结构：
/etc/pki/CA/ newcerts 存放CA签署（颁发）过的数字证书（证书备份目录） private 用于存放CA的私钥 crl 吊销的证书 /etc/pki/tls/ cert.pem 软链接到certs/ca-bundle.crt certs/ 该服务器上的证书存放目录，可以房子自己的证书和内置证书 ca-bundle.crt 内置信任的证书 private 证书密钥存放目录 openssl.cnf openssl的CA主配置文件 1. 颁发证书 1.1 修改CA的一些配置文件 CA要给别人颁发证书，首先自己得有一个作为根证书，我们得在一切工作之前修改好CA的配置文件、序列号、索引等等。
vi /etc/pki/tls/openssl.cnf：
... [ CA_default ] dir = /etc/pki/CA # Where everything is kept certs = $dir/certs # Where the issued certs are kept crl_dir = $dir/crl # Where the issued crl are kept database = $dir/index.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: Oracle单实例安装环境一键配置脚本（CentOS6 + 11gR2 ） date: 2014-12-02 15:21:25 updated: 2014-12-03 00:46:23 tags: [oracle, centos, shell, installation] categories: Oracle 这是自己曾经写的一个oracle 11gR2在CentOS6 x86_64服务器上，一键配置安装环境的脚本，能快速完成安装前环境的配置。
具体完成以下工作：
备份系统配置文件，以防出错 添加oracle用户和用户组 创建安装目录 关闭selinux 在.bash_profile中修改环境变量 修改sysctl.conf文件 修改limits.conf文件 修改PAM的login文件 安装必要的依赖包 使用注意事项：
root的用户执行，chmod +x oraclePreInstCheck.sh ./oraclePreInstCheck.sh运行后，请仔细阅读说明，再决定是否使用该脚本 该脚本默认参数适用于2核4G内存的环境，你可以根据需要修改kernelset()部分 执行完后，你检查一下你的安装目录及权限（默认/db/oracle） 该脚本会有提示输入的地方，请不要挑战它的健壮性，比如输入安装根目录时，不要带入空格 脚本只需执行一次，修改系统参数如sysctl.conf之前，都有备份成xxx.ora_bak 请确保可以通过yum方式安装软件包（使用挂载DVD镜像或联网） 建议结合tee将执行过程记录在日志文件中，./oraclePreInstCheck.sh | tee oraclePreInstCheck.log oraclePreInstCheck.sh：
#!/bin/bash # author zhouxiao # date 2014-03-07 # description oracle 11g R2 for linux 6.0+ x86_64 安装辅助脚本 #定义常量 SYSCTL=/etc/sysctl.conf LIMITS=/etc/security/limits.conf PAM=/etc/pam.d/login PROFILE=/etc/profile BASH_PROFILE=/home/oracle/.bash_profile #循环变量 i=1 #定义显示颜色 #颜色定义 信息(33黄色) 警示(31红色) 过程(36浅蓝) usage() { echo &amp;#34;Scripts: initialize the required env settings for Oracle 11gR2 installation on Linux 6.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 配置 Oracle 11gR2 在 CentOS6 上开机自启动 date: 2015-04-11 15:21:25 updated: 2015-04-11 15:21:25 tags: [oracle, linux] categories: Oracle 修改配置 要达到oracle随开机自启动，一般使用11g自带的dbstart脚本：$ORACLE_HOME/bin/dbstart，但要先修改/etc/oratab的内容，将N改成Y，表示允许实例自启动，假如有2个实例要启动，再写一行：
$ vi /etc/oratab EXCRMPROD:/db/oracle/product/11.2.0/db_1:Y 然后在oracle用户下执行$ORACLE_HOME/bin/dbstart即可启动，日志被记录在$ORACLE_HOME/startup.log。但是，默认情况dbstart和dbshut脚本不能自动启动或关闭监听，所以也要加以修改：
$ vi /db/oracle/product/11.2.0/db_1/bin/dbstart ## 找到下面的代码(约第80行)，在实际脚本代码的前面 # First argument is used to bring up Oracle Net Listener ORACLE_HOME_LISTNER=$1 ## 将此处的 ORACLE_HOME_LISTNER=$1 修改为 ORACLE_HOME_LISTNER=$ORACLE_HOME if [ ! $ORACLE_HOME_LISTNER ] ; then echo &amp;#34;ORACLE_HOME_LISTNER is not SET, unable to auto-start Oracle Net Listener&amp;#34; echo &amp;#34;Usage: $0 ORACLE_HOME&amp;#34; else LOG=$ORACLE_HOME_LISTNER/listener.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 仿豆丁网文件在线浏览解决方案搭建 date: 2015-05-13 01:21:25 updated: 2015-05-13 00:46:23 tags: linux categories: Linux 在公司OA和CRM系统遇到要实现在线查看word/jpg等文件的功能，按照开发小组的要求搭建了一套解决方案：OpenOffice + JodConvertor + SWFTool+ FlexPaper，其中OpenOffice + JodConvertor用于将文档转化为PDF格式文档，SwfTool用于将PDF转化为SWF文档，FlexPaper用于展示。使用这个解决方案的最大好处就是跨平台且较为简单。
1.1 安装openoffice openoffice需要jdk的支持，而且默认已经安装，如果没有，手动下载Apache_OpenOffice_4.0.1_Linux_x86-64_install-rpm_zh-CN.tar.gz到/usr/local/src（CentOS 6.4 x86_64）：
# tar -zxf Apache_OpenOffice_4.0.1_Linux_x86-64_install-rpm_zh-CN.tar.gz # cd zh-CN/RPMS # rpm –ivh *.rpm 拷贝字体 安装完成后把windows（c:\windows\fonts）下的一些常用字体拷贝到 /opt/openoffice4/share/fonts/truetype 目录下，如Arial, Calibri, Courier New, Consolas等，如果你想正确的保留原doc的中文字体，还需要把 黑体、微软雅黑、宋体 常规、新宋体 常规、幼圆、隶书、楷体 等中文字体拷贝进去（重启进程后生效）。
启动后台进程 切换至普通用户，如wxcrm启动转换进程：
$ /opt/openoffice4/program/soffice -headless -accept=&amp;#34;socket,host=127.0.0.1,port=8100;urp;&amp;#34; -nofirststartwizard &amp;amp; # ps –ef | grep soffice 1.2 解压jodconverter JODConverter是一个java的OpenDucument文件转换器，可以进行许多文件格式的转换工具，它利用OpenOffice来进行转换工作，它能完成以下转换：
Microsoft Office格式转换为OpenDucument，以及OpenDucument转换为Microsoft Office OpenDucument转换为PDF，Word、Excel、PowerPoint转换为PDF，RTF转换为PDF等。 从 http://sourceforge.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 怎么用pfSense为你的web服务做负载均衡（翻译） date: 2015-04-24 15:21:25 updated: 2015-04-25 00:46:23 tags: [pfsense,vmware] categories: Linux 本文翻译自Howtoforge上的一篇文章 How To Use pfSense To Load Balance Your Web Servers。注意pfSense的负载均衡有两种：一是设置多个WAN做双线负载均衡，二是本文的为LAN内的web服务器做inbound-loadbalancer。
这篇howto中展示了怎么使用pfSense 2.0 为你的多个web服务器配置负载均衡（load balancer）。这里假定在你的网络环境中已经拥有了一个pfSense服务器和2个以上的apache服务器，并且具有一定的pfSense知识。（参考图解pfSense软路由系统的使用（NAT功能）
1. 前提 一个安装好的pfSense 2.0 机器（如果它是你的外围防火墙，建议安装在物理机上） 至少2个apache服务器（可以是虚拟机） 确保在apache服务器之间代码文件是同步的（rsync、cororsync或其它可以保持web服务器间文件更新） 2. 配置pfSense pfSense可以使用负载均衡的功能让特定的请求压力由多台服务器分担，这对于有多台应用的服务器很有帮助，因为你可以把负载压力分散到其它节点上而不是死磕一个节点。
2.1 Monitor 我们正式开始。首先点击Services -&amp;gt; Load Balancers，然后选择Monitor标签。
点击右边的+加号来添加一条记录，输入monitor的名字Name和描述Description（在这个示例名字和描述我都使用ApacheClusterMon），把类型Type设置成HTTP，主机地址Host设置一个还未使用的IP（后面我们将在这个IP上建立虚拟IP，这个虚拟IP会被分配到故障转移failover节点上，注：也有文章说把它设成WAN IP），HTTP Code保存默认的200 OK，然后点击Save保存并且使修改生效Apply Changes。 2.2 Pool 接着建立服务器池server pool。点击Pools标签的+按钮来添加一个池。
在该示例我指定ApacheSrvPool为服务池名称，设置Mode为Load Balance，端口80（。这个端口时你后端服务器的监听端口，你当然可以设定其它应用的其它端口，不一定非是web）。为这个池设定上一步创建的ApacheClusterMon，依次将你的所有web服务器IP添加到这个池中Add to pool，保存并应用。 2.3 Virtual Server 最后一步，选择Virtual Servers标签页，点击+来添加一条记录。填写名称ApacheClusterVirtualServer、描述和IP地址，这个IP地址与第1步中说的未使用的IP相同，端口80，所有发送到这个WAN IP:port的连接都会被转发到服务器池中。虚拟服务器池Virtual Server Poll选择上一步创建的。提交并应用。 搞定！最后不要忘记为虚拟服务器IP和池添加防火墙规则。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 图解pfSense软路由系统的使用（NAT功能） date: 2015-04-23 15:21:25 updated: 2015-04-24 00:46:23 tags: [pfsense,vmware] categories: Linux pfsense是一款开源的路由和防火墙产品，它基于freebsd系统定制和开发。pfsene拥有友好的web的配置界面，且具有伸缩性强又不失强大性能，在众多开源网络防火墙中属于佼佼者。
2004年，pfsense作为m0n0wall项目（基于freebsd内核的嵌入式软防火墙）的分支项目启动，增加了许多m0n0wall没有的功能(pfSense的官方网站称它为the better m0n0wall).pfSense除了包含宽带路由器的基本功能外,还有以下的特点:
基于稳定可靠的FreeBSD操作系统,能适应全天候运行的要求 具有用户认证功能,使用Web网页的认证方式,配合RADIUS可以实现记费功能 完善的防火墙、流量控制和数据包功能,保证了网络的安全,稳定和高速运行 支持多条WAN线路和负载均衡功能,可大幅度提高网络出口带宽,在带宽拥塞时自动分配负载 内置了IPsec 和PPTP VPN功能,实现不同分支机构的远程互联或远程用户安全地访问内部网 支持802.1Q VLAN标准,可以通过软件模拟的方式使得普通网卡能识别802.1Q的标记,同时为多个VLAN的用户提供服务 支持使用额外的软件包来扩展pfSense功能,为用户提供更多的功能(如FTP和透明代理). 详细的日志功能,方便用户对网络出现的事件分析,统计和处理 使用Web管理界面进行配置(支持SSL),支持远程管理和软件版本自动在线升级 本文简单介绍pfSense的安装及配置过程，完成一个基本的路由器该有的功能，如访问局外网、设置防火墙规则、配置端口映射。这里演示在ESXi虚拟服务器上，解决IP不足的问题。
创建虚拟机 首先去 https://www.pfsense.org/download/ 下载稳定版本的pfSense，如pfSense-LiveCD-2.2.2-RELEASE-amd64.iso.gz（网上看到有人提到这个版本不稳定，我在使用中偶尔也发现突然很慢，建议2.1.5）。在vSphere上创建虚拟机的过程省略，取名01_pfSense，创建虚拟机操作系统时选择“其他 -&amp;gt; FreeBSD 64位”，单CPU,512Mb内存，4G硬盘。将下载的系统解压成iso后挂载到CD/DVD，并“打开电源时连接”。 下图是网卡情况： 为pfSense分配两个网卡，分别是可以连接公司内网的172.29.88.1/24网段的vSphere_Admin端口组，和IP范围是172.30.31.1/24的内部局域网端口组VM Local。 记录下Mac地址 外网接口：00:0c:29:36:b6:c2 内网接口：00:0c:29:36:b6:cc
安装pfsense 启动电源后出现欢迎界面，选择1.Boot pfSense [default]，或等待几秒钟自动选择，进入如下界面： 输入I，回车，然后是一个蓝屏，开始安装。
也可以什么都不用管，系统会一直启动从CD启动得到一个完整的pfSense系统，因为没有安装所以在屏幕下方会有一个选项99） Install pfSense to a hard drive, etc.，输入99同样会进入下面的安装操作系统的过程。 一路保存默认：&amp;lt; Accept these Settings &amp;gt; → &amp;lt; Quick/Easy InStall &amp;gt; → erase all content &amp;lt; OK &amp;gt; → &amp;lt; Standard Kernel &amp;gt; → &amp;lt; Reboot &amp;gt;。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: rpm或yum安装软件提示error-rpmts_HdrFromFdno-key-ID-BAD date: 2015-03-02 01:21:25 updated: 2015-03-02 00:46:23 tags: [linux, 软件包,troubleshooting] categories: Linux 问题 在 CentOS 6.4 x86_64 上无论通过yum或rpm安装软件时，出现以下错误：
yum install glibc-devel ... error: rpmts_HdrFromFdno: Header V3 RSA/SHA1 Signature, key ID c105b9de: BAD ... Problem opening package *.el6.x86_64.rpm 分析 rpm -ivh单独去安装软件也提示上面的错误。rpm -qa 无法列出系统中安装过的软件包，但许多库文件和软件命令是存在的。也尝试过rpm --rebuilddb来重建数据库，但情况依然没有得到改善（centos官网说千万不要在系统broken的情况下rebuilddb，不然有可能变成destroy）
由上面的推断可知问题出现在rpm这个软件包管理工具本身，但此时又无法通过rpm来重新安装自己，所以只能找到具体是什么因素导致的。好在官网的这篇较新的文章正好就是解决该BUG：WARNING: nss-softokn-3.14.3-19.el6_6 updates may be broken ：
大致是说当你使用yum update去更新你的系统时，nss-softokn、nss-softokn-freebl和其它软件一起都得到更新，所以不会有问题。但如果单独去更新某一个软件，如yum update nss-softokn或yum install &amp;lt;software&amp;gt;引起它的依赖包也升级，使得nss-softokn和nss-softokn-freebl版本不匹配，就会导致 rpm/yum 全面停止工作，表现就是上面的key .. BAD。
解决 解决起来也很方便，首先你可以通过cat /var/log/messages|grep nss看到nss-softokn-freebl的版本：
# cat /var/log/messages|grep nss-softokn Mar 2 09:56:18 poprod yum[14920]: Updated: nss-softokn-3.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: Linux下同步工具inotify+rsync使用详解 date: 2014-12-12 01:21:25 updated: 2015-05-05 12:46:23 tags: [rsync,inotify,backup，文件同步] categories: Linux 1. rsync 1.1 什么是rsync rsync是一个远程数据同步工具，可通过LAN/WAN快速同步多台主机间的文件。它使用所谓的“Rsync演算法”来使本地和远程两个主机之间的文件达到同步，这个算法只传送两个文件的不同部分，而不是每次都整份传送，因此速度相当快。所以通常可以作为备份工具来使用。
运行Rsync server的机器也叫backup server，一个Rsync server可同时备份多个client的数据；也可以多个Rsync server备份一个client的数据。Rsync可以搭配ssh甚至使用daemon模式。Rsync server会打开一个873的服务通道(port)，等待对方rsync连接。连接时，Rsync server会检查口令是否相符，若通过口令查核，则可以开始进行文件传输。第一次连通完成时，会把整份文件传输一次，下一次就只传送二个文件之间不同的部份。
基本特点：
可以镜像保存整个目录树和文件系统； 可以很容易做到保持原来文件的权限、时间、软硬链接等； 无须特殊权限即可安装； 优化的流程，文件传输效率高； 可以使用rcp、ssh等方式来传输文件，当然也可以通过直接的socket连接； 支持匿名传输。 命令语法： rsync的命令格式可以为以下六种： rsync [OPTION]… SRC DEST rsync [OPTION]… SRC [USER@]HOST:DEST rsync [OPTION]… [USER@]HOST:SRC DEST rsync [OPTION]… [USER@]HOST::SRC DEST rsync [OPTION]… SRC [USER@]HOST::DEST rsync [OPTION]… rsync://[USER@]HOST[:PORT]/SRC [DEST]
对应于以上六种命令格式，我们可以总结rsync有2种不同的工作模式：
shell模式：使用远程shell程序（如ssh或rsh）进行连接。当源路径或目的路径的主机名后面包含一个冒号分隔符时使用这种模式，rsync安装完成后就可以直接使用了，无所谓启动。（目前没有尝试过这个方法） daemon模式：使用TCP直接连接rsync daemon。当源路径或目的路径的主机名后面包含两个冒号，或使用rsync://URL时使用这种模式，无需远程shell，但必须在一台机器上启动rsync daemon，默认端口873，这里可以通过rsync --daemon使用独立进程的方式，或者通过xinetd超级进程来管理rsync后台进程。 当rsync作为daemon运行时，它需要一个用户身份。如果你希望启用chroot，则必须以root的身份来运行daemon，监听端口，或设定文件属主；如果不启用chroot，也可以不使用root用户来运行daemon，但该用户必须对相应的模块拥有读写数据、日志和lock file的权限。当rsync以daemon模式运行时，它还需要一个配置文件——rsyncd.conf。修改这个配置后不必重启rsync daemon，因为每一次的client连接都会去重新读取该文件。
我们一般把DEST远程服务器端成为rsync Server，运行rsync命令的一端SRC称为Client。
安装： rsync在CentOS6上默认已经安装，如果没有则可以使用yum install rsync -y，服务端和客户端是同一个安装包。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: Linux下rar及zip压缩包中批量替换某文件脚本 date: 2015-01-29 18:21:25 updated: 2015-01-30 11:46:23 tags: [script, shell] categories: Linux 本需求是自己负责的一个生产系统上，有大量以zip和rar结尾的压缩文件散落在文件系统的各个文件夹，先在需要把压缩包里包含某一个特定文件（如tftpd32.exe或Tftpd32.exe，版本较旧），全都替换成比较新的tftpd32.exe版本。压缩文件总数约5000个，需要替换的数量约1500个。
因为是生产环境，不敢轻易乱动，所以脚本考虑的因素就非常多，不允许中间执行过程出现异常，所以找到文件后实际执行替换操作之前做好备份，并且将操作过程记录日志。
以下几点需要考虑：
分别处理zip和rar文件，为减低脚本的复杂程度，分作两个shell脚本。 rar在Linux下默认是没有安装解压缩工具，下载rarlinux-x64-5.2.0.tar.gz zip包中文件含有中文文件名，unzip测试解压缩或列出内容时出现文件名乱码，原因是zip在压缩时不记录当时的编码格式。这个问题非常棘手，乱码打进压缩包是绝对不允许的，网上有几种解压办法有几种办法都不能很好的应对我的场景：并不需要实际解压zip文件，而只需使用 l ——列出文件列表、获取目录及文件名，d ——从压缩包中直接删除某个文件，a ——向压缩包添加一个文件。实际解压到文件系统上是不是乱码我们并不关心。 最后的解决办法是使用p7zip工具，配合LANG变量解决。 向压缩包里添加新文件时，要保持里面的目录结构，则必须在文件系统上存在同样的 相对目录/文件 。所以每次都要在脚本执行目录下创建临时目录tmp_dir，还要及时删除。但如果文件在压缩包的根目录下，这个临时目录就是当前脚本执行目录。 有可能会存在一个压缩包中多个文件夹中包含不止一个tftpd32.exe文件。 每个文件都有一个CRC值，处理文件名大小写不同但实质是同一个文件时有效。 以下脚本使用说明：
变量说明 filelist 变量设定你所需要检查的压缩文件列表（绝对路径），可以通过find /your/dir/ -name *.rar | sort | uniq &amp;gt; testfile。与脚本在相同目录下，并且为unix格式 existlist 变量是从filelist文件中得到的包含特定文件的列表，脚本执行完后可以查看 errorlist 变量是从filelist文件列表中得到的不包含特定文件的列表，当然也有可能这个压缩文件本身不完整 filebak 变量指定要替换的那个压缩文件备份的目录 oldfile 指定要替换的那个文件名 newfile 指定新文件的文件名，注意这个文件一定要在脚本当前目录下 binrar,bin7z 指定解压缩命令目录，因为7z和rar都不是CentOS自带的 fl 是filelist文件列表里的每一条记录 exist 压缩文件fl的内容列表里包含tftpd32.exe的记录，可能有多行 dirfiles 处理exist的结果，形如压缩包里的目录结构 your/dir/tftpd32.exe，可能有多行 df 是dirfiles中的单行记录，它的前面目录部分便是tmp_dir 是否有必要root用户执行看个人情况，执行后部分文件的属主可能会变，可用chown user1.user1 -R /your/dir/恢复 有部分zip文件无法使用7z，但文件本身正常，从日志可以看到error信息 tftpd32.exe区分大小写，如果要查找替换Tftpd32.exe请修改后在执行（确保grep没有-i选项） 可以处理的情况 压缩文件中无tftpd32.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 习惯晚睡 date: 2015-03-14 15:21:25 updated: 2015-03-15 16:46:23 tags: feelings categories: Feel 很久没有像今天这样坐下来写东西了，也不知道抽的什么风，大上午背着电脑跑到南山图书馆来了，可能是实在想不到大好的周末能做些什么吧。其实也倒不是心血来潮，过年回到深圳以后，很长一段时间都在思考过去，规划以后的方向，零零碎碎的记录了一些，但至今未能成文。但今天不是讲规划，而是——习惯，晚睡的习惯。
作为刚24的满血青年，很多人可能会反驳晚一点睡算什么，此时不任性何时才任性。我倒不是说晚睡不行，问题是我因何而晚睡。最近一直在看池建强老师的《MacTalk-人生元编程》这本书，无论Apple的联合创始人沃茨，还是微软的艾伦，在初期哪一个不是没日没夜的工作。当然咱无法与这些传奇人物比拟，但至少说明熬夜，要值得，如果我是在熬夜积累自己，或能对改善以后的状况，我就觉得值得。
可是现在我们大多数人熬夜在干嘛呢，包括我也有反思自己。
这里先说说我的熬夜习惯从何而来吧。大学时候有电脑开始。那时候除了学业，还有部分学生工作，再有就是qq，往往深夜凌晨一两点还在挂着电脑qq，还记得太晚不睡免得有同学说，特意到了1点左右调成隐身，一边看电影，还一边刷微博。当时有个玩的较好的室友，他的原则是过点（0点）必睡，我还曾与他争论过“到点睡觉，规规矩矩”“大学时不疯狂一下没多大意义”，可是现在我回头想来我也并没有因为比他多熬几个夜而记起怎样怎样刻骨铭心的记忆。现在想来更难以理解的是，我大三大四好像竟然是因为学习任务而熬夜加班加点，甚至考研的时间里依旧毫无规律，噢不，有规律的熬夜，而且愈发厉害熬到3点。这样都能考上的话我就不用坐在这里一边埋怨一边writing了。当然还有部分属于我个人的故事……
也就是这样习惯，毕业后延续到现在，不过较好的一点是没那么严重，平日晚一点到1点，因为考虑到第二天还要上班这样一个事实，一到周末，又毅然决然的熬到凌晨三四点，而大部分情况是在看电影电视，似乎周五的晚上是从11点开始，周六的白天从下午一点开始……
写到这里，我倒不是谴责自己晚睡这样一个习惯，因为我相信肯定还是有很大一部分人跟我一样有着凌晨一点才睡的习惯，目前跟我一起合租的同事就是两个活生生的例子，更不是告诉自己“熬夜对身体有害”这样一个众所周知的烂道理。有些人熬夜是迫不得已，而我是因为三四年时间形成的习惯。我依然坚持大学里我对室友说的那个观点（前提是我是男的，身体也没什么旧疾），熬夜疯一下可以，问题是干什么。有多少人可以熬夜而不用考虑明天。
最近上班没什么特别的工作，拿出不少时间去简书上看看文章，或搜到某个人博客，就闲来无事的点开Archive列表，随机点开看看。看到人家几年来做的点点滴滴，同龄人群里，我却丝毫想不起那时候我在做什么，依旧是同龄人我现在正在学的东西，人家两三年前就在用了。这也不难解释我现在的处境了。不止一次有过努力追赶别人的想法，可是晚上一回到家，不是迷上电视就是电脑手机。回家前我计划要做的事情实施了吗？这样是会有一点点累，可我24岁的年龄过着如此安逸的生活，这不是我应得的。来自家里的压力，我应该是努力在工作技能上积累，在生活情商上积累，而我没那么多时间，慢慢来…
一个人的努力是孤独的，也是幸运的。毫无理由的晚睡，第二天迷迷糊糊起床，这不是我想要的状态。想要有所作为，可能就因为一个不经意的习惯而磨损了自己的动力。
我想象这样一个场景：
早上提前30分钟（七点）起来，轻轻松松的洗漱，打扮，然后从容的吃个早饭，车上看看知乎。
上班时间，没事少刷朋友圈，早中晚看几次就行了。中午看看新闻，午休一觉，快速进入工作状态，不能再迷糊半个小时（这也成习惯了吧）。
下午三四点上班累了，走动走动，聊聊天，打打水。眼睛酸了，滴滴眼药水（买了别浪费）
晚上下班车上，听听歌。早的话，跟室友一起买买菜做做饭。
10点以后是自己的时间，我可以舒舒服服的洗个澡，不开电脑，然后看一个半小时的书，或者看看新闻和喜欢的节目，再或者利用好Mac学点东西，写点东西。
周末，九点钟起来。偶尔聚聚，逛逛，但至少拿出一天时间去图书馆，家里真不适合学习、阅读和写作。拿一个晚上去打打球，看看电影什么的。
有人会说，不就是晚睡而已吗，至于这样吗，功利性太强了！
就我目前各方面不稳定因素来说，我觉得有必要这样一个list。把平时和睡前那些零碎时间利用起来，安安静静的坚持多看几书，不再拘泥于自己知道的小圈子，才会发现更多机会。
——闹钟真是一个伟大的发明，它让你放心的入睡，也无情的把你叫醒，为了减轻你的埋怨还允许你贪睡。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: tar命令高级用法——备份数据 date: 2014-12-08 01:21:25 updated: 2014-12-09 00:46:23 tags: [linux命令,tar,backup] categories: Linux Linux上有功能强大的tar命令，tar最初是为了制作磁带备份（tape archive）而设计的，它的作用是把文件和目录备份到磁带中，然后从磁带中提取或恢复文件。现在我们可以使用tar来备份数据到任何存储介质上。它是文件级备份，不必考虑底层文件系统类别，并且支持增量备份。
1. 部分常用选项 -z, --gzip：使用gzip工具（解）压缩，后缀一般为.gz -c, --create：tar打包，后缀一般为.tar -f, --file=：后面立刻接打包或压缩后得到的文件名 -x, --extract：解包命令，与-c对应 -p：保留备份数据的原本权限和属性 -g：后接增量备份的快照文件 -C：指定解压缩的目录 --exclude：排除不打包的目录或文件，支持正则匹配 其他
-X, --exclude-from：在一个文件中列出要排除的目录或文件（在--exclude=较多时使用） -t, --list：列出备份档案中的文件列表，不与-c、-x同时出现 -j, --bzip2：使用bzip2工具（解）压缩，后缀一般为.bz2 -P：保留绝对路径，解压时同样会自动解压到绝对路径下 -v：（解）压缩过程显示文件处理过程，常用但不建议对大型文件使用 2. 增量备份（网站）数据 许多系统（应用或网站）每天都有静态文件产生，对于一些比较重要的静态文件如果有进行定期备份的需求，就可以通过tar打包压缩备份到指定的地方，特别是对一些总文件比较大比较多的情况，还可以利用-g选项来做增量备份。
备份的目录最好使用相对路径，也就是进入到需要备份的根目录下
具体示例方法如下。
备份当前目录下的所有文件 # tar -g /tmp/snapshot_data.snap -zcpf /tmp/data01.tar.gz . 在需要恢复的目录下解压恢复 # tar -zxpf /tmp/data01.tar.gz -C . -g选项可以理解备份时给目录文件做一个快照，记录权限和属性等信息，第一次备份时/tmp/snapshot_data.snap不存在，会新建一个并做完全备份。当目录下的文件有修改后，再次执行第一条备份命令（记得修改后面的档案文件名），会自动根据-g指定的快照文件，增量备份修改过的文件，包括权限和属性，没有动过的文件不会重复备份。
另外需要注意上面的恢复，是“保留恢复”，即存在相同文件名的文件会被覆盖，而原目录下已存在（但备份档案里没有）的，会依然保留。所以如果你想完全恢复到与备份文件一模一样，需要清空原目录。如果有增量备份档案，则还需要使用同样的方式分别解压这些档案，而且要注意顺序。
下面演示一个比较综合的例子，要求：
备份/tmp/data目录，但cache目录以及临时文件排除在外 由于目录比较大（&amp;gt;4G），所以全备时分割备份的档案（如每个备份档案文件最大1G） 保留所有文件的权限和属性，如用户组和读写权限 # cd /tmp/data 做一次完全备份 # rm -f /tmp/snapshot_data.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 关于研究生的一点担忧 date: 2014-11-30 18:21:25 updated: 2014-11-30 20:46:23 tags: [feelings, graduate] categories: Feel 最近有个在大学玩的比较好现在在读研的同学，来询问我一些如何给老师做精品课程在线测试系统的问题，从沟通中我忍不住从个人的角度来表达一下感想和担忧。
首先从我接收到的信息来看，高校导师为了给自己擅长的课程评选上学校、市级或省级精品课程，急于完成一个展示成果的平台，只要能在最短的时间内提交所能看的见的成果，那就表明有效率和实力。所以这个在线测试系统只需要能够展示一个页面，页面上有单项、多选题，提交测试后直接显示对错和总分，无需记录测试者姓名等其他任何与试题无关的信息，也就是没有数据库。差不多就是一个静态页面了，对错的判断，包括答案都固定在代码里面了。我相信稍微了解IT软件开发的人都知道，这样的系统设计可以让人感到无语，当然还有很多不是计算机类专业的，可能看不懂这些，只关心最终实现的效果达到预期就行。偏偏导师和所交予任务的学生，都不懂设计和编程。所以当我说至少应该有个数据库时，“太麻烦，不懂，周期太长”。由于是出于帮忙的目的，也就没有说太多的话来打击他的积极性，说多了反而有点表现自己有多牛B的嫌疑，就硬着头皮做了个demo。
由此可见大学老师为评上精品课程，那种急功近利的心理，只要对外宣传“我们有一个在线测评系统来检验学生学习效果，blablabla&amp;hellip;”，然后评选小组比对评选规则里面有“在线测评”，加分！但请问像上面那样的系统意义何在？老师不知道有谁做过测试，不知道分数，只知道“当前浏览xxx次”，学生完全取决于是否主动。我想如果老师把这个测评当做一个硬性要求或作为所熟知却非常神秘的“平时成绩”的一部分，那只能是通过某种方式提交测试截图了。我心还想，在线测评系统一次性完成上线，是不是就再也不会修改了，加题减题，都要大动干戈的去修改后台代码，丝毫没有规划以后的扩展，当然也许我想多了，因为“这就是很简单的一个测试系统”，嗯，都说是测试而不是正式环境了，认真你就输了。
这里做个小插曲。我们生活的环境，充斥着太多的指标、太多的名声。想起上周在我司门口早上卖炸酱面的摊贩被城管执法包围那件事。每天早上这位大叔家的炸酱面是附近最好吃的，每天都排着很长的队，如果不赶时间我和同事们都会优先选择这家。大家都生活不易，城管也是，起早贪黑，四处蹲点追赶流动摊贩，因为没有业绩没有完成指标，如何回去交差。又想起电视里报道过某地的交警每月要达到罚款20万的指标，这说多了其实就是社会问题了，我们这些小众市民除了旁观，祈祷不要发生在我们身上，还能做些什么呢。指标本应该是一个积极充满正能量的、督促机构上进的一个目标，但是如果是为了充数而不择手段去实现，急功近利，那就变质了。
就在线测评问题来说，个人觉得比较合适的做法，应该是要具有一个长远的观念，为何学校不统一做一个在线测评系统，其他各个课程申请账号，获得出题的资格，自由的在后台添加题目，是否需要记录分数和姓名，老师还可以统计对比各班的情况，甚至在评上精品课程以后，作为进一步考核的数据来源，一次投入，无限产出。相比每门课程做重复低效的工作，一眼就可以看出利弊了。导师舍不得花钱请廉价的学生开发一个拿得出手的系统，只能让手下的研究生“自己看着办”。
另外一方面是我对研究生所表现出来的担忧，是关于学习方法和学习能力。研究生最后毕业靠的是一纸论文，我相信会有高水平有独立见解的论文，但大部分论文“借鉴”的成分会不会太高呢？我们原创性的东西太少了，习惯捡现成的东西，包括我自己也是，写一份配置文档需要google许多文章，然后东抄西拆，拼接起来，但至少它都是实践有效了，对于我个人来说具有较大的参考价值。然而在大学里养成了这样的习惯，就会慢慢的丧失学习能力，遇见要解决一个全新的问题，第一反应不是自己去网上检索，而是找到会的直接问“这个怎么做？”。我该如何回答是好呢？
提问也是有智慧的，问得太宽泛，需要与回答者反复沟通来确认具体的问题，才给出什么样的答案。依然是最初的例子，同学使用ASP.NET来做一个在线测试系统，但他完全不懂编程，于是就问了我“有哪些方法，要准备啥”（还好不是宽泛的问“要怎么做”），我告诉他一些流程性的东西，要基本会一些什么，但他说他是小白，编程基础几乎为零。还是为了快速拿出成果，于是我就违心的打开了2年没有点开竟然没有卸载的Visual Studio 2010，一边搜索，一边拖拉控件，许多基本知识都忘了，做了个及其简陋的demo，拙劣的后台代码自己都不忍直视。我一直不承认自己是个程序猿，实际上也不是，但依然偶尔会兼职一下。很难说我是不是把自己同学给害了，没害是这种可快速复制、完成任务的技能已经学会了，毕竟这一次之后他再也不必学习编程，害他是我把现成的东西给他了。其实任何一本书、任何一篇博客教程都可以自己琢磨快速搞定，而不是一出现问题“表格怎么做”、“图片怎么查”，我真就回了一句“ 搜索关键字 ‘html 表格’、‘asp.net 插入图片’ ”，当然一部分原因是当时忙，没有时间手把手教。
遇到问题，自己查阅资料，自己去理解，练习独立的去面对、解决问题，琢磨不明白的再去问，这样也不会浪费对方太多时间。当然简单一句话的能搞定的问题，也没必要说让提问者去走冤枉路，大概就是这个“度”的问题区分了人与人之间的差距和性格吧，无所谓绝对的对错。
写这么多，有点不自量力了，额，请看到的同学不要对号入座，没有任何针对性和攻击性。</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: SSL/TLS原理详解 date: 2015-01-07 01:21:25 updated: 2015-01-07 10:46:23 tags: [ssl, tls, 安全] categories: Linux 本文大部分整理自网络，相关文章请见文后参考。
关于证书授权中心CA以及数字证书等概念，请移步 OpenSSL 与 SSL 数字证书概念贴 ，如果你想快速自建CA然后签发数字证书，请移步 基于OpenSSL自建CA和颁发SSL证书 。
SSL/TLS作为一种互联网安全加密技术，原理较为复杂，枯燥而无味，我也是试图理解之后重新整理，尽量做到层次清晰。正文开始。
1. SSL/TLS概览 1.1 整体结构 SSL是一个介于HTTP协议与TCP之间的一个可选层，其位置大致如下: SSL：（Secure Socket Layer，安全套接字层），为Netscape所研发，用以保障在Internet上数据传输之安全，利用数据加密(Encryption)技术，可确保数据在网络上之传输过程中不会被截取。当前版本为3.0。它已被广泛地用于Web浏览器与服务器之间的身份认证和加密数据传输。 SSL协议位于TCP/IP协议与各种应用层协议之间，为数据通讯提供安全支持。SSL协议可分为两层： SSL记录协议（SSL Record Protocol）：它建立在可靠的传输协议（如TCP）之上，为高层协议提供数据封装、压缩、加密等基本功能的支持。 SSL握手协议（SSL Handshake Protocol）：它建立在SSL记录协议之上，用于在实际的数据传输开始前，通讯双方进行身份认证、协商加密算法、交换加密密钥等。
TLS：(Transport Layer Security，传输层安全协议)，用于两个应用程序之间提供保密性和数据完整性。 TLS 1.0是IETF（Internet Engineering Task Force，Internet工程任务组）制定的一种新的协议，它建立在SSL 3.0协议规范之上，是SSL 3.0的后续版本，可以理解为SSL 3.1，它是写入了 RFC 的。该协议由两层组成： TLS 记录协议（TLS Record）和 TLS 握手协议（TLS Handshake）。较低的层为 TLS 记录协议，位于某个可靠的传输协议（例如 TCP）上面。
SSL/TLS协议提供的服务主要有：
认证用户和服务器，确保数据发送到正确的客户机和服务器； 加密数据以防止数据中途被窃取； 维护数据的完整性，确保数据在传输过程中不被改变。 1.2 TLS与SSL的差异 版本号：TLS记录格式与SSL记录格式相同，但版本号的值不同，TLS的版本1.0使用的版本号为SSLv3.1。 报文鉴别码：SSLv3.0和TLS的MAC算法及MAC计算的范围不同。TLS使用了RFC-2104定义的HMAC算法。SSLv3.0使用了相似的算法，两者差别在于SSLv3.0中，填充字节与密钥之间采用的是连接运算，而HMAC算法采用的是异或运算。但是两者的安全程度是相同的。 伪随机函数：TLS使用了称为PRF的伪随机函数来将密钥扩展成数据块，是更安全的方式。 报警代码：TLS支持几乎所有的SSLv3.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: CentOS 6.x 内核升级（2.6.32 -&amp;gt; 3.10.58）过程记录 date: 2014-10-24 01:21:25 updated: 2014-10-27 10:46:23 tags: [docker, Linux内核, upgrade] categories: [Linux, CentOS] 本人升级的目的是想在CentOS6.2上运行docker，官方建议内核版本在3.8.0及以上，于是就自己从Linux内核官方网站上下载源码，自己编译。 ##1. 准备工作## ###1.1 确认内核及版本信息###
[root@hostname ~]# uname -r 2.6.32-220.el6.x86_64 [root@hostname ~]# cat /etc/centos-release CentOS release 6.2 (Final) ###1.2 安装软件###
编译安装新内核，依赖于开发环境和开发库
# yum grouplist //查看已经安装的和未安装的软件包组，来判断我们是否安装了相应的开发环境和开发库； # yum groupinstall &amp;#34;Development Tools&amp;#34; //一般是安装这两个软件包组，这样做会确定你拥有编译时所需的一切工具 # yum install ncurses-devel //你必须这样才能让 make *config 这个指令正确地执行 # yum install qt-devel //如果你没有 X 环境，这一条可以不用 # yum install hmaccalc zlib-devel binutils-devel elfutils-libelf-devel //创建 CentOS-6 内核时需要它们 如果当初安装系统是选择了Software workstation，上面的安装包几乎都已包含。 ##2.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 在Mac在Mac/win7下上使用Vagrant打造本地开发环境 date: 2015-03-25 11:21:25 updated: 2015-03-27 18:46:23 tags: [vagrant, virtualbox, 虚拟化,开发环境] categories: Virtualization 1. vagrant介绍 1.1 vagrant能做什么 做Web开发（java/php/python/ruby&amp;hellip;）少不了要在本地搭建好开发环境，虽然说目前各种脚本/语言都有对应的Windows版，甚至是一键安装包，但很多时候和Windows环境的兼容性（如配置文件、编译的模块）并不是那么好，麻烦的问题是实际部署的环境通常是Linux，常常还要面临着开发和部署环境不一致，上线前还要大量的调试。而如果让每个开发人员都自己去搭建本地环境，安装虚拟机、下载ISO镜像、选择规格安装创建vm、安装OS、配置，会耗费非常多的时间，如果是团队开发应该要尽量保持每个人的运行环境一致。此时vagrant正式你所需要的。不适用正式环境部署。
vagrant实际上一套虚拟机管理工具，基于Ruby开发，底层支持VirtualBox、VMware甚至AWS、docker等作为虚拟化系统。我们可以通过 Vagrant 封装一个 Linux 的开发环境，分发给团队成员。成员可以在自己喜欢的桌面系统（Mac/Windows/Linux）上开发程序，代码却能统一在封装好的环境里运行，“代码在我机子上运行没有问题”这种说辞将成为历史。
通过上面的介绍如果你还在困惑有virtualbox或vmware为什么还要加入vagrant，纠结于要不要使用，可以参考这个问答 使用vagrant的意义在哪，另外docker作为后起之秀也可以做vagrant能完成的事情，stackoverflow有关于两位作者讨论各自应用场景的精彩&amp;quot;互掐&amp;quot;，传送门→ （中文）。
1.2 几个概念 Provider：供应商，在这里指Vagrant调用的虚拟化工具。Vagrant本身并没有能力创建虚拟机，它是调用一些虚拟化工具来创建，如VirtualBox、VMWare、Xen、Docker，甚至AWS，这些虚拟化工具只要安装好了，vagrant会自动封装在底层通过统一的命令调用。也就是说使用vagrant时你电脑上还需要安装对应的Provider，默认是免费开源的virtualbox。 Box：可被Vagrant直接使用的虚拟机镜像文件，大小根据内容的不同从200M-2G不等。针对不同的Provider，Box文件的格式是不一样的，从 vagrantcloud.com 你可以找到社区维护的box。
Vagrantfile：Vagrant根据Vagrantfile中的配置来创建虚拟机，是Vagrant的核心。在Vagrantfile文件中你需要指明使用哪个Box（可以下载好的或自己制作，或指定在线的URL地址），虚拟机使用的内存大小和CPU，需要预安装哪些软件，虚拟机的网络配置，与host的共享目录等。
Provisioner：是Vagrant的插件的一种。大部分现成的box并不是你正好想要的，通过使用你熟悉的provisioner，比如Puppet，可以在你使用vagrant up启动虚拟机时自动的安装软件、修改配置等初始化操作。当然你也可以在最先启动虚拟机后，使用vagrant ssh进去然后手动安装软件，但毕竟不是所有人都是系统管理员，写好Vagrantfile后无需人工干预马上就可以使用vm。目前支持并实现的provisioning有Puppet、Salt、Ansible、Chef这些知名的自动化运维工具，当然需要一定的使用经验；也可以使用shell provisioner，故名思议这个插件就是通过执行shell命令完成统一的作用。
Guest Additions：这个是常在下载 base box 介绍里有的，一般用来实现host到vm的端口转发、目录共享，在开发环境上都建议装上以便测试。
2. 安装vagrant VirtualBox: 4.3.12，https://www.virtualbox.org/wiki/Download_Old_Builds_4_3 。我上手使用的是4.3.20，折腾出过几个问题，据说说4.3.12版本较稳定。 建议选择VirtualBox ，即使你电脑上已经安装VMware Workstation或Fushion，它的vagrant插件还是要收费的 Vagrant: 1.7.1，http://www.vagrantup.com/downloads-archive.html 选择适合你的平台（Windows、Mac、Linux），下载对应格式的安装包。如Mac下 vagrant_1.7.1.dmg、VirtualBox-4.3.20-96997-OSX.dmg 。
3. 使用vagrant打造一个本地开发环境 本文将会演示从 nrel CentOS6.5 开始，安装必要的开发包、python、插件、Puppet，然后打包成一个box分发给团队的全过程。你也可以在别人box的基础上进一步通过Vagrantfile定制自己的环境。
3.1 初始化 3.1.1 vagrant box add {box-name} {box-url} $ vagrant box add ct65_00 Downloads/centos65.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: vim编辑器技巧备忘（初级-中级） date: 2014-08-07 01:21:25 updated: 2014-08-07-12 00:46:23 tags: [vim,编辑器] categories: Linux “学习vim并且其会成为你最后一个使用的文本编辑器” 学习建议：
丢弃鼠标和小键盘 具有搭配使用各种按键的意识 首先来一张 mindmap :
1. 初级 1.1 编辑模式（Insert Mode） 编辑模式包括以下动作：
insert：i在光标所在字符前插入，I在当前行首第一个非空格字符前插入 append：a在光标所在字符后插入，A在行末尾开始插入 open：o在下一行插入新行，O在光标所在行的上一行插入新行 replace：r将光标处字符替换成r紧接的字符；R一直替换字符串，知道ESC键退出，同windows下的Insert键 Ctrl+p：自动提示 [ESC]：回到普通模式 1.2 普通模式（Normal Mode） h, j, k, l ，分别对应 左← 下↓ 上↑ 右→
:q, :q!, :wq 退出 不保存强行退出 保存退出
移动光标到当前行首/非空格，同^，:0
$ 移动光标到当前行尾，同:$
G 移动光标到文档最后一行首
30G 转到第30行，同 :30
9- 光标向上移动9行，同9k
9+ 光饼向下移动9行，同9[space]，9j
gg 转到文档第一行(1G)
H 移动到屏幕的第一列
M 移动到屏幕的中间列
L 移动到屏幕的最后列
w 移动到下一个单词的首字母，（标点符号认为是一个单词，W表示单词以空格分隔）</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 使用vmware vconverter从物理机迁移系统到虚拟机P2V（多图） date: 2015-04-05 15:21:25 updated: 2015-04-06 00:46:23 tags: [vsphere, 虚拟化,vmware] categories: Virtualization 本文完整记录了如何从物理服务器，保持所有环境配置信息，纹丝不动的迁移到虚拟机上，俗称 P2V 。采用的工具是VMware公司的 VMware vcenter vconverter standalone，它支持将windows和linux操作系统用作源，可以执行若干转换任务：
将正在运行的远程物理机和虚拟机作为虚拟机导入到vCenter Server管理的独立ESX/ESXi或ESX/ESXi主机 将由VMware Workstation或Microsoft Hyper-V Server托管的虚拟机导入到vCenter Server管理的ESX/ESXi主机 将第三方备份或磁盘映像导入到vCenterServer管理的ESX/ESXi主机中 将旧版服务器迁移到新硬件，而不重新安装操作系统或应用程序软件等 完整功能见《Converter Standalone 用户指南》 Converter Standalone的组件，只能安装在Windows操作系统上：
Converter Standalone Server —— 启用并执行虚拟机的导入和导出 Converter Standalone agent —— Converter Standalone Server会在Windows物理机上安装代理，从而将这些物理机作为虚拟机导入，完成后可以选择自动删除 Converter Standalone client —— 与Converter服务端配合使用，包括看到的用户界面、创建和管理转换任务等 Vmware vCenter Converter引导CD：是单独的组件，可用于在物理机上执行冷克隆 冷克隆可以创建一致的源计算机的精确副本，而我们更多的是进行热克隆，也就是源服务器在迁移过程中会继续工作，这就可能会出现某些文件不一致，但Converter Standalone会在热克隆后将目标虚拟机与与主机同步，同步执行过程是将在初始克隆期间更改的块从源复制到目标。
本文记录的过程是，源主机是 SUSE 11.x 物理机，运行华为的智能呼叫中心应用，因此安装有Oracle数据库，对于数据文件和控制文件的一致性和安全性较高，所以建议先把oracle数据库关闭再操作；目标虚拟服务器是 ESXi 5.1，但我使用的Converter是 5.5-en，操作过程类似。下面正式开始
源主机：172.30.31.0/24 ESXi: 172.29.88.0/24，与源主机IP段无法通信 Helper VM: 172.29.41.0/24，与上面两个IP段都通</description>
    </item>
    
    <item>
      <title></title>
      <link>http://xgknight.com/posts/1/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://xgknight.com/posts/1/01/</guid>
      <description>title: 误删vSphere虚拟机.vmdk文件的恢复 date: 2014-10-28 15:21:25 updated: 2014-10-28 00:46:23 tags: [vsphere, 虚拟化,troubleshooting] categories: Virtualization 1. 错误描述 在vSphere上，一次重启虚拟服务器时出现启动不了，提示找不到vmdk虚拟磁盘文件： 2. 原因分析 查看这台虚拟服务器的摘要信息，对比datastore上其他可用的虚拟机，发现损坏的服务器上确实缺少一个vmdk磁盘文件，但是可以看见一个50G的xxx-flat.vmdk文件；而正常的服务器只有xxx.vmdk，没有xxx-flat.vmdk，关机之后两个文件都存在，而且真实的磁盘容量从vmdk转移到了xxx-flat.vmdk。 虚拟主机在运行的时候，实际在使用的是xxx-flat.vmdk，然而xxx.vmdk是可以同时被删除的，才导致了问题。
这里需要说明，虚拟机的每个磁盘驱动器都包含了一对.vmdk文件。一个是文本文件，包含了关于虚拟硬盘的描述数据；另外一个是磁盘的实际内容。例如，一个名为examplevm的虚拟机连接有一个硬盘。这个磁盘由如下两个文件构成：一个小于 1KB 的examplevm.vmdk描述文件和一个10GB大小的examplevm- flat.vmdk平面（数据）文件，该文件包含虚拟机的实际数据，而这些数据又是以二进制的形式存放在物理磁盘上，examplevm.vmdk描述文件就是描述这种映射关系的。 另外：
A note for ESX-users: Do not use Datastorebrowser to identify vmdks or download them for editiing. The Datastorebrowser does not display vmdks correctly. It usually hides *-flat.vmdks and *-delta.vmdks.
TO-DO: 后续为 VMware ESXi 5 的磁盘专门记录一篇文章，说明“置备空间”以及vmfstools工具的使用。
3. 解决办法 (1) 用ssh登录vsphere主机，查找xxx-flat.vmdk文件所在的位置以及目录，并记录文件的大小
~ # find / -name &amp;#34;新建虚拟机-flat.vmdk&amp;#34; /vmfs/volumes/50a98441-ab02c8b7-e60a-001517712dce/新建虚拟机/新建虚拟机-flat.</description>
    </item>
    
  </channel>
</rss>
